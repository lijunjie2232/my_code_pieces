{
  "folders": [
    {
      "id": "FFoy_tpD",
      "name": "Default",
      "defaultLanguage": "typescript",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "createdAt": 1705547730793,
      "updatedAt": 1705547730793,
      "index": 0
    },
    {
      "name": "js",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "plain_text",
      "id": "8qmQazwt",
      "createdAt": 1705547881037,
      "updatedAt": 1705547887416,
      "index": 1
    },
    {
      "name": "nodejs",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "plain_text",
      "id": "OtjZFwbc",
      "createdAt": 1705559758412,
      "updatedAt": 1705559762435,
      "index": 2
    },
    {
      "name": "python",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "python",
      "id": "weWtbZI4",
      "createdAt": 1705649797466,
      "updatedAt": 1709526488611,
      "index": 3
    },
    {
      "name": "linux",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "sh",
      "id": "NCg2YrWJ",
      "createdAt": 1705655890816,
      "updatedAt": 1709526511683,
      "index": 4
    },
    {
      "name": "web",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "plain_text",
      "id": "fA481292",
      "createdAt": 1705739854728,
      "updatedAt": 1705739858907,
      "index": 5
    },
    {
      "name": "ts",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "typescript",
      "id": "RxpfS9zV",
      "createdAt": 1709687889308,
      "updatedAt": 1709687938343,
      "index": 6
    },
    {
      "name": "cmd",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "powershell",
      "id": "HRD2NCV8",
      "createdAt": 1711067461127,
      "updatedAt": 1711067487711,
      "index": 7
    },
    {
      "name": "algo",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "c_cpp",
      "id": "4ojt5eME",
      "createdAt": 1720877654533,
      "updatedAt": 1720877817895,
      "index": 8
    },
    {
      "name": "deeplearning",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "python",
      "id": "DvcfGvIx",
      "createdAt": 1724574331649,
      "updatedAt": 1724574577063,
      "index": 9
    }
  ],
  "snippets": [
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "8qmQazwt",
      "tagsIds": [],
      "description": null,
      "name": "xhr",
      "content": [
        {
          "label": "get",
          "language": "javascript",
          "value": "function loadDoc() {\n    // 第一步： 创建xhr对象\n    let xhr = new XMLHttpRequest();\n    // 第二步： 调用open函数 指定请求方式 与URL地址\n    xhr.open('GET', '/demo/music_list.xml', true);\n    // 第三步： 调用send函数 发起ajax请求\n    xhr.send();\n    // 第四步： 监听onreadystatechange事件\n    xhr.onreadystatechange = function () {\n        // 监听xhr对象的请求状态 与服务器的响应状态\n        if (this.readyState == 4 && this.status == 200) {\n            // 如果响应就绪的话，就创建表格(拿到了服务器响应回来的数据xhr.responseText)\n            myFunction(this)\n        }\n    }\n}\n\nxhr.open('GET', 'http://www.liulongbin.top:3006/api/getbooks?id=1')\n"
        },
        {
          "label": "post-formdata",
          "language": "javascript",
          "value": "// 第一步： 创建xhr对象\nlet xhr = new XMLHttpRequest();\n// 第二步： 调用open函数\nxhr.open('POST', 'http://www.liulongbin.top:3006/api/addbook')\n// 第三步： 设置Content-Type属性 （这一步是固定的写法）\nxhr.setRequestHeader('Conten-Type', 'application/x-www-form-urlencoded')\n// 第四步： 调用send（）函数，同时将数据以查询字符串的形式，提交给服务器\nxhr.send('bookname=水浒传&author=施耐庵&publisher=天津图书出版社')\n// 第五步：监听onreadystatechange事件\nxhr.onreadystatechange = function () {\n    if (xhr.readyState === 4 && xhr.status === 200) {\n        console.log(xhr.responseText)\n    }\n}"
        },
        {
          "label": "post-json",
          "language": "javascript",
          "value": "const xhr = new XMLHttpRequest()\n\n// listen for `load` event\nxhr.onload = () => {\n  // print JSON response\n  if (xhr.status >= 200 && xhr.status < 300) {\n    // parse JSON\n    const response = JSON.parse(xhr.responseText)\n    console.log(response)\n  }\n}\n\n// create a JSON object\nconst json = {\n  email: 'eve.holt@reqres.in',\n  password: 'cityslicka'\n}\n\n// open request\nxhr.open('POST', 'https://reqres.in/api/login')\n\n// set `Content-Type` header\nxhr.setRequestHeader('Content-Type', 'application/json')\n\n// send rquest with JSON payload\nxhr.send(JSON.stringify(json))"
        }
      ],
      "id": "jWmi9e8d",
      "createdAt": 1705547901298,
      "updatedAt": 1705548171733
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "8qmQazwt",
      "tagsIds": [],
      "description": null,
      "name": "ajax",
      "content": [
        {
          "label": "get",
          "language": "javascript",
          "value": "$.get('url', {name: 'zs', age: 20}, function() {})\n// 等价于\n$.get('url?name=zs&age=20', function() {})\n\n$.ajax({ method: 'GET', url: 'url', data: {name: 'zs', age: 20}, success: function() {} })\n// 等价于\n$.ajax({ method: 'GET', url: 'url?name=zs&age=20', success: function() {} })"
        },
        {
          "label": "json",
          "language": "plain_text",
          "value": "$.ajax({\n  url: 'example.com/api/data',\n  method: 'GET',\n  dataType: 'json',\n  success: function(data) {\n    // 成功接收到数据后的回调函数\n    // data 参数就是解析后的 JSON 数据\n    console.log(data); // 在控制台中打印数据\n\n    // 以下可以根据需要进行数据处理和展示\n    // 例如，将数据渲染到页面上：\n    var html = '';\n    $.each(data, function(index, item) {\n      html += '<li>' + item.name + '</li>';\n    });\n    $('#list').html(html);\n  },\n  error: function(xhr, status, error) {\n    // 处理请求错误的回调函数\n    console.log(error);\n  }\n});\n"
        }
      ],
      "id": "sAcJDFaN",
      "createdAt": 1705548024545,
      "updatedAt": 1705680788382
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "8qmQazwt",
      "tagsIds": [],
      "description": null,
      "name": "fetch api",
      "content": [
        {
          "label": "post-json",
          "language": "javascript",
          "value": "// create a JSON object\nconst json = {\n  email: 'hi@attacomsian.com',\n  password: '123abc'\n}\n\n// request options\nconst options = {\n  method: 'POST',\n  body: JSON.stringify(json),\n  headers: {\n    'Content-Type': 'application/json'\n  }\n}\n\n// send post request\nfetch('/login', options)\n  .then(res => res.json())\n  .then(res => console.log(res))\n  .catch(err => console.error(err))"
        },
        {
          "label": "get",
          "language": "javascript",
          "value": "fetch('/js/users.json')\n  .then(response => {\n    // handle the response data\n  })\n  .catch(error => {\n    // handle errors\n  })\n  \nfetch('https://reqres.in/api/users')\n  .then(response => response.json())\n  .then(data => {\n    data.data.forEach(user => {\n      console.log(`${user.id}: ${user.first_name} ${user.last_name}`)\n    })\n  })"
        },
        {
          "label": "header",
          "language": "javascript",
          "value": "// create an empty `Headers` object\nconst headers = new Headers()\n\n// add headers\nheaders.append('Content-Type', 'text/plain')\nheaders.append('Accept', 'application/json')\n\n// add custom headers\nheaders.append('X-AT-Platform', 'Desktop')\nheaders.append('X-AT-Source', 'Google Search')\n\n// check if the header exists\nheaders.has('Accept') // true\n\n// get headers\nheaders.get('Accept') // application/json\nheaders.get('X-AT-Source') // Google Search\n\n// update header value\nheaders.set('Content-Type', 'application/json')\n\n// remove headers\nheaders.delete('Content-Type')\nheaders.delete('X-AT-Platform')\n\n// Passing an object literal\nconst headers = new Headers({\n  'Content-Type': 'application/json',\n  Accept: 'application/json'\n})\n\n// OR\n\n// Passing an array of arrays\nconst headers = new Headers([\n  ['Content-Type', 'application/json'],\n  ['Accept', 'application/json']\n])\n\n// >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nconst request = new Request('https://reqres.in/api/users', {\n  headers: headers\n})\n\nfetch(request)\n  .then(res => res.json())\n  .then(json => console.log(json))\n  .catch(err => console.error('Error:', err))"
        }
      ],
      "id": "klHkol_O",
      "createdAt": 1705548237079,
      "updatedAt": 1705681113608
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "OtjZFwbc",
      "tagsIds": [],
      "description": null,
      "name": "Buffer",
      "content": [
        {
          "label": "子片段 1",
          "language": "javascript",
          "value": "let buf = Buffer.alloc(10);"
        }
      ],
      "id": "D1oJIFA5",
      "createdAt": 1705559765903,
      "updatedAt": 1705559826668
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "yaml",
      "content": [
        {
          "label": "read",
          "language": "python",
          "value": "import yaml\n\nwith open('voc.yaml', 'r', encoding='utf8') as f:\n\tdata = yaml.safe_load(f)"
        },
        {
          "label": "write",
          "language": "plain_text",
          "value": "import yaml\n\n# 创建配置字典\nconfig = {\n    'database': {\n        'host': 'localhost',\n        'port': 5432,\n        'name': 'mydb'\n    },\n    'app': {\n        'debug': True,\n        'log_level': 'info'\n    }\n}\n\n# 写入 YAML 文件\nwith open('config.yaml', 'w') as yaml_file:\n    yaml.dump(config, yaml_file)"
        }
      ],
      "id": "Gyt1iP24",
      "createdAt": 1705649805191,
      "updatedAt": 1705649964517
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "ruemal.yaml",
      "content": [
        {
          "label": "read",
          "language": "plain_text",
          "value": "from ruamel.yaml import YAML\nyaml=YAML(typ='safe')\nwith open('conf.yaml', 'r') as yaml_file:\n\tconf = yaml.load(yaml_file)"
        },
        {
          "label": "write",
          "language": "plain_text",
          "value": "import ruemal.yaml\n\n# 创建配置字典\nconfig = {\n    'database': {\n        'host': 'localhost',\n        'port': 5432,\n        'name': 'mydb'\n    },\n    'app': {\n        'debug': True,\n        'log_level': 'info'\n    }\n}\n\n# 写入 YAML 文件\nwith open('config.yaml', 'w') as yaml_file:\n    ruemal.yaml.dump(config, yaml_file)"
        }
      ],
      "id": "veB74x97",
      "createdAt": 1705649919184,
      "updatedAt": 1705827167283
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "argparse",
      "content": [
        {
          "label": "basic",
          "language": "plain_text",
          "value": "import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--verbose\", help=\"increase output verbosity\",\n                    action=\"store_true\")\nargs = parser.parse_args()"
        },
        {
          "label": "list",
          "language": "python",
          "value": "import argparse\n \nparser = argparse.ArgumentParser()\n \n# By default it will fail with multiple arguments.\nparser.add_argument('--default')\n \n# Telling the type to be a list will also fail for multiple arguments,\n# but give incorrect results for a single argument.\nparser.add_argument('--list-type', type=list)\n \n# This will allow you to provide multiple arguments, but you will get\n# a list of lists which is not desired.\nparser.add_argument('--list-type-nargs', type=list, nargs='+')\n \n# This is the correct way to handle accepting multiple arguments.\n# '+' == 1 or more.\n# '*' == 0 or more.\n# '?' == 0 or 1.\n# An int is an explicit number of arguments to accept.\nparser.add_argument('--nargs', nargs='+')\n \n# To make the input integers\nparser.add_argument('--nargs-int-type', nargs='+', type=int)\n \n# An alternate way to accept multiple inputs, but you must\n# provide the flag once per input. Of course, you can use\n# type=int here if you want.\nparser.add_argument('--append-action', action='append')\n \n# To show the results of the given option to screen.\nfor _, value in parser.parse_args()._get_kwargs():\n    if value is not None:\n        print(value)\n        \n        \n\"\"\"\n$ python arg.py --default 1234 2345 3456 4567\n...\narg.py: error: unrecognized arguments: 2345 3456 4567\n \n$ python arg.py --list-type 1234 2345 3456 4567\n...\narg.py: error: unrecognized arguments: 2345 3456 4567\n \n$ # Quotes won't help here... \n$ python arg.py --list-type \"1234 2345 3456 4567\"\n['1', '2', '3', '4', ' ', '2', '3', '4', '5', ' ', '3', '4', '5', '6', ' ', '4', '5', '6', '7']\n$ python arg.py --list-type-nargs 1234 2345 3456 4567\n[['1', '2', '3', '4'], ['2', '3', '4', '5'], ['3', '4', '5', '6'], ['4', '5', '6', '7']]\n$ python arg.py --nargs 1234 2345 3456 4567\n['1234', '2345', '3456', '4567']\n$ python arg.py --nargs-int-type 1234 2345 3456 4567\n[1234, 2345, 3456, 4567]\n$ # Negative numbers are handled perfectly fine out of the box.\n$ python arg.py --nargs-int-type -1234 2345 -3456 4567\n[-1234, 2345, -3456, 4567]\n$ python arg.py --append-action 1234 --append-action 2345 --append-action 3456 --append-action 4567\n\"\"\""
        }
      ],
      "id": "UP1uoVQH",
      "createdAt": 1705650796734,
      "updatedAt": 1724577088639
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "NCg2YrWJ",
      "tagsIds": [],
      "description": null,
      "name": "nvidia-smi",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "// 调整gpu持久性模式\nsudo nvidia-smi -pm 1\n// 调整gpu最大功率\nsudo nvidia-smi -pl 300"
        }
      ],
      "id": "26X8AOSD",
      "createdAt": 1705655898703,
      "updatedAt": 1705655972195
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "fA481292",
      "tagsIds": [],
      "description": null,
      "name": "http MIME",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "Multipurpose lnternet Mail Extensions:\n\nhtml: text/html\ncss: text/css\njs: text/javascript\npng: image/png\njpg: image/jpeg\ngif: image/gif\nmp4: video/mp4'\nmp3: audio/mpeg\njson: application/json"
        }
      ],
      "id": "HnMsiaZI",
      "createdAt": 1705739861641,
      "updatedAt": 1705740021013
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "jupyter",
      "content": [
        {
          "label": "reload",
          "language": "plain_text",
          "value": "%load_ext autoreload\n%autoreload 2"
        },
        {
          "label": "plot",
          "language": "python",
          "value": "%matplotlib inline"
        }
      ],
      "id": "Wry74Dzx",
      "createdAt": 1705886423955,
      "updatedAt": 1711760156929
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Path",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "file = Path('/root/data/voc.yaml')\nfile.stem => 'voc'"
        }
      ],
      "id": "5e0YC450",
      "createdAt": 1706190040944,
      "updatedAt": 1706190107535
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "supression warning",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "import warnings\n\nwarnings.filterwarnings('ignore')\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)"
        }
      ],
      "id": "8qlwmnmh",
      "createdAt": 1706193575402,
      "updatedAt": 1715651037810
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "numpy",
      "content": [
        {
          "label": "dim+",
          "language": "plain_text",
          "value": "ann = np.expand_dims(ann,0)"
        },
        {
          "label": "min-max",
          "language": "plain_text",
          "value": "np.clip(a, 1, 8)"
        },
        {
          "label": "eu dist",
          "language": "python",
          "value": "def euclidean_distance(u, v):\n    \"\"\"\n    Returns the euclidean distance between vectors u and v. This is equivalent\n    to the length of the vector (u - v).\n    \"\"\"\n    diff = u - v\n    # return sqrt(numpy.dot(diff, diff.T))\n    return np.sum(np.diag(np.sqrt(np.dot(diff, diff.T))))"
        },
        {
          "label": "diag",
          "language": "plain_text",
          "value": "x=np.array([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\nnp.diag(x) => array([0, 4, 8])"
        }
      ],
      "id": "ZhL1nAet",
      "createdAt": 1706504886238,
      "updatedAt": 1706580864691
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "matplotlib",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# matplotlib折线图（标记点、标记点大小、标记点边颜色、标记点边宽\nfrom matplotlib import pyplot as plt\nx = range(1,10) #x轴的位置\ny = [6,7,12,12,15,17,15,20,18] #y轴的位置\n#传入x,y，通过plot画图,并设置折线颜色、透明度、折线样式和折线宽度  标记点、标记点大小、标记点边颜色、标记点边宽\nplt.plot(x,y,color='red',alpha=0.3,linestyle='--',linewidth=5,marker='o'\n         ,markeredgecolor='r',markersize='20',markeredgewidth=10)\nplt.show()\n"
        }
      ],
      "id": "ZKxV4l_b",
      "createdAt": 1706538922876,
      "updatedAt": 1706538967381
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "torch",
      "content": [
        {
          "label": "cuda cache",
          "language": "plain_text",
          "value": "torch.cuda.empty_cache()"
        },
        {
          "label": "ddp",
          "language": "python",
          "value": "import torch\nimport torch.nn.functional as F\nfrom utils import MyTrainDataset\n\nimport torch.multiprocessing as mp\nimport torch.distributed as dist\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.distributed import init_process_group, destroy_process_group, get_rank\nimport os\n\nLOCAL_RANK = int(\n    os.getenv(\"LOCAL_RANK\", -1)\n)  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\n\ndef ddp_setup(rank: int, world_size: int):\n    \"\"\"\n    Args:\n        rank: Unique identifier of each process\n    world_size: Total number of processes\n    \"\"\"\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"12355\"\n    torch.cuda.set_device(rank)\n    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n\n    train_data = torch.utils.data.DataLoader(\n        dataset=train_dataset,\n        batch_size=32,\n        shuffle=False,\n        sampler=DistributedSampler(train_dataset),\n    )\n\ndef _run_epoch(self, epoch):\n    b_sz = len(next(iter(self.train_data))[0])\n    self.train_data.sampler.set_epoch(epoch)\n    for source, targets in self.train_data:\n        ...\n        self._run_batch(source, targets)\n\ndef save_model(model, epoch, save_every):\n    def _save_checkpoint(ckp):\n        ...\n        pass\n\n    ckp = model.module.state_dict()\n    ...\n    ...\n    if get_rank() == 0 and epoch % save_every == 0:\n        _save_checkpoint(ckp)\n    \n    dist.barrier()\n    return\n\ndef main(rank, world_size, total_epochs, save_every):\n    ddp_setup(rank, world_size)\n    dataset, model, optimizer = load_train_objs()\n    train_data = prepare_dataloader(dataset, batch_size=32)\n    trainer = Trainer(model, train_data, optimizer, rank, save_every)\n    trainer.train(total_epochs)\n    destroy_process_group()\n\nif __name__ == \"__main__\":\n    import sys\n    total_epochs = int(sys.argv[1])\n    save_every = int(sys.argv[2])\n    world_size = WORLD_SIZE\n    mp.spawn(main, args=(LOCAL_RANK, world_size, total_epochs, save_every,), nprocs=world_size)"
        }
      ],
      "id": "iUBzP4mv",
      "createdAt": 1706543184905,
      "updatedAt": 1725934447395
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "@thread",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "def threaded(func):\n    \"\"\"\n    Multi-threads a target function by default and returns the thread or function result.\n\n    Use as @threaded decorator. The function runs in a separate thread unless 'threaded=False' is passed.\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        \"\"\"Multi-threads a given function based on 'threaded' kwarg and returns the thread or function result.\"\"\"\n        if kwargs.pop(\"threaded\", True):  # run in thread\n            thread = threading.Thread(target=func, args=args, kwargs=kwargs, daemon=True)\n            thread.start()\n            return thread\n        else:\n            return func(*args, **kwargs)\n\n    return wrapper"
        }
      ],
      "id": "CBAeSmOT",
      "createdAt": 1706544304341,
      "updatedAt": 1706544314752
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "multiprocessing",
      "content": [
        {
          "label": "apply_async",
          "language": "plain_text",
          "value": "#apply  (阻塞，同步方式)\nfrom  multiprocessing import Pool\nimport time\n \n#apply_async   (非阻塞，异步方式)\ndef f1(i):\n    time.sleep(0.5)\n    print(i)\n    return i + 100\ndef f2(arg):\n    print(arg)\n \nif __name__ == \"__main__\":\n    pool = Pool(5)\n    for i in range(1,31):\n        pool.apply_async(func=f1,args=(i,),callback=f2)\n    pool.close()\n    pool.join()\n"
        },
        {
          "label": "cpu_count",
          "language": "plain_text",
          "value": "from multiprocessing import cpu_count\n\nprint(\"CPU的核数为：{}\".format(cpu_count()))\nprint(type(cpu_count()))"
        },
        {
          "label": "submit",
          "language": "plain_text",
          "value": "from concurrent.futures import ProcessPoolExecutor\nimport  time\ndef task(name):\n    print(\"name\",name)\n    time.sleep(1)\n\nif __name__ == \"__main__\":\n    start = time.time()\n    ex = ProcessPoolExecutor(2)\n\n    for i in range(5):\n        ex.submit(task,\"safly%d\"%i)\n    ex.shutdown(wait=True)\n\n    print(\"main\")\n    end = time.time()\n    print(end - start)"
        },
        {
          "label": "map",
          "language": "plain_text",
          "value": "from multiprocessing import Pool\n\ndef f(x):\n    return x*x\n\nif __name__ == '__main__':\n    with Pool(5) as p:\n        print(p.map(f, [1, 2, 3]))"
        },
        {
          "label": "apply",
          "language": "plain_text",
          "value": "#apply  (阻塞，同步方式)\nfrom  multiprocessing import Pool\nimport time\n \ndef f1(i):\n    time.sleep(0.5)\n    print(i)\n    return i + 100\n \nif __name__ == \"__main__\":\n    pool = Pool(5)\n    for i in range(1,31):\n        pool.apply(func=f1,args=(i,))"
        },
        {
          "label": "imap",
          "language": "python",
          "value": "from tqdm import tqdm    \nfrom torch.multiprocessing import Pool\n\nwith Pool(15) as pool:\n    results = pool.imap(func=get_image_sm, iterable=zip(repeat(path), image_list))\n    pbar = tqdm(results, desc=\"calc\", total=len(image_list))\n    for result in pbar:\n        if isinstance(result, tuple):\n            img_count += 1\n            mean += result[0]\n            std += result[1]\n            pbar.set_postfix({\"mean\": mean / img_count, \"std\": std / img_count})\n        else:\n            print(result)\n    pbar.close()"
        }
      ],
      "id": "CUsUEUiX",
      "createdAt": 1706577534588,
      "updatedAt": 1724908222026
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "concurrent",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed, wait, ALL_COMPLETED\nimport time, random, os\n\ndef piao(name, n):\n    print('%s is piaoing %s' % (name, os.getpid()))\n    time.sleep(1)\n    return n ** 2\n\n\nif __name__ == '__main__':\n\t\t########################################\n    p = ProcessPoolExecutor(2)\n    objs = []\n    start = time.time()\n    for i in range(5):\n        obj = p.submit(piao, 'safly %s' % i, i)  # 异步调用\n        objs.append(obj)\n\n    p.shutdown(wait=True)\n    print('主', os.getpid())\n    for obj in objs:\n        print(obj.done())\n        print(obj.result(timeout=None))\n\n    stop = time.time()\n    print(stop - start)\n\t\t########################################\n    p = ThreadPoolExecutor(2)\n    objs = []\n    start = time.time()\n    for i in range(5):\n        obj = p.submit(piao, '%s' % i, i)  # 异步调用\n        objs.append(obj)\n\n    print('主', os.getpid())\n    for obj in as_completed(objs):\n        print(obj.result())\n\t\t########################################\n    p = ThreadPoolExecutor(2)\n    objs = []\n    start = time.time()\n    for i in range(5):\n        obj = p.submit(piao, '%s' % i, i)  # 异步调用\n        objs.append(obj)\n\n    print('主', os.getpid())\n    wait(objs, return_when=ALL_COMPLETED)\n    for obj in objs:\n        print(obj.done())\n        print(obj.result(timeout=None))\n\n    stop = time.time()\n    print(stop - start)\n    p.shutdown(wait=True)"
        }
      ],
      "id": "v00hMsQs",
      "createdAt": 1706578242881,
      "updatedAt": 1727002786295
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "未命名程式碼片段",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": ""
        }
      ],
      "id": "RYf5I8fv",
      "createdAt": 1706580332307,
      "updatedAt": 1706580336957
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "OtjZFwbc",
      "tagsIds": [],
      "description": null,
      "name": "guard process",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "var fork = require('child_process').fork;\n\n//保存被子进程实例数组\nvar workers = [];\n\n//这里的被子进程理论上可以无限多\nvar appsPath = ['./app.js'];\n\nvar createWorker = function(appPath){\n　　//保存fork返回的进程实例\n　　var worker = fork(appPath);\n\n　　//监听子进程exit事件\n　　worker.on('exit',function(){\n　　　　console.log('worker:' + worker.pid + 'exited');\n　　　　delete workers[worker.pid];\n　　　　createWorker(appPath);\n　　 });\n\n　　workers[worker.pid] = worker;\n　　console.log('Create worker:' + worker.pid);\n};\n\n//启动所有子进程\nfor (var i = appsPath.length - 1; i >= 0; i--) {\n　　createWorker(appsPath[i]);\n}\n\n//父进程退出时杀死所有子进程\nprocess.on('exit',function(){\n　　 for(var pid in workers){\n　　　　workers[pid].kill();\n　　}\n});"
        }
      ],
      "id": "24sDH8Hh",
      "createdAt": 1706666147942,
      "updatedAt": 1706666155658
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "pickle",
      "content": [
        {
          "label": "dump",
          "language": "plain_text",
          "value": "with open('data.pickle', 'wb') as f:\n    pickle.dump(data, f)"
        },
        {
          "label": "dumps",
          "language": "plain_text",
          "value": "import pickle\ndic = {\"k1\":\"v1\",\"k2\":123}\ns = pickle.dumps(dic)\nprint(s)"
        },
        {
          "label": "load",
          "language": "plain_text",
          "value": "with open('data.pickle', 'rb') as f:\n    data = pickle.load(f)"
        },
        {
          "label": "loads",
          "language": "plain_text",
          "value": "import pickle\ndic = {\"k1\":\"v1\",\"k2\":123}\ns = pickle.dumps(dic)\ndic2 = pickle.loads(s)\nprint(dic2)"
        }
      ],
      "id": "gw3WAZqO",
      "createdAt": 1708936622268,
      "updatedAt": 1708936691956
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "progress",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# coding=utf-8\nfrom progress.bar import Bar\nimport time\n\n# 创建Bar类的实例\nbar = Bar('MyProcess:', max=100)\n# 循环处理某业务，调用bar对象的next()方法，循环次数等于max\nfor _ in range(100):\n # Do some work\n    time.sleep(0.05)\n    bar.next()\n# 循环完成后调用finish()方法\nbar.finish()\n\n\nwith Bar('Processing', max=20) as bar:\n    for i in range(20):\n        time.sleep(0.05)\n        bar.next()\n        \nfor i in Bar(\n    \t\tf\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(range(100)):\n    time.sleep(0.05)"
        }
      ],
      "id": "54MBrGJN",
      "createdAt": 1709098599140,
      "updatedAt": 1709989377044
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "get_VOC_ds",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import xml.etree.ElementTree as ET\n\nfrom tqdm import tqdm\nfrom ultralytics.utils.downloads import download\nfrom pathlib import Path\nimport yaml as yl\nimport numpy as np\nimport copy\nfrom progress.bar import Bar\nimport os\nimport subprocess\n\nwith open(\"voc.yaml\", \"r\", encoding=\"utf8\") as f:\n    yaml = yl.safe_load(f)\n\n\ndef convert_label(path, lb_path, year, image_id, tho=0, class_filter=None):\n    def convert_box(size, box):\n        dw, dh = 1.0 / size[0], 1.0 / size[1]\n        x, y, w, h = (\n            (box[0] + box[1]) / 2.0 - 1,\n            (box[2] + box[3]) / 2.0 - 1,\n            box[1] - box[0],\n            box[3] - box[2],\n        )\n        return x * dw, y * dh, w * dw, h * dh\n\n    in_file = open(path / f\"VOC{year}/Annotations/{image_id}.xml\")\n    out_file = open(lb_path, \"w\")\n    tree = ET.parse(in_file)\n    root = tree.getroot()\n    size = root.find(\"size\")\n    w = int(size.find(\"width\").text)\n    h = int(size.find(\"height\").text)\n\n    names = list(yaml[\"names\"].values())  # names list\n    for obj in root.iter(\"object\"):\n        cls = obj.find(\"name\").text\n        if cls in names and int(obj.find(\"difficult\").text) != 1:\n            xmlbox = obj.find(\"bndbox\")\n            bb = convert_box(\n                (w, h),\n                [float(xmlbox.find(x).text) for x in (\"xmin\", \"xmax\", \"ymin\", \"ymax\")],\n            )\n            cls_id = names.index(cls)  # class id\n            if class_filter:\n                if class_filter(cls_id):\n                    out_file.write(\" \".join(str(a) for a in (cls_id, *bb)) + \"\\n\")\n            else:\n                if np.random.random() >= tho:\n                    out_file.write(\" \".join(str(a) for a in (cls_id, *bb)) + \"\\n\")\n                else:\n                    out_file.write(\" \".join(str(a) for a in (0, *bb)) + \"\\n\")\n\n\n# Download\ndir = Path(yaml[\"path\"])  # dataset root dir\n# url = 'https://mirror.ghproxy.com/github.com/ultralytics/yolov5/releases/download/v1.0/'\nurl = \"https://github.com/ultralytics/yolov5/releases/download/v1.0/\"\nurls = [\n    f\"{url}VOCtrainval_06-Nov-2007.zip\",  # 446MB, 5012 images\n    f\"{url}VOCtest_06-Nov-2007.zip\",  # 438MB, 4953 images\n    f\"{url}VOCtrainval_11-May-2012.zip\",\n]  # 1.95GB, 17126 images\n# download(\n#     urls,\n#     dir=dir / \"images\",\n#     curl=True,\n#     threads=1,\n#     exist_ok=True,\n# )  # download and unzip over existing paths (required)\n\n# Convert origin\ndir = Path(yaml[\"path\"]) / \"origin\"\nos.makedirs(dir, exist_ok=True)\nsubprocess.run(\n    [\n        \"rsync\",\n        \"-auvrt\",\n        str((Path(yaml[\"path\"]) / \"images\").absolute()),\n        str(dir.absolute()),\n    ]\n)\npath = dir / \"images/VOCdevkit\"\nfor year, image_set in (\n    (\"2012\", \"train\"),\n    (\"2012\", \"val\"),\n    (\"2007\", \"train\"),\n    (\"2007\", \"val\"),\n    (\"2007\", \"test\"),\n):\n    imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n    lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n    imgs_path.mkdir(exist_ok=True, parents=True)\n    lbs_path.mkdir(exist_ok=True, parents=True)\n\n    with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n        image_ids = f.read().strip().split()\n    for id in Bar(\n        f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(image_ids):\n        f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n        lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n        f.rename(imgs_path / f.name)  # move image\n        convert_label(path, lb_path, year, id)  # convert labels to YOLO format\n    new_yaml = copy.deepcopy(yaml)\n    new_yaml[\"path\"] = dir.absolute()\n    with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n        yl.dump(new_yaml, yaml_file)\n\n# Convert zen obj\ndir = Path(yaml[\"path\"]) / \"obj\"  # dataset root dir\nos.makedirs(dir, exist_ok=True)\nsubprocess.run(\n    [\n        \"rsync\",\n        \"-auvrt\",\n        str((Path(yaml[\"path\"]) / \"images\").absolute()),\n        str(dir.absolute()),\n    ]\n)\npath = dir / \"images/VOCdevkit\"\nfor year, image_set in (\n    (\"2012\", \"train\"),\n    (\"2012\", \"val\"),\n    (\"2007\", \"train\"),\n    (\"2007\", \"val\"),\n    (\"2007\", \"test\"),\n):\n    imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n    lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n    imgs_path.mkdir(exist_ok=True, parents=True)\n    lbs_path.mkdir(exist_ok=True, parents=True)\n\n    with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n        image_ids = f.read().strip().split()\n    for id in Bar(\n        f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(image_ids):\n        f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n        lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n        f.rename(imgs_path / f.name)  # move image\n        convert_label(path, lb_path, year, id, tho=1)  # convert labels to YOLO format\n    new_yaml = copy.deepcopy(yaml)\n    new_yaml[\"path\"] = dir.absolute()\n    new_yaml[\"names\"] = {0: \"unknown object\"}\n    for i in range(len(yaml[\"names\"])):\n        new_yaml[i + 1] = yaml[\"names\"][i]\n    with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n        yl.dump(new_yaml, yaml_file)\n\n# Convert han obj\ndir = Path(yaml[\"path\"]) / \"obj_50pa\"  # dataset root dir\nos.makedirs(dir, exist_ok=True)\nsubprocess.run(\n    [\n        \"rsync\",\n        \"-auvrt\",\n        str((Path(yaml[\"path\"]) / \"images\").absolute()),\n        str(dir.absolute()),\n    ]\n)\npath = dir / \"images/VOCdevkit\"\nfor year, image_set in (\n    (\"2012\", \"train\"),\n    (\"2012\", \"val\"),\n    (\"2007\", \"train\"),\n    (\"2007\", \"val\"),\n    (\"2007\", \"test\"),\n):\n    imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n    lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n    imgs_path.mkdir(exist_ok=True, parents=True)\n    lbs_path.mkdir(exist_ok=True, parents=True)\n\n    with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n        image_ids = f.read().strip().split()\n    for id in Bar(\n        f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(image_ids):\n        f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n        lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n        f.rename(imgs_path / f.name)  # move image\n        convert_label(path, lb_path, year, id, tho=0.5)  # convert labels to YOLO format\n    new_yaml = copy.deepcopy(yaml)\n    new_yaml[\"path\"] = dir.absolute()\n    new_yaml[\"names\"] = {0: \"unknown object\"}\n    for i in range(len(yaml[\"names\"])):\n        new_yaml[i + 1] = yaml[\"names\"][i]\n    with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n        yl.dump(new_yaml, yaml_file)\n\n# Convert continous learning dataset\nclass_stage = [[0, 6], [6, 13], [13, 20]]\nfor i, j in class_stage:\n    class_filter_testval = lambda x: x < j\n    class_filter_train = lambda x: x >= i and x < j\n    dir = Path(yaml[\"path\"]) / f\"split_{i}_{j}\"  # dataset root dir\n    os.makedirs(dir, exist_ok=True)\n    subprocess.run(\n        [\n            \"rsync\",\n            \"-auvrt\",\n            str((Path(yaml[\"path\"]) / \"images\").absolute()),\n            str(dir.absolute()),\n        ]\n    )\n    path = dir / \"images/VOCdevkit\"\n    for year, image_set in (\n        (\"2012\", \"train\"),\n        (\"2012\", \"val\"),\n        (\"2007\", \"train\"),\n        (\"2007\", \"val\"),\n        (\"2007\", \"test\"),\n    ):\n        imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n        lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n        imgs_path.mkdir(exist_ok=True, parents=True)\n        lbs_path.mkdir(exist_ok=True, parents=True)\n\n        with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n            image_ids = f.read().strip().split()\n\n        for id in Bar(\n            f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n        ).iter(image_ids):\n            f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n            lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n            f.rename(imgs_path / f.name)  # move image\n            convert_label(\n                path,\n                lb_path,\n                year,\n                id,\n                class_filter=(\n                    class_filter_testval if image_set == \"test\" else class_filter_train\n                ),\n            )  # convert labels to YOLO format\n        new_yaml = copy.deepcopy(yaml)\n        new_yaml[\"path\"] = dir.absolute()\n        new_yaml[\"names\"] = {}\n        for ii in range(j):\n            new_yaml[ii] = yaml[\"names\"][ii]\n        with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n            yl.dump(new_yaml, yaml_file)\n"
        }
      ],
      "id": "SRdwFBY0",
      "createdAt": 1709358035263,
      "updatedAt": 1724662697548
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "NCg2YrWJ",
      "tagsIds": [],
      "description": null,
      "name": "shell echo font",
      "content": [
        {
          "label": "color",
          "language": "plain_text",
          "value": "字体颜色\n字体颜色：30-37\n\n默认=0\n黑色=30\n红色=31\n绿色=32\n黄色=33\n蓝色=34\n紫色=35\n天蓝色（青色）=36\n白色=37\n# echo -e \"\\e[30m 黑色 \\e[0m\"\n# echo -e \"\\e[31m 红色 \\e[0m\"\n# echo -e \"\\e[32m 绿色 \\e[0m\"\n# echo -e \"\\e[33m 黄色 \\e[0m\"\n# echo -e \"\\e[34m 蓝色 \\e[0m\"\n# echo -e \"\\e[35m 紫色 \\e[0m\"\n# echo -e \"\\e[36m 青色 \\e[0m\"\n# echo -e \"\\e[37m 白色 \\e[0m\"\n\n背景颜色\n背景颜色：40-47\n\n默认=0\n黑色=40\n红色=41\n绿色=42\n黄色=43\n蓝色=44\n紫色=45\n天蓝色（青色）=46\n白色=47\n# echo -e \"\\e[40m 黑底 \\e[0m\"\n# echo -e \"\\e[41m 红底 \\e[0m\"\n# echo -e \"\\e[42m 绿底 \\e[0m\"\n# echo -e \"\\e[43m 黄底 \\e[0m\"\n# echo -e \"\\e[44m 蓝底 \\e[0m\"\n# echo -e \"\\e[45m 紫底 \\e[0m\"\n# echo -e \"\\e[46m 青底 \\e[0m\"\n# echo -e \"\\e[47m 白底 \\e[0m\"\n\n黑底彩色\n黑底彩色：90-97\n\n黑=90\n深红=91\n绿=92\n黄色=93\n蓝色=94\n紫色=95\n深绿（青色）=96\n白色=97\n# echo -e \"\\e[90m 黑底黑字 \\e[0m\"\n# echo -e \"\\e[91m 黑底红字 \\e[0m\"\n# echo -e \"\\e[92m 黑底绿字 \\e[0m\"\n# echo -e \"\\e[93m 黑底黄字 \\e[0m\"\n# echo -e \"\\e[94m 黑底蓝字 \\e[0m\"\n# echo -e \"\\e[95m 黑底紫字 \\e[0m\"\n# echo -e \"\\e[96m 黑底青字 \\e[0m\"\n# echo -e \"\\e[97m 黑底白字 \\e[0m\"\n\n## 字体控制选项\n\\e[0m 关闭所有属性\n\\e[1m 设置高亮度\n\\e[4m 下划线\n\\e[5m 闪烁\n\\e[7m 反显，撞色显示，显示为白字黑底，或者显示为黑底白字\n\\e[8m 消影，字符颜色将会与背景颜色相同\n\\e[nA 光标上移 n 行\n\\e[nB 光标下移 n 行\n\\e[nC 光标右移 n 行\n\\e[nD 光标左移 n 行\n\\e[y;xH 设置光标位置\n\\e[2J 清屏\n\\e[K 清除从光标到行尾的内容\n\\e[s 保存光标位置\n\\e[u 恢复光标位置\n\\e[?25 隐藏光标\n\\e[?25h 显示光标"
        },
        {
          "label": "子片段 2",
          "language": "plain_text",
          "value": ""
        }
      ],
      "id": "blnb3Iy1",
      "createdAt": 1709523344717,
      "updatedAt": 1709523454756
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "NCg2YrWJ",
      "tagsIds": [],
      "description": null,
      "name": "tput",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "tput Color Capabilities:\n\ntput setab [0-7] – Set a background color using ANSI escape\ntput setb [0-7] – Set a background color\ntput setaf [0-7] – Set a foreground color using ANSI escape\ntput setf [0-7] – Set a foreground color\n\nColor Code for tput:\n\n0 – Black\n1 – Red\n2 – Green\n3 – Yellow\n4 – Blue\n5 – Magenta\n6 – Cyan\n7 – White\n\ntput Text Mode Capabilities:\n\ntput bold – Set bold mode\ntput dim – turn on half-bright mode\ntput smul – begin underline mode\ntput rmul – exit underline mode\ntput rev – Turn on reverse mode\ntput smso – Enter standout mode (bold on rxvt)\ntput rmso – Exit standout mode\ntput sgr0 – Turn off all attributes"
        },
        {
          "label": "子片段 2",
          "language": "sh",
          "value": "#!/bin/bash\n\nprintf $(tput setaf 2; tput bold)'color show\\n\\n'$(tput sgr0)\n\nfor((i=0; i<=7; i++)); do\n\techo $(tput setaf $i)\"show me the money\"$(tput sgr0)\ndone\n\nprintf '\\n'$(tput setaf 2; tput setab 0; tput bold)'background color show'$(tput sgr0)'\\n\\n'\n\nfor((i=0,j=7; i<=7; i++,j--)); do\n\techo $(tput setaf $i; tput setab $j; tput bold)\"show me the money\"$(tput sgr0)\ndone\n\nexit 0\n"
        }
      ],
      "id": "rl2tSchb",
      "createdAt": 1709523474208,
      "updatedAt": 1709526826833
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "RxpfS9zV",
      "tagsIds": [],
      "description": null,
      "name": "遍历数组",
      "content": [
        {
          "label": "子片段 1",
          "language": "typescript",
          "value": "/*TypeScript继承自JavaScript，因此可以使用JavaScript中的所有数组遍历方法，包括：\n\nfor循环\n可以使用传统的for循环遍历数组。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nfor (let i = 0; i < arr.length; i++) {\n  console.log(arr[i]);\n}\n/*forEach()方法\n可以使用forEach()方法遍历数组，它接受一个回调函数作为参数，回调函数接受三个参数：当前元素的值、当前元素的索引和数组本身。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\narr.forEach((value, index, array) => {\n  console.log(value);\n});\n/*map()方法\n可以使用map()方法遍历数组，它接受一个回调函数作为参数，回调函数返回一个新的数组，新数组的元素是根据原数组的元素经过处理后得到的。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nconst newArr = arr.map((value, index, array) => {\n  return value * 2;\n});\n\nconsole.log(newArr);\n/*filter()方法\n可以使用filter()方法遍历数组，它接受一个回调函数作为参数，回调函数返回一个布尔值，表示当前元素是否应该被包含在新的数组中。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nconst filteredArr = arr.filter((value, index, array) => {\n  return value % 2 === 0;\n});\n\nconsole.log(filteredArr);\n/*reduce()方法\n可以使用reduce()方法遍历数组，它接受一个回调函数作为参数，回调函数接受四个参数：累加器、当前元素的值、当前元素的索引和数组本身。回调函数返回的值作为下一次调用回调函数的累加器的值。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nconst sum = arr.reduce((accumulator, currentValue, currentIndex, array) => {\n  return accumulator + currentValue;\n}, 0);\n\nconsole.log(sum);\n/*还有其他一些数组遍历方法，如some()、every()、find()、findIndex()等，它们的使用方法与上述方法类似，根据实际需求选择适合的方法即可。*/"
        }
      ],
      "id": "_qQRFf4S",
      "createdAt": 1709687898236,
      "updatedAt": 1709687973606
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "lxml",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "from lxml import etree\n\nroot=etree.Element('root')\nprint(root.tag)\nchild=etree.SubElement(root,'child') # 添加一个子节点\nchild.set('id','test_Id')\nprint(etree.tostring(root))          # tostring 为序列化"
        },
        {
          "label": "xpath",
          "language": "python",
          "value": "from lxml import etree\n\nhtml = etree.parse('./test.html', etree.HTMLParser())\nresult = etree.tostring(html)\nprint(result.decode('utf-8'))"
        }
      ],
      "id": "sVMMZEu2",
      "createdAt": 1709787008159,
      "updatedAt": 1710954937124
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "snowflake",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# pip install snowflake-id\nfrom snowflake import SnowflakeGenerator\n\ngen = SnowflakeGenerator(42)\n\nfor i in range(100):\n    val = next(gen)\n    print(val)"
        }
      ],
      "id": "izjU0ZO0",
      "createdAt": 1710000893638,
      "updatedAt": 1710000948908
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Process",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# 导入进程模块\nimport multiprocessing\n \n# 最多允许3个进程同时运行\npool = multiprocessing.Pool(processes = 3)\n \n1、apply() — 该函数用于传递不定参数，主进程会被阻塞直到函数执行结束（不建议使用，并且3.x以后不在出现），函数原型如下：\n\napply(func, args=(), kwds={})\n2、apply_async — 与apply用法一致，但它是非阻塞的且支持结果返回后进行回调，函数原型如下：\n\napply_async(func[, args=()[, kwds={}[, callback=None]]])\n3、map() — Pool类中的map方法，与内置的map函数用法基本一致，它会使进程阻塞直到结果返回，函数原型如下：\n\nmap(func, iterable, chunksize=None)\n注意：虽然第二个参数是一个迭代器，但在实际使用中，必须在整个队列都就绪后，程序才会运行子进程。\n\n4、map_async() — 与map用法一致，但是它是非阻塞的。其有关事项见apply_async，函数原型如下：\n\nmap_async(func, iterable, chunksize, callback)\n5、close() — 关闭进程池（pool），使其不在接受新的任务。\n\n6、terminal() — 结束工作进程，不在处理未处理的任务。\n\n7、join() — 主进程阻塞等待子进程的退出， join方法要在close或terminate之后使用。"
        }
      ],
      "id": "lapLuKwb",
      "createdAt": 1710003507218,
      "updatedAt": 1710003515804
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "sqlite3",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import sqlite3\ncon = sqlite3.connect(\"tutorial.db\")\n\ncur = con.cursor()\ncur.execute(\"CREATE TABLE movie(title, year, score)\")\nres = cur.execute(\"SELECT name FROM sqlite_master\")\nres.fetchone()"
        }
      ],
      "id": "jftvFjm0",
      "createdAt": 1710206891856,
      "updatedAt": 1710206929164
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "HRD2NCV8",
      "tagsIds": [],
      "description": null,
      "name": "gpupdate /force",
      "content": [
        {
          "label": "子片段 1",
          "language": "powershell",
          "value": "gpupdate /force"
        }
      ],
      "id": "59rdBTM8",
      "createdAt": 1711067467424,
      "updatedAt": 1711067493810
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "glob",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import glob\n\n1、返回目录的路径列表\n\npath_list1 = glob.glob('./test_dir/')\n\npath_list2 = glob.glob('./test_dir/*')\n\npath_list3 = glob.glob('./test_dir/*.py')\n\npath_list4 = glob.glob('./test_dir/*/*.py')\n\npath_list5 = glob.glob('./test_dir/**', recursive=True)\n\npath_list6 = glob.glob('./test_dir/**/*.py', recursive=True)"
        }
      ],
      "id": "Ld88RgtY",
      "createdAt": 1715163051153,
      "updatedAt": 1715163101262
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "4ojt5eME",
      "tagsIds": [],
      "description": null,
      "name": "dijkstra",
      "content": [
        {
          "label": "子片段 1",
          "language": "c_cpp",
          "value": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint inf = 999999;//不连通的点之间的距离设为无穷大\nlong long int e[10000][10000];\nint dis[10000];//最短距离数组\nint book[10000];//记录下哪些点被选中\n\n//计算单点到全部顶点的距离\nint Dijkstra(int &n, int &m, int &s, vector<vector<int>> &data, int &t)\n{\n\t//初始化任意两点之间的距离数组\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t{\n\t\t\tif (i == j)\n\t\t\t\te[i][j] = 0;\n\t\t\telse\n\t\t\t\te[i][j] = inf;\n\t\t}\n\t}\n\t//把权值加入到任意两点之间的距离数组中\n\tfor (int i = 1; i <= m; ++i)\n\t{\n\t\te[data[i - 1][0]][data[i - 1][1]] = data[i - 1][2];\n\t}\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tif (i != s)\n\t\t{\n\t\t\tdis[i] = e[s][i];//记录源点到其余所有点的最短路径\n\t\t\tbook[i] = 0;//记录哪些点被选取了\n\t\t}\n\t}\n\tint u, min;\n\tfor (int i = 1; i <= n - 1; ++i)\n\t{\n\t\tmin = inf;\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t{\n\t\t\tif (book[j] == 0 && dis[j] < min)//找到源点离还没有被选取的点中的最近顶点\n\t\t\t{\n\t\t\t\tmin = dis[j];\n\t\t\t\tu = j;//记录下最近顶点的位置\n\t\t\t}\n\t\t}\n\t\tbook[u] = 1;\n\t\t/*\n\t\t*例如存在一条从u到v的边，那么可以通过将边u->v添加到尾部来拓展一条从源点到v的路径，\n\t\t*这条路径的长度是dis[u]+e[u][v]。如果这个值比目前已知的dis[v]的值要小，\n\t\t*我们可以用新值来替代当前dis[v]中的值。\n\t\t*/\n\t\tfor (int v = 1; v <= n; ++v)\n\t\t{\n\t\t\tif (e[u][v] < inf)\n\t\t\t{\n\t\t\t\tif (dis[v] > dis[u] + e[u][v])\n\t\t\t\t\tdis[v] = dis[u] + e[u][v];//松弛\n\t\t\t}\n\t\t}\n\t}\n\treturn dis[t];\n}"
        }
      ],
      "id": "BaJf5Dyh",
      "createdAt": 1720877663687,
      "updatedAt": 1720877806903
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "4ojt5eME",
      "tagsIds": [],
      "description": null,
      "name": "floyd",
      "content": [
        {
          "label": "子片段 1",
          "language": "c_cpp",
          "value": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint inf = 999999;//不连通的点之间的距离设为无穷大\nlong long int e[10000][10000];\n\n//计算两两顶点之间的最短路径\nvoid Floyd(int &n, int &m, vector<vector<int>> &data)\n{\n\t//初始化任意两点之间的距离数组\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t{\n\t\t\tif (i == j)\n\t\t\t\te[i][j] = 0;\n\t\t\telse\n\t\t\t\te[i][j] = inf;\n\t\t}\n\t}\n\t//把权值加入到任意两点之间的距离数组中\n\tfor (int i = 1; i <= m; ++i)\n\t{\n\t\te[data[i - 1][0]][data[i - 1][1]] = data[i - 1][2];\n\t}\n\t/*\n\t*最开始只允许经过1号顶点进行中转，接下来只允许经过1和2号顶点进行中转……允许经过1~n号所有顶点\n\t*进行中转，求任意两点之间的最短路程。用一句话概括就是：从i号顶点到j号顶点只经过前k号点的最短路程。\n\t*/\n\tfor (int k = 1; k <= n; ++k)\n\t\tfor (int i = 1; i <= n; ++i)\n\t\t\tfor (int j = 1; j <= n; ++j)\n\t\t\t\tif (e[i][j] > e[i][k] + e[k][j])\n\t\t\t\t\te[i][j] = e[i][k] + e[k][j];\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t\tcout << e[i][j] << \" \";\n\t\tcout << endl;\n\t}\n}"
        }
      ],
      "id": "luMgxnlF",
      "createdAt": 1720877674998,
      "updatedAt": 1720877803451
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "4ojt5eME",
      "tagsIds": [],
      "description": null,
      "name": "kruskal & prim",
      "content": [
        {
          "label": "子片段 1",
          "language": "c_cpp",
          "value": "/************************************************************************\nCSDN 勿在浮沙筑高台 http://blog.csdn.net/luoshixian099算法导论--最小生成树（Prim、Kruskal）2016年7月14日\n************************************************************************/\n#include <iostream>\n#include <vector>\n#include <queue>\n#include <algorithm>\nusing namespace std;\n#define INFINITE 0xFFFFFFFF   \n#define VertexData unsigned int  //顶点数据\n#define UINT  unsigned int\n#define vexCounts 6  //顶点数量\nchar vextex[] = { 'A', 'B', 'C', 'D', 'E', 'F' };\nstruct node \n{\n    VertexData data;\n    unsigned int lowestcost;\n}closedge[vexCounts]; //Prim算法中的辅助信息\ntypedef struct \n{\n    VertexData u;\n    VertexData v;\n    unsigned int cost;  //边的代价\n}Arc;  //原始图的边信息\nvoid AdjMatrix(unsigned int adjMat[][vexCounts])  //邻接矩阵表示法\n{\n    for (int i = 0; i < vexCounts; i++)   //初始化邻接矩阵\n        for (int j = 0; j < vexCounts; j++)\n        {\n            adjMat[i][j] = INFINITE;\n        }\n    adjMat[0][1] = 6; adjMat[0][2] = 1; adjMat[0][3] = 5;\n    adjMat[1][0] = 6; adjMat[1][2] = 5; adjMat[1][4] = 3;\n    adjMat[2][0] = 1; adjMat[2][1] = 5; adjMat[2][3] = 5; adjMat[2][4] = 6; adjMat[2][5] = 4;\n    adjMat[3][0] = 5; adjMat[3][2] = 5; adjMat[3][5] = 2;\n    adjMat[4][1] = 3; adjMat[4][2] = 6; adjMat[4][5] = 6;\n    adjMat[5][2] = 4; adjMat[5][3] = 2; adjMat[5][4] = 6;\n}\nint Minmum(struct node * closedge)  //返回最小代价边\n{\n    unsigned int min = INFINITE;\n    int index = -1;\n    for (int i = 0; i < vexCounts;i++)\n    {\n        if (closedge[i].lowestcost < min && closedge[i].lowestcost !=0)\n        {\n            min = closedge[i].lowestcost;\n            index = i;\n        }\n    }\n    return index;\n}\nvoid MiniSpanTree_Prim(unsigned int adjMat[][vexCounts], VertexData s)\n{\n    for (int i = 0; i < vexCounts;i++)\n    {\n        closedge[i].lowestcost = INFINITE;\n    }      \n    closedge[s].data = s;      //从顶点s开始\n    closedge[s].lowestcost = 0;\n    for (int i = 0; i < vexCounts;i++)  //初始化辅助数组\n    {\n        if (i != s)\n        {\n            closedge[i].data = s;\n            closedge[i].lowestcost = adjMat[s][i];\n        }\n    }\n    for (int e = 1; e <= vexCounts -1; e++)  //n-1条边时退出\n    {\n        int k = Minmum(closedge);  //选择最小代价边\n        cout << vextex[closedge[k].data] << \"--\" << vextex[k] << endl;//加入到最小生成树\n        closedge[k].lowestcost = 0; //代价置为0\n        for (int i = 0; i < vexCounts;i++)  //更新v中顶点最小代价边信息\n        {\n            if ( adjMat[k][i] < closedge[i].lowestcost)\n            {\n                closedge[i].data = k;\n                closedge[i].lowestcost = adjMat[k][i];\n            }\n        }\n    }\n}\nvoid ReadArc(unsigned int  adjMat[][vexCounts],vector<Arc> &vertexArc) //保存图的边代价信息\n{\n    Arc * temp = NULL;\n    for (unsigned int i = 0; i < vexCounts;i++)\n    {\n        for (unsigned int j = 0; j < i; j++)\n        {\n            if (adjMat[i][j]!=INFINITE)\n            {\n                temp = new Arc;\n                temp->u = i;\n                temp->v = j;\n                temp->cost = adjMat[i][j];\n                vertexArc.push_back(*temp);\n            }\n        }\n    }\n}\nbool compare(Arc  A, Arc  B)\n{\n    return A.cost < B.cost ? true : false;\n}\nbool FindTree(VertexData u, VertexData v,vector<vector<VertexData> > &Tree)\n{\n    unsigned int index_u = INFINITE;\n    unsigned int index_v = INFINITE;\n    for (unsigned int i = 0; i < Tree.size();i++)  //检查u,v分别属于哪颗树\n    {\n        if (find(Tree[i].begin(), Tree[i].end(), u) != Tree[i].end())\n            index_u = i;\n        if (find(Tree[i].begin(), Tree[i].end(), v) != Tree[i].end())\n            index_v = i;\n    }\n \n    if (index_u != index_v)   //u,v不在一颗树上，合并两颗树\n    {\n        for (unsigned int i = 0; i < Tree[index_v].size();i++)\n        {\n            Tree[index_u].push_back(Tree[index_v][i]);\n        }\n        Tree[index_v].clear();\n        return true;\n    }\n    return false;\n}\nvoid MiniSpanTree_Kruskal(unsigned int adjMat[][vexCounts])\n{\n    vector<Arc> vertexArc;\n    ReadArc(adjMat, vertexArc);//读取边信息\n    sort(vertexArc.begin(), vertexArc.end(), compare);//边按从小到大排序\n    vector<vector<VertexData> > Tree(vexCounts); //6棵独立树\n    for (unsigned int i = 0; i < vexCounts; i++)\n    {\n        Tree[i].push_back(i);  //初始化6棵独立树的信息\n    }\n    for (unsigned int i = 0; i < vertexArc.size(); i++)//依次从小到大取最小代价边\n    {\n        VertexData u = vertexArc[i].u;  \n        VertexData v = vertexArc[i].v;\n        if (FindTree(u, v, Tree))//检查此边的两个顶点是否在一颗树内\n        {\n            cout << vextex[u] << \"---\" << vextex[v] << endl;//把此边加入到最小生成树中\n        }   \n    }\n}\n \nint main()\n{\n    unsigned int  adjMat[vexCounts][vexCounts] = { 0 };\n    AdjMatrix(adjMat);   //邻接矩阵\n    cout << \"Prim :\" << endl;\n    MiniSpanTree_Prim(adjMat,0); //Prim算法，从顶点0开始.\n    cout << \"-------------\" << endl << \"Kruskal:\" << endl;\n    MiniSpanTree_Kruskal(adjMat);//Kruskal算法\n    return 0;\n}"
        }
      ],
      "id": "Xig7I5Yc",
      "createdAt": 1720877781205,
      "updatedAt": 1720877799120
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "fnmatch",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import fnmatch\nimport os\n\nfor file in os.listdir('.'):\n    if fnmatch.fnmatch(file, '*.txt'):\n        print(file)"
        }
      ],
      "id": "Ivhp6eLe",
      "createdAt": 1721203676475,
      "updatedAt": 1721203681413
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "anki_db",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import sqlite3\nimport pandas as pd\nfrom tqdm import tqdm\nimport re\n\nif __name__ == \"__main__\":\n    con = sqlite3.connect(\"data.db\")\n    cur = con.cursor()\n    res = cur.execute(\"SELECT tags,sfld from notes\")\n    data = res.fetchall()\n"
        }
      ],
      "id": "60pjlgt8",
      "createdAt": 1722057259380,
      "updatedAt": 1722057293355
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "json objectification",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": ""
        }
      ],
      "id": "kmrtyaUH",
      "createdAt": 1724574340170,
      "updatedAt": 1724574347941
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "logging",
      "content": [
        {
          "label": "basic",
          "language": "python",
          "value": "import logging\n\nLOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\nDATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n\nlogging.basicConfig(filename='my.log', level=logging.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)\n\nlogging.debug(\"This is a debug log.\")\nlogging.info(\"This is a info log.\")\nlogging.warning(\"This is a warning log.\")\nlogging.error(\"This is a error log.\")\nlogging.critical(\"This is a critical log.\")"
        },
        {
          "label": "advanced",
          "language": "python",
          "value": "import logging\nimport logging.handlers\nimport datetime\n\nlogger = logging.getLogger('mylogger')\nlogger.setLevel(logging.DEBUG)\n\nrf_handler = logging.handlers.TimedRotatingFileHandler('all.log', when='midnight', interval=1, backupCount=7, atTime=datetime.time(0, 0, 0, 0))\nrf_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n\nf_handler = logging.FileHandler('error.log')\nf_handler.setLevel(logging.ERROR)\nf_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(filename)s[:%(lineno)d] - %(message)s\"))\n\nlogger.addHandler(rf_handler)\nlogger.addHandler(f_handler)\n\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warning message')\nlogger.error('error message')\nlogger.critical('critical message')"
        },
        {
          "label": "调用subprocess 使用logging打印日志",
          "language": "python",
          "value": "import sys\nimport logging\nfrom logging.handlers import TimedRotatingFileHandler\nimport os\nfrom subprocess import Popen, PIPE, STDOUT\nreload(sys)\nsys.setdefaultencoding('utf8')\n\n\nLOG_FILE_NAME = 'send_snmp_trap.log'\nlogger = logging.getLogger('SenSNMPTrap.py')\nlogger.setLevel(level=logging.INFO)\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(funcName)s - %(process)d - %(levelname)s - %(message)s')\nLOG_PATH = os.path.join('/tmp', LOG_FILE_NAME)\n\n# 每天午夜更新日志文件\nhandler = TimedRotatingFileHandler(LOG_PATH, when='midnight', backupCount=3, )\nhandler.setLevel(logging.INFO)\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\n\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\nconsole.setFormatter(formatter)\n# 输出到屏幕\nlogger.addHandler(console)\n\n\ndef log_subprocess_output(pipe):\n    for line in iter(pipe.readline, b''):  # b'\\n'-separated lines\n        logger.info('got line from subprocess: %r', line)\n\n\ndef run_command(command_line_args):\n    process = Popen(command_line_args, stdout=PIPE, stderr=STDOUT)\n    with process.stdout:\n        log_subprocess_output(process.stdout)\n    exitcode = process.wait()  # 0 means success\n    if exitcode == 0:\n        logger.info('success')\n    else:\n        logger.error(\"failed\")\n\nrun_command(command_line_args=['ls', '/tp/'])"
        }
      ],
      "id": "w2BFB5oy",
      "createdAt": 1724574359923,
      "updatedAt": 1724831165349
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "yolov5_to_coco",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# -*- encoding: utf-8 -*-\n# @File: yolov5_2_coco.py\n# @Author: lijunjie2232\n# @Contact: git@lijunjie2232\n\nimport argparse\nimport json\nimport shutil\nimport time\nimport warnings\nfrom pathlib import Path\n\nimport cv2\nfrom tqdm import tqdm\nimport yaml\n\nclass YOLOV5ToCOCO():\n    def __init__(self, data_dir):\n        self.raw_data_dir = Path(data_dir)\n\n        self.verify_exists(self.raw_data_dir / 'images')\n        self.verify_exists(self.raw_data_dir / 'labels')\n\n        save_dir_name = f'{Path(self.raw_data_dir).name}_COCO_format'\n        self.output_dir = self.raw_data_dir.parent / save_dir_name\n        self.mkdir(self.output_dir)\n\n        self._init_json()\n\n    def __call__(self, mode_list: list):\n        if not mode_list:\n            raise ValueError('mode_list is empty!!')\n\n        for mode in mode_list:\n            # Read the image txt.\n            txt_path = self.raw_data_dir / f'{mode}.txt'\n            self.verify_exists(txt_path)\n            img_list = self.read_txt(txt_path)\n            if mode == 'train':\n                img_list = self.append_bg_img(img_list)\n\n            # Create the directory of saving the new image.\n            save_img_dir = self.output_dir / f'{mode}2017'\n            self.mkdir(save_img_dir)\n\n            # Generate json file.\n            anno_dir = self.output_dir / \"annotations\"\n            self.mkdir(anno_dir)\n\n            save_json_path = anno_dir / f'instances_{mode}2017.json'\n            json_data = self.convert(img_list, save_img_dir, mode)\n\n            self.write_json(save_json_path, json_data)\n        print(f'Successfully convert, detail in {self.output_dir}')\n\n    def _init_json(self):\n        classes_path = self.raw_data_dir / 'classes.txt'\n        data_yaml_path = self.raw_data_dir / 'data.yaml'\n        if self.verify_exists(classes_path, raise_if_ne=False):\n            self.categories = self._get_category(classes_path)\n        elif self.verify_exists(data_yaml_path, raise_if_ne=False):\n            self.categories = self._get_category(data_yaml_path)\n        else:\n            raise(Exception('no dataset info file found'))\n\n        self.type = 'instances'\n        self.annotation_id = 1\n\n        self.cur_year = time.strftime('%Y', time.localtime(time.time()))\n        self.info = {\n            'year': int(self.cur_year),\n            'version': '1.0',\n            'description': 'For object detection',\n            'date_created': self.cur_year,\n        }\n\n        self.licenses = [{\n            'id': 1,\n            'name': 'Apache License v2.0',\n            'url': 'https://github.com/RapidAI/YOLO2COCO/LICENSE',\n        }]\n\n    def append_bg_img(self, img_list):\n        bg_dir = self.raw_data_dir / 'background_images'\n        if bg_dir.exists():\n            bg_img_list = list(bg_dir.iterdir())\n            for bg_img_path in bg_img_list:\n                img_list.append(str(bg_img_path))\n        return img_list\n\n    def _get_category(self, classes_path):\n        if classes_path.name.endswith('txt'):\n            class_list = self.read_txt(classes_path)\n        elif classes_path.name.endswith('yaml'):\n            with open(classes_path, 'r', encoding='utf-8') as f:\n                y = yaml.safe_load(f)\n            class_list = y['names']\n        else:\n            raise(Exception('invalid dataset info file'))\n        categories = []\n        for i, category in enumerate(class_list, 1):\n            categories.append({\n                'supercategory': category,\n                'id': i,\n                'name': category,\n            })\n        return categories\n\n    def convert(self, img_list, save_img_dir, mode):\n        images, annotations = [], []\n        cvt_process = tqdm(img_list, desc=mode)\n        anno_nums = 0\n        for img_id, img_path in enumerate(cvt_process, 1):\n            \n            image_dict = self.get_image_info(img_path, img_id, save_img_dir)\n            images.append(image_dict)\n\n            label_path = self.raw_data_dir / 'labels' / f'{Path(img_path).stem}.txt'\n            annotation = self.get_annotation(label_path,\n                                             img_id,\n                                             image_dict['height'],\n                                             image_dict['width'])\n            if len(annotation) > 0:\n                annotations.extend(annotation)\n                anno_nums += len(annotation)\n            \n            cvt_process.set_postfix(\n                {\n                    'processed': Path(img_path).name,\n                    'anno numbers': anno_nums,\n                }\n            )\n\n        json_data = {\n            'info': self.info,\n            'images': images,\n            'licenses': self.licenses,\n            'type': self.type,\n            'annotations': annotations,\n            'categories': self.categories,\n        }\n        return json_data\n\n    def get_image_info(self, img_path, img_id, save_img_dir):\n        img_path = Path(img_path)\n        if self.raw_data_dir.as_posix() not in img_path.as_posix():\n            # relative path (relative to the raw_data_dir)\n            # e.g. images/images(3).jpg\n            img_path = self.raw_data_dir / img_path\n\n        self.verify_exists(img_path)\n\n        new_img_name = f'{img_id:012d}.jpg'\n        save_img_path = save_img_dir / new_img_name\n        img_src = cv2.imread(str(img_path))\n        if img_path.suffix.lower() == \".jpg\":\n            shutil.copyfile(img_path, save_img_path)\n        else:\n            cv2.imwrite(str(save_img_path), img_src)\n\n        height, width = img_src.shape[:2]\n        image_info = {\n            'date_captured': self.cur_year,\n            'file_name': new_img_name,\n            'id': img_id,\n            'height': height,\n            'width': width,\n        }\n        return image_info\n\n    def get_annotation(self, label_path: Path, img_id, height, width):\n        def get_box_info(vertex_info, height, width):\n            cx, cy, w, h = [float(i) for i in vertex_info]\n\n            cx = cx * width\n            cy = cy * height\n            box_w = w * width\n            box_h = h * height\n\n            # left top\n            x0 = max(cx - box_w / 2, 0)\n            y0 = max(cy - box_h / 2, 0)\n\n            # right bottom\n            x1 = min(x0 + box_w, width)\n            y1 = min(y0 + box_h, height)\n\n            segmentation = [[x0, y0, x1, y0, x1, y1, x0, y1]]\n            bbox = [x0, y0, box_w, box_h]\n            area = box_w * box_h\n            return segmentation, bbox, area\n\n        if not label_path.exists():\n            # annotation = [{\n            #     'segmentation': [],\n            #     'area': 0,\n            #     'iscrowd': 0,\n            #     'image_id': img_id,\n            #     'bbox': [],\n            #     'category_id': -1,\n            #     'id': self.annotation_id,\n            # }]\n            # self.annotation_id += 1\n            # return annotation\n            return []\n\n        annotation = []\n        label_list = self.read_txt(str(label_path))\n        for i, one_line in enumerate(label_list):\n            label_info = one_line.split(' ')\n            if len(label_info) < 5:\n                warnings.warn(\n                    f'The {i+1} line of the {label_path} has been corrupted.')\n                continue\n\n            category_id, vertex_info = label_info[0], label_info[1:]\n            segmentation, bbox, area = get_box_info(vertex_info, height, width)\n            annotation.append({\n                'segmentation': segmentation,\n                'area': area,\n                'iscrowd': 0,\n                'image_id': img_id,\n                'bbox': bbox,\n                'category_id': int(category_id)+1,\n                'id': self.annotation_id,\n            })\n            self.annotation_id += 1\n        return annotation\n\n    @staticmethod\n    def read_txt(txt_path):\n        with open(str(txt_path), 'r', encoding='utf-8') as f:\n            data = list(map(lambda x: x.rstrip('\\n'), f))\n        return data\n\n    @staticmethod\n    def mkdir(dir_path):\n        Path(dir_path).mkdir(parents=True, exist_ok=True)\n\n    @staticmethod\n    def verify_exists(file_path, raise_if_ne=True):\n        file_path = Path(file_path)\n        if not file_path.exists():\n            if raise_if_ne:\n                raise FileNotFoundError(f'The {file_path} is not exists!!!')\n            else:\n                return False\n        else:\n            return True\n\n    @staticmethod\n    def write_json(json_path, content: dict):\n        with open(json_path, 'w', encoding='utf-8') as f:\n            json.dump(content, f, ensure_ascii=False)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser('Datasets converter from YOLOV5 to COCO')\n    parser.add_argument('--data_dir', type=str, default='datasets/YOLOV5',\n                        help='Dataset root path')\n    parser.add_argument('--mode_list', type=str, default='train,val',\n                        help='generate which mode')\n    args = parser.parse_args()\n\n    converter = YOLOV5ToCOCO(args.data_dir)\n    converter(mode_list=args.mode_list.split(','))\n\n"
        }
      ],
      "id": "aM9qIpVf",
      "createdAt": 1724574636984,
      "updatedAt": 1724574654722
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "make_index_4_yolov5",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# -*- encoding: utf-8 -*-\n# @File: makeIndex4yolov5ds.py\n# @Author: lijunjie2232\n# @Contact: git@lijunjie2232\n\nimport random\nimport os\nfrom tqdm import tqdm\nimport argparse\nimport yaml\nfrom pathlib import Path\n\ndef makeIndex(yaml_file=Path('./data.yaml'), out_path=None, ds_type='inner', ds_split='train,val,test'):\n    with open(yaml_file, 'r', encoding='utf-8') as f:\n        yaml_data = yaml.safe_load(f)\n    data_path = Path(yaml_data['path'])\n    train = yaml_data['train']\n    val = yaml_data['val']\n    train_img = []\n    val_img = []\n    if not isinstance(train, list):\n        train = [train]\n    if not isinstance(val, list):\n        val = [val]\n    for d in train:\n        train_img.extend(dataWalker(d, root=data_path))\n    for d in val:\n        val_img.extend(dataWalker(d, root=data_path))\n    saveIndex(train_img, Path(out_path)/\"train.txt\" if out_path else Path(yaml_file).parent/\"train.txt\")\n    saveIndex(val_img, Path(out_path)/\"val.txt\" if out_path else Path(yaml_file).parent/\"val.txt\")\n\n\ndef dataWalker(img_dir, anno_dir=None, root=Path('.')):\n    if not anno_dir:\n        anno_dir = str(img_dir).replace('images', 'labels')\n    img_list = []\n    for file in tqdm(os.listdir(root/img_dir), desc='walking ...', leave=False):\n        if os.path.isfile(os.path.join(root/anno_dir, os.path.splitext(file)[0]+'.txt')):\n            # img_list.append(os.path.abspath(os.path.join(img_dir, file)))\n            img_list.append(Path(os.path.join(img_dir, file)).__str__())\n    return img_list\n\ndef saveIndex(index_list, path):\n    with open(path, 'w') as f:\n        for line in tqdm(index_list, desc='save to '+str(path), leave=False):\n            f.write(line+'\\n')\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser('Datasets converter from YOLOV5 to COCO')\n    parser.add_argument('--data_dir', type=str, default='./',\n                        help='Dataset root path')\n    parser.add_argument('--out_dir', type=str, default='',\n                        help='Dataset split result output path')\n    parser.add_argument('--type', type=str, default='inner',\n                        help='Dataset construction type, inner:type dir in images/labels dir; outer:...')\n    parser.add_argument('--data_split', type=str, default='train,val',\n                        help='Dataset split')\n    args = parser.parse_args()\n\n    ROOT = Path('.')\n\n    makeIndex(ROOT/args.data_dir, args.out_dir, ds_type=args.type, ds_split=args.data_split)\n\n"
        }
      ],
      "id": "zXh0Znfi",
      "createdAt": 1724574687043,
      "updatedAt": 1724574709788
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "param & flops",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import torch\nimport torchvision\nfrom thop import profile\n\n# Model\nprint('==> Building model..')\nmodel = torchvision.models.alexnet(pretrained=False)\n\ndummy_input = torch.randn(1, 3, 224, 224)\nflops, params = profile(model, (dummy_input,))\nprint('flops: ', flops, 'params: ', params)\nprint('flops: %.2f M, params: %.2f M' % (flops / 1000000.0, params / 1000000.0))"
        },
        {
          "label": "子片段 2",
          "language": "python",
          "value": "freeze_param = 0\ntrain_param = 0\nfor i in model.parameters():\n    if i.requires_grad:\n        train_param += i.numel()\n    else:\n        freeze_param += i.numel()\nfor name, i in model.named_parameters():\n    if i.requires_grad:\n        train_param += i.numel()\n    else:\n        freeze_param += i.numel()\nprint(\"trainable params: %.2f M\" % (train_param / 1000000.0))\nprint(\"freeze params: %.2f M\" % (freeze_param / 1000000.0))"
        }
      ],
      "id": "AUEnTr0e",
      "createdAt": 1724579916146,
      "updatedAt": 1724776769307
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "time",
      "content": [
        {
          "label": "basic",
          "language": "python",
          "value": "import time\n\nlocaltime = time.localtime(time.time())\nprint \"本地时间为 :\", localtime\n# 本地时间为 : time.struct_time(tm_year=2016, tm_mon=4, tm_mday=7, tm_hour=10, tm_min=3, tm_sec=27, tm_wday=3, tm_yday=98, tm_isdst=0)\n\nlocaltime = time.asctime( time.localtime(time.time()) )\nprint \"本地时间为 :\", localtime\n# 本地时间为 : Thu Apr  7 10:05:21 2016"
        },
        {
          "label": "format",
          "language": "python",
          "value": "import time\n\n# 格式化成2016-03-20 11:45:39形式\nprint time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n# 2016-04-07 10:25:09\n\n# 格式化成Sat Mar 28 22:24:24 2016形式\nprint time.strftime(\"%a %b %d %H:%M:%S %Y\", time.localtime())\n# Thu Apr 07 10:25:09 2016\n\n# 将格式字符串转换为时间戳\na = \"Sat Mar 28 22:24:24 2016\"\nprint time.mktime(time.strptime(a,\"%a %b %d %H:%M:%S %Y\"))\n# 1459175064.0\n\n\"\"\"\npython中时间日期格式化符号：\n\n%y 两位数的年份表示（00-99）\n%Y 四位数的年份表示（000-9999）\n%m 月份（01-12）\n%d 月内中的一天（0-31）\n%H 24小时制小时数（0-23）\n%I 12小时制小时数（01-12）\n%M 分钟数（00-59）\n%S 秒（00-59）\n%a 本地简化星期名称\n%A 本地完整星期名称\n%b 本地简化的月份名称\n%B 本地完整的月份名称\n%c 本地相应的日期表示和时间表示\n%j 年内的一天（001-366）\n%p 本地A.M.或P.M.的等价符\n%U 一年中的星期数（00-53）星期天为星期的开始\n%w 星期（0-6），星期天为星期的开始\n%W 一年中的星期数（00-53）星期一为星期的开始\n%x 本地相应的日期表示\n%X 本地相应的时间表示\n%Z 当前时区的名称\n%% %号本身\n\"\"\""
        },
        {
          "label": "calender",
          "language": "python",
          "value": "#!/usr/bin/python\n# -*- coding: UTF-8 -*-\n \nimport calendar\n \ncal = calendar.month(2016, 1)\nprint \"以下输出2016年1月份的日历:\"\nprint cal"
        }
      ],
      "id": "WHxAFSQd",
      "createdAt": 1724660133793,
      "updatedAt": 1724660309591
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "yolo_objectify",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import argparse\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os\nimport shutil\nimport logging as lg\nfrom multiprocessing.pool import ThreadPool\n\nLOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\nlg.basicConfig(level=lg.DEBUG, format=LOG_FORMAT)\n\n\ndef txt_objectify(path: Path):\n    if not path.suffix == \".txt\":\n        return\n    bak_file = path.parent / f\"{path.name}_bak.txt\"\n    if not bak_file.is_file():\n        shutil.copy(path, bak_file)\n    with open(bak_file, \"r\", encoding=\"utf-8\") as old_f:\n        anns = old_f.read().strip(\"\\n\").split(\"\\n\")\n        with open(path, \"w\", encoding=\"utf-8\") as new_f:\n            for ann in anns:\n                ann = ann.strip(\" \").split(\" \")\n                ann[0] = \"0\"\n                new_f.write(\" \".join(ann))\n                new_f.write(\"\\n\")\n\n\ndef dir_walker(dir: Path, filter, func, pool=None):\n    for file in os.listdir(dir):\n        file = dir / file\n        if file.is_dir():\n            dir_walker(file, filter, func)\n        elif filter(file):\n            if pool:\n                pool.apply_async(func=func,args=(file))\n            else:\n                func(file)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"objectification yolo label directory\")\n    parser.add_argument(\"-d\", type=str, required=True)\n    args = parser.parse_args()\n\n    path = Path(args.d)\n\n    filter = lambda file: return file.suffix == \".txt\"\n    \n    pool = ThreadPool(16)\n    \n    dir_walker(path, filter, txt_objectify, pool=pool)\n    \n"
        }
      ],
      "id": "FLBLihaP",
      "createdAt": 1724908462822,
      "updatedAt": 1724908475930
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "v3det(threadpool image check)",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# %%\nimport json\nimport os\nimport shutil\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom copy import deepcopy\nfrom PIL import Image\nfrom multiprocessing.pool import ThreadPool\nfrom itertools import repeat\n\n\n# %%\nDATA = Path(\"./data/\")\nANN_DIR = DATA / \"annotations\"\nOUT_DIR = Path(\"./yolo_format\")\n\n# %%\nwith open(ANN_DIR / \"v3det_2023_v1_train.json\", \"r\", encoding=\"utf-8\") as f:\n    train_json = json.load(f)\n\n\n# %%\ndef img_checker(args):\n    dir, img = args\n    img_file = img[\"file_name\"]\n    if str(img_file).endswith('jpg') or str(img_file).endswith('jpg'):\n        try:\n            Image.open(dir/img_file).load()\n        except:\n            if (dir/img_file).is_file():\n                os.unlik(dir/img_file)\n            img[\"file_name\"] = None\n        finally:\n            return img\n    return None\n\n# %%\nnew_images = []\nnew_id = dict({})\nimg_count = 1\nos.makedirs((OUT_DIR / \"images\" / \"train\"), exist_ok=True)\nwith ThreadPool(32) as pool:\n    results = pool.imap(func=img_checker,iterable= zip(repeat(DATA), train_json[\"images\"]))\n    for i in tqdm(results, total=len(train_json[\"images\"])):\n        if not i:\n            continue\n        if i[\"file_name\"]:\n            img_file = DATA / i[\"file_name\"]\n            new_img_path = OUT_DIR / f\"images/train/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n            shutil.copy(img_file, new_img_path)\n            this_img = deepcopy(i)\n            this_img[\"file_name\"] = new_img_path.name\n            new_id[this_img[\"id\"]] = img_count\n            this_img[\"id\"] = img_count\n            new_images.append(this_img)\n            img_count += 1\n\n\"\"\"for i in tqdm(train_json[\"images\"]):\n    img_file = DATA / i[\"file_name\"]\n    new_img_path = OUT_DIR / f\"images/train/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n    try:\n        Image.open(img_file).load()\n    except:\n        print(img_file)\n        os.unlik(img_file)\n        continue\n    if not new_img_path.is_file():\n        shutil.copy(img_file, new_img_path)\n    this_img = deepcopy(i)\n    this_img[\"file_name\"] = new_img_path.name\n    new_id[this_img[\"id\"]] = img_count\n    this_img[\"id\"] = img_count\n    new_images.append(this_img)\n    img_count += 1\"\"\"\n\nnew_annotations = []\nann_count = 0\nfor a in tqdm(train_json[\"annotations\"]):\n    if a[\"image_id\"] in new_id:\n        this_ann = deepcopy(a)\n        this_ann[\"image_id\"] = new_id[this_ann[\"image_id\"]]\n        this_ann[\"id\"] = ann_count\n        new_annotations.append(this_ann)\n        ann_count += 1\n\nnew_train_json = deepcopy(train_json)\nnew_train_json[\"images\"] = new_images\nnew_train_json[\"annotations\"] = new_annotations\n\nwith open(OUT_DIR / \"annotations\" / \"instances_train.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(new_train_json, f)\n\n# %%\ni\n\n# %%\na\n\n\n# %%\nthis_img\n\n\n# %%\nthis_ann\n\n\n# %%\nwith open(ANN_DIR / \"v3det_2023_v1_val.json\", \"r\", encoding=\"utf-8\") as f:\n    val_json = json.load(f)\n\n\n# %%\nnew_images = []\nnew_id = dict({})\nimg_count = 1\nos.makedirs((OUT_DIR / \"images\" / \"val\"), exist_ok=True)\nwith ThreadPool(32) as pool:\n    results = pool.imap(target=img_checker,iterable= zip(repeat(DATA), val_json[\"images\"]))\n    for i in tqdm(results, total=len(val_json[\"images\"])):\n        if not i:\n            continue\n        if i[\"file_name\"]:\n            img_file = DATA / i[\"file_name\"]\n            new_img_path = OUT_DIR / f\"images/val/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n            shutil.copy(img_file, new_img_path)\n            this_img = deepcopy(i)\n            this_img[\"file_name\"] = new_img_path.name\n            new_id[this_img[\"id\"]] = img_count\n            this_img[\"id\"] = img_count\n            new_images.append(this_img)\n            img_count += 1\n\n\"\"\"for i in tqdm(val_json[\"images\"]):\n    img_file = DATA / i[\"file_name\"]\n    new_img_path = OUT_DIR / f\"images/val/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n    try:\n        image.open(img_file).load()\n    except:\n        print(img_file)\n        os.unlik(img_file)\n        continue\n    if not new_img_path.is_file():\n        shutil.copy(img_file, new_img_path)\n    this_img = deepcopy(i)\n    this_img[\"file_name\"] = new_img_path.name\n    new_id[this_img[\"id\"]] = img_count\n    this_img[\"id\"] = img_count\n    new_images.append(this_img)\n    img_count += 1\"\"\"\n\nnew_annotations = []\nann_count = 0\nfor a in tqdm(val_json[\"annotations\"]):\n    if a[\"image_id\"] in new_id:\n        this_ann = deepcopy(a)\n        this_ann[\"image_id\"] = new_id[this_ann[\"image_id\"]]\n        this_ann[\"id\"] = ann_count\n        new_annotations.append(this_ann)\n        ann_count += 1\n\nnew_val_json = deepcopy(val_json)\nnew_val_json[\"images\"] = new_images\nnew_val_json[\"annotations\"] = new_annotations\n\nwith open(OUT_DIR / \"annotations\" / \"instances_val.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(new_val_json, f)\n\n\n\n\n"
        }
      ],
      "id": "iXUs53Ff",
      "createdAt": 1724919224198,
      "updatedAt": 1724919274735
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "image checker",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# %%\nimport json\nimport os\nimport shutil\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom copy import deepcopy\nfrom PIL import Image\nfrom multiprocessing.pool import ThreadPool\nfrom itertools import repeat\n\n\n# %%\nDATA = Path(\"./data/\")\nANN_DIR = DATA / \"annotations\"\nOUT_DIR = Path(\"./yolo_format\")\n\n# %%\nwith open(ANN_DIR / \"v3det_2023_v1_train.json\", \"r\", encoding=\"utf-8\") as f:\n    train_json = json.load(f)\n\n\n# %%\ndef img_checker(args):\n    dir, img = args\n    img_file = img[\"file_name\"]\n    if str(img_file).endswith('jpg') or str(img_file).endswith('jpg'):\n        try:\n            Image.open(dir / img_file).verify()\n            img = Image.open(dir / img_file)\n            img.load()\n        except:\n            if (dir/img_file).is_file():\n                os.unlik(dir/img_file)\n            img[\"file_name\"] = None\n        finally:\n            return img\n    return None\n\n# %%\nnew_images = []\nnew_id = dict({})\nimg_count = 1\nos.makedirs((OUT_DIR / \"images\" / \"train\"), exist_ok=True)\nwith ThreadPool(32) as pool:\n    results = pool.imap(func=img_checker,iterable= zip(repeat(DATA), train_json[\"images\"]))\n    for i in tqdm(results, total=len(train_json[\"images\"])):\n        if not i:\n            continue\n        if i[\"file_name\"]:\n            img_file = DATA / i[\"file_name\"]\n            new_img_path = OUT_DIR / f\"images/train/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n            shutil.copy(img_file, new_img_path)\n            this_img = deepcopy(i)\n            this_img[\"file_name\"] = new_img_path.name\n            new_id[this_img[\"id\"]] = img_count\n            this_img[\"id\"] = img_count\n            new_images.append(this_img)\n            img_count += 1\n"
        }
      ],
      "id": "OaCbxc8o",
      "createdAt": 1725756511234,
      "updatedAt": 1725770181958
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "pytorch ddp",
      "content": [
        {
          "label": "train",
          "language": "python",
          "value": "导入\ntorch.multiprocessing 是围绕 Python 原生多处理的 PyTorch 包装器\n\n分布式进程组包含所有可以相互通信和同步的进程。\n\nimport torch\nimport torch.nn.functional as F\nfrom utils import MyTrainDataset\n\n+ import torch.multiprocessing as mp\n+ from torch.utils.data.distributed import DistributedSampler\n+ from torch.nn.parallel import DistributedDataParallel as DDP\n+ from torch.distributed import init_process_group, destroy_process_group\n+ import os\n构建进程组\n首先，在初始化组进程之前，调用 set_device，它为每个进程设置默认 GPU。这对于防止 GPU:0 上的挂起或过度内存使用至关重要。\n\n进程组可以通过 TCP（默认）或从共享文件系统初始化。阅读有关 进程组初始化 的更多信息\n\ninit_process_group 初始化分布式进程组。\n\n了解有关 选择 DDP 后端 的更多信息\n\n+ def ddp_setup(rank: int, world_size: int):\n+   \"\"\"\n+   Args:\n+       rank: Unique identifier of each process\n+      world_size: Total number of processes\n+   \"\"\"\n+   os.environ[\"MASTER_ADDR\"] = \"localhost\"\n+   os.environ[\"MASTER_PORT\"] = \"12355\"\n+   torch.cuda.set_device(rank)\n+   init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n构建 DDP 模型\n- self.model = model.to(gpu_id)\n+ self.model = DDP(model, device_ids=[gpu_id])\n分发输入数据\nDistributedSampler 将输入数据跨所有分布式进程进行分块。\n\n每个进程将接收一个包含 32 个样本的输入批次；有效批次大小为 32 * nprocs，使用 4 个 GPU 时为 128。\n\ntrain_data = torch.utils.data.DataLoader(\n    dataset=train_dataset,\n    batch_size=32,\n-   shuffle=True,\n+   shuffle=False,\n+   sampler=DistributedSampler(train_dataset),\n)\n在每个 epoch 开始时调用 DistributedSampler 上的 set_epoch() 方法对于使跨多个 epoch 的混洗正常工作是必要的。否则，将在每个 epoch 中使用相同的排序。\n\ndef _run_epoch(self, epoch):\n    b_sz = len(next(iter(self.train_data))[0])\n+   self.train_data.sampler.set_epoch(epoch)\n    for source, targets in self.train_data:\n      ...\n      self._run_batch(source, targets)\n保存模型检查点\n我们只需要从一个进程保存模型检查点。如果没有这个条件，每个进程都会保存其相同模式的副本。阅读有关使用 DDP 保存和加载模型的更多信息 此处\n\n- ckp = self.model.state_dict()\n+ ckp = self.model.module.state_dict()\n...\n...\n- if epoch % self.save_every == 0:\n+ if self.gpu_id == 0 and epoch % self.save_every == 0:\n  self._save_checkpoint(epoch)\n警告\n\n集体调用 是在所有分布式进程上运行的函数，它们用于将某些状态或值收集到特定进程。集体调用要求所有等级都运行集体代码。在这个例子中，_save_checkpoint 不应该有任何集体调用，因为它只在 rank:0 进程上运行。如果您需要进行任何集体调用，则应在 if self.gpu_id == 0 检查之前进行。\n\n运行分布式训练作业\n包括新的参数 rank（替换 device）和 world_size。\n\nrank 是在调用 mp.spawn 时由 DDP 自动分配的。\n\nworld_size 是整个训练作业中的进程数量。对于 GPU 训练，这对应于使用的 GPU 数量，并且每个进程都在专用 GPU 上工作。\n\n- def main(device, total_epochs, save_every):\n+ def main(rank, world_size, total_epochs, save_every):\n+  ddp_setup(rank, world_size)\n   dataset, model, optimizer = load_train_objs()\n   train_data = prepare_dataloader(dataset, batch_size=32)\n-  trainer = Trainer(model, train_data, optimizer, device, save_every)\n+  trainer = Trainer(model, train_data, optimizer, rank, save_every)\n   trainer.train(total_epochs)\n+  destroy_process_group()\n\nif __name__ == \"__main__\":\n   import sys\n   total_epochs = int(sys.argv[1])\n   save_every = int(sys.argv[2])\n-  device = 0      # shorthand for cuda:0\n-  main(device, total_epochs, save_every)\n+  world_size = torch.cuda.device_count()\n+  mp.spawn(main, args=(world_size, total_epochs, save_every,), nprocs=world_size)"
        },
        {
          "label": "inference",
          "language": "python",
          "value": "import torch\nimport torch.distributed as dist\nimport json\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\n# 模拟推理结果\ndef inference_on_gpu(model, data_loader, device):\n    model.eval()\n    all_predictions = []\n    with torch.no_grad():\n        for images, image_ids in data_loader:\n            images = images.to(device)\n            outputs = model(images)  # 假设模型输出包含预测框和类别\n\n            # 将输出转换为 COCO 格式的预测结果\n            for i, output in enumerate(outputs):\n                pred_boxes = output['boxes'].cpu().numpy()\n                pred_scores = output['scores'].cpu().numpy()\n                pred_labels = output['labels'].cpu().numpy()\n\n                # 每张图片的预测框\n                for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n                    all_predictions.append({\n                        \"image_id\": image_ids[i].item(),\n                        \"category_id\": label.item(),\n                        \"bbox\": box.tolist(),  # COCO 格式的 [x_min, y_min, width, height]\n                        \"score\": score.item()\n                    })\n    return all_predictions\n\n# 收集所有 GPU 上的推理结果\ndef gather_predictions(predictions):\n    # 如果是分布式训练，需要收集每个 GPU 的结果\n    all_predictions = [None for _ in range(dist.get_world_size())]\n    dist.all_gather_object(all_predictions, predictions)  # 收集每个 GPU 的预测结果\n    # 展平收集到的预测结果\n    all_predictions = [item for sublist in all_predictions for item in sublist]\n    return all_predictions\n\n# 计算 COCO mAP\ndef evaluate_predictions(coco_gt, all_predictions, output_file='predictions.json'):\n    with open(output_file, 'w') as f:\n        json.dump(all_predictions, f)\n\n    coco_dt = coco_gt.loadRes(output_file)\n    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n\n# 主推理与评估流程\ndef main():\n    # 初始化分布式环境\n    dist.init_process_group(backend='nccl')\n\n    # 设置设备\n    device = torch.device(f'cuda:{dist.get_rank()}')\n\n    # 加载模型和数据\n    model = YourModel().to(device)\n    data_loader = YourDataLoader()  # 假设 data_loader 返回 (images, image_ids)\n    \n    # COCO ground truth 数据\n    coco_gt = COCO(annotation_file='instances_val2017.json')\n\n    # 每个 GPU 执行推理\n    predictions = inference_on_gpu(model, data_loader, device)\n\n    # 收集所有 GPU 的推理结果\n    all_predictions = gather_predictions(predictions)\n\n    # 只有 rank 0 的进程负责计算 mAP\n    if dist.get_rank() == 0:\n        evaluate_predictions(coco_gt, all_predictions)\n\n    # 结束分布式进程组\n    dist.barrier()\n    dist.destroy_process_group()\n\nif __name__ == \"__main__\":\n    main()\n"
        }
      ],
      "id": "PfEmpLuD",
      "createdAt": 1725932493707,
      "updatedAt": 1726814950100
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "memory_profiler",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import numpy as np\nfrom memory_profiler import profile\n \n@profile\ndef demo():\n    a = np.random.rand(10000000)\n    b = np.random.rand(10000000)\n    \n    a_ = a[a < b]\n    b_ = b[a < b]\n    \n    del a, b\n \n    return a_, b_\n \n \nif __name__ == '__main__':\n    demo()"
        }
      ],
      "id": "1mZKVtdM",
      "createdAt": 1726649105037,
      "updatedAt": 1726649118980
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "@timecalc",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "def timecalc(func):\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f\"[function]: {func.__name__}, [time]: {end - start}ms\")\n        return result\n    return wrapper"
        }
      ],
      "id": "JWFfVT6n",
      "createdAt": 1726819216801,
      "updatedAt": 1726819221854
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Queue",
      "content": [
        {
          "label": "get&put",
          "language": "plain_text",
          "value": "\"\"\"\nPython 中的消息队列\nPython 提供了 queue 模块来实现线程之间的消息队列。queue.Queue 是线程安全的，允许多个线程安全地访问和修改队列中的数据。\n\nqueue.Queue 的基本用法\nqueue.Queue 通过两个主要方法实现线程安全的队列操作：\n\nput(item)：将数据项放入队列。\nget()：从队列中取出数据项。如果队列为空，它会阻塞直到有数据可取。\n\"\"\"\n\nimport threading\nimport queue\nimport time\n\n# 创建队列对象\nq = queue.Queue()\n\n# 生产者线程\ndef producer():\n    for i in range(5):\n        item = f\"item_{i}\"\n        print(f\"Producing {item}\")\n        q.put(item)\n        time.sleep(1)\n\n# 消费者线程\ndef consumer():\n    while True:\n        item = q.get()\n        if item is None:\n            break\n        print(f\"Consuming {item}\")\n        q.task_done()\n\n# 创建线程\nproducer_thread = threading.Thread(target=producer)\nconsumer_thread = threading.Thread(target=consumer)\n\n# 启动线程\nproducer_thread.start()\nconsumer_thread.start()\n\n# 等待生产者结束\nproducer_thread.join()\n\n# 向队列发送终止信号\nq.put(None)\n\n# 等待消费者结束\nconsumer_thread.join()\n\nprint(\"All tasks finished\")\n\"\"\"\n分析：\n生产者线程：负责将数据项放入队列。这里每隔 1 秒向队列中添加一个数据项。\n消费者线程：负责从队列中取出数据并处理。如果队列为空，q.get() 会阻塞，直到有新数据项进入队列。当所有生产任务完成后，通过向队列中添加 None 来通知消费者线程结束。\n线程通信：queue.Queue 在多个线程之间安全地传递数据，避免了手动加锁的复杂性。\n\"\"\""
        },
        {
          "label": "Full&Empty",
          "language": "python",
          "value": "\"\"\"\n阻塞与非阻塞队列\n队列的 put() 和 get() 方法默认是阻塞的，但你可以通过设置 block=False 来让它们变为非阻塞模式。如果在非阻塞模式下调用 get() 时队列为空，或者 put() 时队列满了，它们会抛出 queue.Empty 或 queue.Full 异常。\n\n非阻塞队列示例：\n\"\"\"\n\nimport queue\n\nq = queue.Queue(maxsize=3)\n\n# 非阻塞地放入队列\ntry:\n    q.put(\"item\", block=False)\nexcept queue.Full:\n    print(\"Queue is full!\")\n\n# 非阻塞地获取队列\ntry:\n    item = q.get(block=False)\nexcept queue.Empty:\n    print(\"Queue is empty!\")"
        },
        {
          "label": "join&task_done",
          "language": "python",
          "value": "\"\"\"\nqueue.Queue 的其他方法\nq.task_done()：当消费者线程完成对某个任务的处理时，调用此方法通知队列该任务已完成。\nq.join()：阻塞主线程，直到队列中的所有任务都已完成。它会等待所有任务都调用 task_done()。\n\"\"\"\nimport threading\nimport queue\n\nq = queue.Queue()\n\ndef producer():\n    for i in range(5):\n        q.put(i)\n        print(f\"Produced {i}\")\n\ndef consumer():\n    while True:\n        item = q.get()\n        print(f\"Consumed {item}\")\n        q.task_done()\n\n# 启动生产者和消费者线程\nthreading.Thread(target=producer).start()\nthreading.Thread(target=consumer, daemon=True).start()\n\n# 等待所有任务完成\nq.join()\nprint(\"All tasks are done\")"
        },
        {
          "label": "子片段 4",
          "language": "python",
          "value": "\"\"\"\nPython queue 模块还提供了其他几种类型的队列：\n\nqueue.LifoQueue：后进先出（LIFO）的队列，类似于栈。\nqueue.PriorityQueue：优先级队列，数据项会按照优先级顺序排列。\n优先级队列示例：\n\"\"\"\nimport queue\n\npq = queue.PriorityQueue()\n\n# 将数据按照优先级放入队列\npq.put((2, \"Medium priority\"))\npq.put((1, \"High priority\"))\npq.put((3, \"Low priority\"))\n\n# 按照优先级顺序获取数据\nwhile not pq.empty():\n    priority, task = pq.get()\n    print(f\"Processing task with priority {priority}: {task}\")"
        },
        {
          "label": "子片段 5",
          "language": "python",
          "value": ""
        },
        {
          "label": "子片段 6",
          "language": "python",
          "value": ""
        }
      ],
      "id": "YcCA6Xx6",
      "createdAt": 1726991761016,
      "updatedAt": 1726993316352
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "re replace",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "re.sub(\"<.*?>\", \"\", word)"
        }
      ],
      "id": "zW1UeYgh",
      "createdAt": 1727353216088,
      "updatedAt": 1727425970531
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "cuda time",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "torch.cuda.synchronize()\nstart = time()\nmodel(x)\ntorch.cuda.synchronize()\nend = time()\nprint(end - start, \"ms\")"
        }
      ],
      "id": "HVTNDdUU",
      "createdAt": 1727425732121,
      "updatedAt": 1727425739504
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "cude mem",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "import torch\nfrom torchvision import models\nfrom memory_profiler import profile\nfrom inspect import unwrap\nfrom time import time\n\n\n@profile\ndef model_test():\n    device = torch.device(\"cuda:0\")\n    model = models.resnet50().cuda()\n    print(torch.cuda.memory_allocated() / 1024**2, \"MB\")\n    model = model.cpu()\n    print(torch.cuda.max_memory_allocated() / 1024**2, \"MB\")\n    print(torch.cuda.memory_summary())\n    model = model.cuda()\n\n    with torch.profiler.profile(\n        activities=[\n            torch.profiler.ProfilerActivity.CPU,\n            torch.profiler.ProfilerActivity.CUDA,\n        ],\n        # execution_trace_observer=(\n        #     torch.profiler.ExecutionTraceObserver().register_callback(\"./execution_trace.json\")\n        # ),\n        record_shapes=True,\n        profile_memory=True,  # 启用显存分析\n        with_stack=True,\n    ) as prof:\n        x = torch.randn(1, 3, 224, 224).cuda()\n        model(x)\n    print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n\n    x = torch.randn(32, 3, 224, 224).cuda()\n    torch.cuda.synchronize()\n    start = time()\n    model(x)\n    torch.cuda.synchronize()\n    end = time()\n    print(end - start, \"ms\")\n\n\nif __name__ == \"__main__\":\n    model_test()\n    unwrap(model_test)()\n"
        }
      ],
      "id": "7aNFOFbC",
      "createdAt": 1727425948490,
      "updatedAt": 1727425960495
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "pytorch cudnn enable",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import torch\ntorch.backends.cudnn.enabled = True\ntorch.backend.cudnn.benchmark=True"
        }
      ],
      "id": "9doO_wAe",
      "createdAt": 1727507206242,
      "updatedAt": 1727507218048
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "whisper inference with ddp",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import whisper\nfrom whisper.transcribe import *\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.distributed import init_process_group, barrier\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport argparse\n\nos.environ[\"MKL_NUM_THREADS\"] = \"1024\"\nos.environ[\"OMP_NUM_THREADS\"] = \"1024\"\ntorch.set_num_threads(1024)\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\nLOCAL_RANK = int(\n    os.getenv(\"LOCAL_RANK\", 0)\n)  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", 0))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\n\n\nclass input_files(Dataset):\n    def __init__(self, path, valid_suffix=[\".acc\", \".mp3\", \".wav\"]):\n        self.path = path\n        self.files = (self.path / file for file in os.listdir(path))\n        self.files = [\n            f.__str__() for f in filter(lambda f: f.suffix in valid_suffix, self.files)\n        ]\n\n    def __getitem__(self, index):\n        return self.files[index]\n\n    def __len__(self):\n        return len(self.files)\n\n\ndef ddp_setup(rank: int, world_size: int):\n    \"\"\"\n    Args:\n        rank: Unique identifier of each process\n    world_size: Total number of processes\n    \"\"\"\n    torch.cuda.set_device(rank)\n    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n\n\ndef get_args():\n    # fmt: off\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    # parser.add_argument(\"audio\", nargs=\"+\", type=str, help=\"audio file(s) to transcribe\")\n    parser.add_argument(\"--model\", default=\"small\", type=str, help=\"name of the Whisper model to use\")\n    parser.add_argument(\"--model_dir\", type=str, default=None, help=\"the path to save model files; uses ~/.cache/whisper by default\")\n    parser.add_argument(\"--device\", default=\"cuda\" if torch.cuda.is_available() else \"cpu\", help=\"device to use for PyTorch inference\")\n    parser.add_argument(\"--output_dir\", \"-o\", type=str, default=\"./output\", help=\"directory to save the outputs\")\n    parser.add_argument(\"--output_format\", \"-f\", type=str, default=\"all\", choices=[\"txt\", \"vtt\", \"srt\", \"tsv\", \"json\", \"all\"], help=\"format of the output file; if not specified, all available formats will be produced\")\n    parser.add_argument(\"--verbose\", type=str2bool, default=True, help=\"whether to print out the progress and debug messages\")\n\n    parser.add_argument(\"--task\", type=str, default=\"transcribe\", choices=[\"transcribe\", \"translate\"], help=\"whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')\")\n    parser.add_argument(\"--language\", type=str, default=None, choices=sorted(LANGUAGES.keys()) + sorted([k.title() for k in TO_LANGUAGE_CODE.keys()]), help=\"language spoken in the audio, specify None to perform language detection\")\n\n    parser.add_argument(\"--temperature\", type=float, default=0, help=\"temperature to use for sampling\")\n    parser.add_argument(\"--best_of\", type=optional_int, default=5, help=\"number of candidates when sampling with non-zero temperature\")\n    parser.add_argument(\"--beam_size\", type=optional_int, default=5, help=\"number of beams in beam search, only applicable when temperature is zero\")\n    parser.add_argument(\"--patience\", type=float, default=None, help=\"optional patience value to use in beam decoding, as in https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to conventional beam search\")\n    parser.add_argument(\"--length_penalty\", type=float, default=None, help=\"optional token length penalty coefficient (alpha) as in https://arxiv.org/abs/1609.08144, uses simple length normalization by default\")\n\n    parser.add_argument(\"--suppress_tokens\", type=str, default=\"-1\", help=\"comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations\")\n    parser.add_argument(\"--initial_prompt\", type=str, default=None, help=\"optional text to provide as a prompt for the first window.\")\n    parser.add_argument(\"--condition_on_previous_text\", type=str2bool, default=True, help=\"if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop\")\n    parser.add_argument(\"--fp16\", type=str2bool, default=True, help=\"whether to perform inference in fp16; True by default\")\n\n    parser.add_argument(\"--temperature_increment_on_fallback\", type=optional_float, default=0.2, help=\"temperature to increase when falling back when the decoding fails to meet either of the thresholds below\")\n    parser.add_argument(\"--compression_ratio_threshold\", type=optional_float, default=2.4, help=\"if the gzip compression ratio is higher than this value, treat the decoding as failed\")\n    parser.add_argument(\"--logprob_threshold\", type=optional_float, default=-1.0, help=\"if the average log probability is lower than this value, treat the decoding as failed\")\n    parser.add_argument(\"--no_speech_threshold\", type=optional_float, default=0.6, help=\"if the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence\")\n    parser.add_argument(\"--word_timestamps\", type=str2bool, default=False, help=\"(experimental) extract word-level timestamps and refine the results based on them\")\n    parser.add_argument(\"--prepend_punctuations\", type=str, default=\"\\\"\\'“¿([{-\", help=\"if word_timestamps is True, merge these punctuation symbols with the next word\")\n    parser.add_argument(\"--append_punctuations\", type=str, default=\"\\\"\\'.。,，!！?？:：”)]}、\", help=\"if word_timestamps is True, merge these punctuation symbols with the previous word\")\n    parser.add_argument(\"--highlight_words\", type=str2bool, default=False, help=\"(requires --word_timestamps True) underline each word as it is spoken in srt and vtt\")\n    parser.add_argument(\"--max_line_width\", type=optional_int, default=None, help=\"(requires --word_timestamps True) the maximum number of characters in a line before breaking the line\")\n    parser.add_argument(\"--max_line_count\", type=optional_int, default=None, help=\"(requires --word_timestamps True) the maximum number of lines in a segment\")\n    parser.add_argument(\"--max_words_per_line\", type=optional_int, default=None, help=\"(requires --word_timestamps True, no effect with --max_line_width) the maximum number of words in a segment\")\n    parser.add_argument(\"--threads\", type=optional_int, default=0, help=\"number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS\")\n    parser.add_argument(\"--clip_timestamps\", type=str, default=\"0\", help=\"comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process, where the last end timestamp defaults to the end of the file\")\n    parser.add_argument(\"--hallucination_silence_threshold\", type=optional_float, help=\"(requires --word_timestamps True) skip silent periods longer than this threshold (in seconds) when a possible hallucination is detected\")\n\n    return parser.parse_args().__dict__\n\n\nif __name__ == \"__main__\":\n    ddp_setup(RANK, WORLD_SIZE)\n    input_dir = Path(\"input\")\n    output_dir = Path(\"output\")\n    output_dir.mkdir(exist_ok=True)\n\n    args = get_args()\n    model_name = \"large-v3\"\n    model_dir = args[\"model_dir\"]\n    output_format = \"all\"\n    device = \"cuda\"\n    args[\"language\"] = \"Japanese\"\n\n    args.pop(\"model\")\n    args.pop(\"model_dir\")\n    args.pop(\"output_dir\")\n    args.pop(\"output_format\")\n    args.pop(\"device\")\n    args.pop(\"threads\")\n\n    model = whisper.load_model(\"large-v3\", device=\"cuda\", download_root=model_dir)\n    temperature = args.pop(\"temperature\")\n    if (increment := args.pop(\"temperature_increment_on_fallback\")) is not None:\n        temperature = tuple(np.arange(temperature, 1.0 + 1e-6, increment))\n    else:\n        temperature = [temperature]\n\n    writer = get_writer(output_format, output_dir)\n    word_options = [\n        \"highlight_words\",\n        \"max_line_count\",\n        \"max_line_width\",\n        \"max_words_per_line\",\n    ]\n    args[\"word_timestamps\"] = True\n    if not args[\"word_timestamps\"]:\n        for option in word_options:\n            assert args[option], Exception(\n                f\"--{option} requires --word_timestamps True\"\n            )\n    if args[\"max_line_count\"] and not args[\"max_line_width\"]:\n        warnings.warn(\"--max_line_count has no effect without --max_line_width\")\n    if args[\"max_words_per_line\"] and args[\"max_line_width\"]:\n        warnings.warn(\"--max_words_per_line has no effect with --max_line_width\")\n    writer_args = {arg: args.pop(arg) for arg in word_options}\n\n    dataset = input_files(input_dir)\n    loop = DataLoader(\n        dataset,\n        batch_size=1,\n        sampler=DistributedSampler(dataset, shuffle=False),\n    )\n    if not RANK:\n        loop = tqdm(loop)\n    for audio_path in loop:\n        assert len(audio_path) == 1\n        audio_path = audio_path[0]\n        result = transcribe(\n            model, audio_path.__str__(), temperature=temperature, **args\n        )\n        writer(result, audio_path, **writer_args)\n        # try:\n        #     result = transcribe(model, audio_path.__str__(), temperature=temperature, **args)\n        #     writer(result, audio_path, **writer_args)\n        # except Exception as e:\n        #     traceback.print_exc()\n        #     print(f\"Skipping {audio_path} due to {type(e).__name__}: {str(e)}\")\n    barrier()\n"
        }
      ],
      "id": "v8waXzoJ",
      "createdAt": 1727510394313,
      "updatedAt": 1727511239340
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "mp3 extractor",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import subprocess\nfrom pathlib import Path\nimport os\nimport sys\nfrom multiprocessing.pool import Pool\n\n\ndef mp3_extractor(input, output):\n    subprocess.run(\n        [\n            \"ffmpeg.exe\",\n            \"-i\",\n            input,\n            \"-vn\",\n            \"-c:a\",\n            \"mp3\",\n            output,\n        ]\n    )\n\n\nif __name__ == \"__main__\":\n    ROOT = Path(__file__).parent.parent\n    mp3_dir = ROOT / \"mp3\"\n    mp3_dir.mkdir(exist_ok=True)\n    with Pool(16) as pool:\n        for file in os.listdir(ROOT):\n            file = ROOT / file\n            if file.suffix != \".mp4\":\n                continue\n            input = file.absolute().__str__()\n            output = (mp3_dir / f\"{file.stem}.mp3\").absolute().__str__()\n            pool.apply_async(mp3_extractor, args=(input, output))\n        pool.close()\n        pool.join()\n"
        }
      ],
      "id": "wthzwaeG",
      "createdAt": 1727512632091,
      "updatedAt": 1727512640972
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "未命名程式碼片段",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": ""
        }
      ],
      "id": "YOzeI46J",
      "createdAt": 1729164388322,
      "updatedAt": 1729164388322
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "hamming",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import torch\n\ndef hamming_distance_batchwise(hamming_codes):\n    \"\"\"\n    计算 m 个二进制向量两两之间的海明距离\n    :param hamming_codes: 二进制向量张量，形状为 [m, embedding_size]\n    :return: 海明距离矩阵，形状为 [m, m]\n    \"\"\"\n    m = hamming_codes.size(0)\n    \n    # 扩展维度，使每个向量可以与其他所有向量进行比较\n    # 形状从 [m, embedding_size] 变成 [m, 1, embedding_size] 和 [1, m, embedding_size]\n    hamming_codes_1 = hamming_codes.unsqueeze(1)  # [m, 1, embedding_size]\n    hamming_codes_2 = hamming_codes.unsqueeze(0)  # [1, m, embedding_size]\n    \n    # 进行逐位异或操作，得到异或结果矩阵，形状为 [m, m, embedding_size]\n    xor_result = torch.bitwise_xor(hamming_codes_1, hamming_codes_2)\n    \n    # 统计异或结果中 1 的数量，即海明距离\n    # 最后结果是 [m, m] 的矩阵，其中每个元素是对应向量之间的海明距离\n    hamming_distances = torch.sum(xor_result, dim=-1)\n    \n    return hamming_distances\n\n# 测试\nhamming_codes = torch.tensor([[0, 0, 1, 1, 0, 1, 1], \n                              [1, 0, 0, 1, 1, 0, 1], \n                              [1, 1, 1, 0, 0, 0, 1]], dtype=torch.int64)\n\n# 计算两两之间的海明距离矩阵\nhamming_distances = hamming_distance_batchwise(hamming_codes)\nprint(\"Hamming distance matrix:\\n\", hamming_distances)\n"
        }
      ],
      "id": "1V9l10Wh",
      "createdAt": 1729164391321,
      "updatedAt": 1729164399413
    }
  ],
  "tags": [
    {
      "name": "normal usage",
      "id": "7xSxQ3Xg",
      "createdAt": 1705650814819,
      "updatedAt": 1705650814819
    }
  ]
}