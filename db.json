{
  "folders": [
    {
      "id": "FFoy_tpD",
      "name": "Default",
      "defaultLanguage": "typescript",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "createdAt": 1705547730793,
      "updatedAt": 1705547730793,
      "index": 0
    },
    {
      "name": "js",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "plain_text",
      "id": "8qmQazwt",
      "createdAt": 1705547881037,
      "updatedAt": 1705547887416,
      "index": 1
    },
    {
      "name": "nodejs",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "plain_text",
      "id": "OtjZFwbc",
      "createdAt": 1705559758412,
      "updatedAt": 1705559762435,
      "index": 2
    },
    {
      "name": "python",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "python",
      "id": "weWtbZI4",
      "createdAt": 1705649797466,
      "updatedAt": 1709526488611,
      "index": 3
    },
    {
      "name": "linux",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "sh",
      "id": "NCg2YrWJ",
      "createdAt": 1705655890816,
      "updatedAt": 1709526511683,
      "index": 4
    },
    {
      "name": "web",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "plain_text",
      "id": "fA481292",
      "createdAt": 1705739854728,
      "updatedAt": 1705739858907,
      "index": 5
    },
    {
      "name": "ts",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "typescript",
      "id": "RxpfS9zV",
      "createdAt": 1709687889308,
      "updatedAt": 1709687938343,
      "index": 6
    },
    {
      "name": "cmd",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "powershell",
      "id": "HRD2NCV8",
      "createdAt": 1711067461127,
      "updatedAt": 1711067487711,
      "index": 7
    },
    {
      "name": "algo",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "c_cpp",
      "id": "4ojt5eME",
      "createdAt": 1720877654533,
      "updatedAt": 1720877817895,
      "index": 8
    },
    {
      "name": "deeplearning",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "python",
      "id": "DvcfGvIx",
      "createdAt": 1724574331649,
      "updatedAt": 1724574577063,
      "index": 9
    },
    {
      "name": "java",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "java",
      "id": "PoO2O3Rm",
      "createdAt": 1729592825287,
      "updatedAt": 1729592889036
    },
    {
      "name": "android",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "kotlin",
      "id": "twJ-w0RU",
      "createdAt": 1729995664649,
      "updatedAt": 1729995682092
    },
    {
      "name": "sql",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "mysql",
      "id": "mdpwqphi",
      "createdAt": 1730010819388,
      "updatedAt": 1730010903566
    },
    {
      "name": "opencv",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "python",
      "id": "mgv1LCgf",
      "createdAt": 1737197456615,
      "updatedAt": 1737197590829
    },
    {
      "name": "regex",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "plain_text",
      "id": "7IuFDFml",
      "createdAt": 1737547307056,
      "updatedAt": 1737547323213
    },
    {
      "name": "ja",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "markdown",
      "id": "VCkpA7ri",
      "createdAt": 1740032485076,
      "updatedAt": 1740032508487
    },
    {
      "name": "note",
      "parentId": null,
      "isOpen": false,
      "isSystem": false,
      "defaultLanguage": "markdown",
      "id": "PgWKBdHD",
      "createdAt": 1742960538371,
      "updatedAt": 1742960555014
    }
  ],
  "snippets": [
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "8qmQazwt",
      "tagsIds": [],
      "description": null,
      "name": "xhr",
      "content": [
        {
          "label": "get",
          "language": "javascript",
          "value": "function loadDoc() {\n    // 第一步： 创建xhr对象\n    let xhr = new XMLHttpRequest();\n    // 第二步： 调用open函数 指定请求方式 与URL地址\n    xhr.open('GET', '/demo/music_list.xml', true);\n    // 第三步： 调用send函数 发起ajax请求\n    xhr.send();\n    // 第四步： 监听onreadystatechange事件\n    xhr.onreadystatechange = function () {\n        // 监听xhr对象的请求状态 与服务器的响应状态\n        if (this.readyState == 4 && this.status == 200) {\n            // 如果响应就绪的话，就创建表格(拿到了服务器响应回来的数据xhr.responseText)\n            myFunction(this)\n        }\n    }\n}\n\nxhr.open('GET', 'http://www.liulongbin.top:3006/api/getbooks?id=1')\n"
        },
        {
          "label": "post-formdata",
          "language": "javascript",
          "value": "// 第一步： 创建xhr对象\nlet xhr = new XMLHttpRequest();\n// 第二步： 调用open函数\nxhr.open('POST', 'http://www.liulongbin.top:3006/api/addbook')\n// 第三步： 设置Content-Type属性 （这一步是固定的写法）\nxhr.setRequestHeader('Conten-Type', 'application/x-www-form-urlencoded')\n// 第四步： 调用send（）函数，同时将数据以查询字符串的形式，提交给服务器\nxhr.send('bookname=水浒传&author=施耐庵&publisher=天津图书出版社')\n// 第五步：监听onreadystatechange事件\nxhr.onreadystatechange = function () {\n    if (xhr.readyState === 4 && xhr.status === 200) {\n        console.log(xhr.responseText)\n    }\n}"
        },
        {
          "label": "post-json",
          "language": "javascript",
          "value": "const xhr = new XMLHttpRequest()\n\n// listen for `load` event\nxhr.onload = () => {\n  // print JSON response\n  if (xhr.status >= 200 && xhr.status < 300) {\n    // parse JSON\n    const response = JSON.parse(xhr.responseText)\n    console.log(response)\n  }\n}\n\n// create a JSON object\nconst json = {\n  email: 'eve.holt@reqres.in',\n  password: 'cityslicka'\n}\n\n// open request\nxhr.open('POST', 'https://reqres.in/api/login')\n\n// set `Content-Type` header\nxhr.setRequestHeader('Content-Type', 'application/json')\n\n// send rquest with JSON payload\nxhr.send(JSON.stringify(json))"
        }
      ],
      "id": "jWmi9e8d",
      "createdAt": 1705547901298,
      "updatedAt": 1705548171733
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "8qmQazwt",
      "tagsIds": [],
      "description": null,
      "name": "ajax",
      "content": [
        {
          "label": "get",
          "language": "javascript",
          "value": "$.get('url', {name: 'zs', age: 20}, function() {})\n// 等价于\n$.get('url?name=zs&age=20', function() {})\n\n$.ajax({ method: 'GET', url: 'url', data: {name: 'zs', age: 20}, success: function() {} })\n// 等价于\n$.ajax({ method: 'GET', url: 'url?name=zs&age=20', success: function() {} })"
        },
        {
          "label": "json",
          "language": "plain_text",
          "value": "$.ajax({\n  url: 'example.com/api/data',\n  method: 'GET',\n  dataType: 'json',\n  success: function(data) {\n    // 成功接收到数据后的回调函数\n    // data 参数就是解析后的 JSON 数据\n    console.log(data); // 在控制台中打印数据\n\n    // 以下可以根据需要进行数据处理和展示\n    // 例如，将数据渲染到页面上：\n    var html = '';\n    $.each(data, function(index, item) {\n      html += '<li>' + item.name + '</li>';\n    });\n    $('#list').html(html);\n  },\n  error: function(xhr, status, error) {\n    // 处理请求错误的回调函数\n    console.log(error);\n  }\n});\n"
        }
      ],
      "id": "sAcJDFaN",
      "createdAt": 1705548024545,
      "updatedAt": 1705680788382
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "8qmQazwt",
      "tagsIds": [],
      "description": null,
      "name": "fetch api",
      "content": [
        {
          "label": "post-json",
          "language": "javascript",
          "value": "// create a JSON object\nconst json = {\n  email: 'hi@attacomsian.com',\n  password: '123abc'\n}\n\n// request options\nconst options = {\n  method: 'POST',\n  body: JSON.stringify(json),\n  headers: {\n    'Content-Type': 'application/json'\n  }\n}\n\n// send post request\nfetch('/login', options)\n  .then(res => res.json())\n  .then(res => console.log(res))\n  .catch(err => console.error(err))"
        },
        {
          "label": "get",
          "language": "javascript",
          "value": "fetch('/js/users.json')\n  .then(response => {\n    // handle the response data\n  })\n  .catch(error => {\n    // handle errors\n  })\n  \nfetch('https://reqres.in/api/users')\n  .then(response => response.json())\n  .then(data => {\n    data.data.forEach(user => {\n      console.log(`${user.id}: ${user.first_name} ${user.last_name}`)\n    })\n  })"
        },
        {
          "label": "header",
          "language": "javascript",
          "value": "// create an empty `Headers` object\nconst headers = new Headers()\n\n// add headers\nheaders.append('Content-Type', 'text/plain')\nheaders.append('Accept', 'application/json')\n\n// add custom headers\nheaders.append('X-AT-Platform', 'Desktop')\nheaders.append('X-AT-Source', 'Google Search')\n\n// check if the header exists\nheaders.has('Accept') // true\n\n// get headers\nheaders.get('Accept') // application/json\nheaders.get('X-AT-Source') // Google Search\n\n// update header value\nheaders.set('Content-Type', 'application/json')\n\n// remove headers\nheaders.delete('Content-Type')\nheaders.delete('X-AT-Platform')\n\n// Passing an object literal\nconst headers = new Headers({\n  'Content-Type': 'application/json',\n  Accept: 'application/json'\n})\n\n// OR\n\n// Passing an array of arrays\nconst headers = new Headers([\n  ['Content-Type', 'application/json'],\n  ['Accept', 'application/json']\n])\n\n// >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nconst request = new Request('https://reqres.in/api/users', {\n  headers: headers\n})\n\nfetch(request)\n  .then(res => res.json())\n  .then(json => console.log(json))\n  .catch(err => console.error('Error:', err))"
        }
      ],
      "id": "klHkol_O",
      "createdAt": 1705548237079,
      "updatedAt": 1705681113608
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "OtjZFwbc",
      "tagsIds": [],
      "description": null,
      "name": "Buffer",
      "content": [
        {
          "label": "子片段 1",
          "language": "javascript",
          "value": "let buf = Buffer.alloc(10);"
        }
      ],
      "id": "D1oJIFA5",
      "createdAt": 1705559765903,
      "updatedAt": 1705559826668
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "yaml",
      "content": [
        {
          "label": "read",
          "language": "python",
          "value": "import yaml\n\nwith open('voc.yaml', 'r', encoding='utf8') as f:\n\tdata = yaml.safe_load(f)"
        },
        {
          "label": "write",
          "language": "plain_text",
          "value": "import yaml\n\n# 创建配置字典\nconfig = {\n    'database': {\n        'host': 'localhost',\n        'port': 5432,\n        'name': 'mydb'\n    },\n    'app': {\n        'debug': True,\n        'log_level': 'info'\n    }\n}\n\n# 写入 YAML 文件\nwith open('config.yaml', 'w') as yaml_file:\n    yaml.dump(config, yaml_file)"
        }
      ],
      "id": "Gyt1iP24",
      "createdAt": 1705649805191,
      "updatedAt": 1705649964517
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "ruemal.yaml",
      "content": [
        {
          "label": "read",
          "language": "plain_text",
          "value": "from ruamel.yaml import YAML\nyaml=YAML(typ='safe')\nwith open('conf.yaml', 'r') as yaml_file:\n\tconf = yaml.load(yaml_file)"
        },
        {
          "label": "write",
          "language": "plain_text",
          "value": "import ruemal.yaml\n\n# 创建配置字典\nconfig = {\n    'database': {\n        'host': 'localhost',\n        'port': 5432,\n        'name': 'mydb'\n    },\n    'app': {\n        'debug': True,\n        'log_level': 'info'\n    }\n}\n\n# 写入 YAML 文件\nwith open('config.yaml', 'w') as yaml_file:\n    ruemal.yaml.dump(config, yaml_file)"
        }
      ],
      "id": "veB74x97",
      "createdAt": 1705649919184,
      "updatedAt": 1705827167283
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "argparse",
      "content": [
        {
          "label": "basic",
          "language": "plain_text",
          "value": "import argparse\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--verbose\", help=\"increase output verbosity\",\n                    action=\"store_true\")\nargs = parser.parse_args()"
        },
        {
          "label": "list",
          "language": "python",
          "value": "import argparse\n \nparser = argparse.ArgumentParser()\n \n# By default it will fail with multiple arguments.\nparser.add_argument('--default')\n \n# Telling the type to be a list will also fail for multiple arguments,\n# but give incorrect results for a single argument.\nparser.add_argument('--list-type', type=list)\n \n# This will allow you to provide multiple arguments, but you will get\n# a list of lists which is not desired.\nparser.add_argument('--list-type-nargs', type=list, nargs='+')\n \n# This is the correct way to handle accepting multiple arguments.\n# '+' == 1 or more.\n# '*' == 0 or more.\n# '?' == 0 or 1.\n# An int is an explicit number of arguments to accept.\nparser.add_argument('--nargs', nargs='+')\n \n# To make the input integers\nparser.add_argument('--nargs-int-type', nargs='+', type=int)\n \n# An alternate way to accept multiple inputs, but you must\n# provide the flag once per input. Of course, you can use\n# type=int here if you want.\nparser.add_argument('--append-action', action='append')\n \n# To show the results of the given option to screen.\nfor _, value in parser.parse_args()._get_kwargs():\n    if value is not None:\n        print(value)\n        \n        \n\"\"\"\n$ python arg.py --default 1234 2345 3456 4567\n...\narg.py: error: unrecognized arguments: 2345 3456 4567\n \n$ python arg.py --list-type 1234 2345 3456 4567\n...\narg.py: error: unrecognized arguments: 2345 3456 4567\n \n$ # Quotes won't help here... \n$ python arg.py --list-type \"1234 2345 3456 4567\"\n['1', '2', '3', '4', ' ', '2', '3', '4', '5', ' ', '3', '4', '5', '6', ' ', '4', '5', '6', '7']\n$ python arg.py --list-type-nargs 1234 2345 3456 4567\n[['1', '2', '3', '4'], ['2', '3', '4', '5'], ['3', '4', '5', '6'], ['4', '5', '6', '7']]\n$ python arg.py --nargs 1234 2345 3456 4567\n['1234', '2345', '3456', '4567']\n$ python arg.py --nargs-int-type 1234 2345 3456 4567\n[1234, 2345, 3456, 4567]\n$ # Negative numbers are handled perfectly fine out of the box.\n$ python arg.py --nargs-int-type -1234 2345 -3456 4567\n[-1234, 2345, -3456, 4567]\n$ python arg.py --append-action 1234 --append-action 2345 --append-action 3456 --append-action 4567\n\"\"\""
        }
      ],
      "id": "UP1uoVQH",
      "createdAt": 1705650796734,
      "updatedAt": 1724577088639
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "NCg2YrWJ",
      "tagsIds": [],
      "description": null,
      "name": "nvidia-smi",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "// 调整gpu持久性模式\nsudo nvidia-smi -pm 1\n// 调整gpu最大功率\nsudo nvidia-smi -pl 300"
        }
      ],
      "id": "26X8AOSD",
      "createdAt": 1705655898703,
      "updatedAt": 1705655972195
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "fA481292",
      "tagsIds": [],
      "description": null,
      "name": "http MIME",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "Multipurpose lnternet Mail Extensions:\n\nhtml: text/html\ncss: text/css\njs: text/javascript\npng: image/png\njpg: image/jpeg\ngif: image/gif\nmp4: video/mp4'\nmp3: audio/mpeg\njson: application/json"
        }
      ],
      "id": "HnMsiaZI",
      "createdAt": 1705739861641,
      "updatedAt": 1705740021013
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "jupyter",
      "content": [
        {
          "label": "reload",
          "language": "plain_text",
          "value": "%load_ext autoreload\n%autoreload 2"
        },
        {
          "label": "plot",
          "language": "python",
          "value": "%matplotlib inline"
        }
      ],
      "id": "Wry74Dzx",
      "createdAt": 1705886423955,
      "updatedAt": 1711760156929
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Path",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "file = Path('/root/data/voc.yaml')\nfile.stem => 'voc'"
        }
      ],
      "id": "5e0YC450",
      "createdAt": 1706190040944,
      "updatedAt": 1706190107535
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "supression warning",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "import warnings\n\nwarnings.filterwarnings('ignore')\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)"
        }
      ],
      "id": "8qlwmnmh",
      "createdAt": 1706193575402,
      "updatedAt": 1715651037810
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "numpy",
      "content": [
        {
          "label": "dim+",
          "language": "plain_text",
          "value": "ann = np.expand_dims(ann,0)"
        },
        {
          "label": "min-max",
          "language": "plain_text",
          "value": "np.clip(a, 1, 8)"
        },
        {
          "label": "eu dist",
          "language": "python",
          "value": "def euclidean_distance(u, v):\n    \"\"\"\n    Returns the euclidean distance between vectors u and v. This is equivalent\n    to the length of the vector (u - v).\n    \"\"\"\n    diff = u - v\n    # return sqrt(numpy.dot(diff, diff.T))\n    return np.sum(np.diag(np.sqrt(np.dot(diff, diff.T))))"
        },
        {
          "label": "diag",
          "language": "plain_text",
          "value": "x=np.array([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\nnp.diag(x) => array([0, 4, 8])"
        }
      ],
      "id": "ZhL1nAet",
      "createdAt": 1706504886238,
      "updatedAt": 1706580864691
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "matplotlib",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# matplotlib折线图（标记点、标记点大小、标记点边颜色、标记点边宽\nfrom matplotlib import pyplot as plt\nx = range(1,10) #x轴的位置\ny = [6,7,12,12,15,17,15,20,18] #y轴的位置\n#传入x,y，通过plot画图,并设置折线颜色、透明度、折线样式和折线宽度  标记点、标记点大小、标记点边颜色、标记点边宽\nplt.plot(x,y,color='red',alpha=0.3,linestyle='--',linewidth=5,marker='o'\n         ,markeredgecolor='r',markersize='20',markeredgewidth=10)\nplt.show()\n"
        }
      ],
      "id": "ZKxV4l_b",
      "createdAt": 1706538922876,
      "updatedAt": 1706538967381
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "torch",
      "content": [
        {
          "label": "cuda cache",
          "language": "plain_text",
          "value": "torch.cuda.empty_cache()"
        },
        {
          "label": "ddp",
          "language": "python",
          "value": "import torch\nimport torch.nn.functional as F\nfrom utils import MyTrainDataset\n\nimport torch.multiprocessing as mp\nimport torch.distributed as dist\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.distributed import init_process_group, destroy_process_group, get_rank\nimport os\n\nLOCAL_RANK = int(\n    os.getenv(\"LOCAL_RANK\", -1)\n)  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\n\ndef ddp_setup(rank: int, world_size: int):\n    \"\"\"\n    Args:\n        rank: Unique identifier of each process\n    world_size: Total number of processes\n    \"\"\"\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"12355\"\n    torch.cuda.set_device(rank)\n    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n\n    train_data = torch.utils.data.DataLoader(\n        dataset=train_dataset,\n        batch_size=32,\n        shuffle=False,\n        sampler=DistributedSampler(train_dataset),\n    )\n\ndef _run_epoch(self, epoch):\n    b_sz = len(next(iter(self.train_data))[0])\n    self.train_data.sampler.set_epoch(epoch)\n    for source, targets in self.train_data:\n        ...\n        self._run_batch(source, targets)\n\ndef save_model(model, epoch, save_every):\n    def _save_checkpoint(ckp):\n        ...\n        pass\n\n    ckp = model.module.state_dict()\n    ...\n    ...\n    if get_rank() == 0 and epoch % save_every == 0:\n        _save_checkpoint(ckp)\n    \n    dist.barrier()\n    return\n\ndef main(rank, world_size, total_epochs, save_every):\n    ddp_setup(rank, world_size)\n    dataset, model, optimizer = load_train_objs()\n    train_data = prepare_dataloader(dataset, batch_size=32)\n    trainer = Trainer(model, train_data, optimizer, rank, save_every)\n    trainer.train(total_epochs)\n    destroy_process_group()\n\nif __name__ == \"__main__\":\n    import sys\n    total_epochs = int(sys.argv[1])\n    save_every = int(sys.argv[2])\n    world_size = WORLD_SIZE\n    mp.spawn(main, args=(LOCAL_RANK, world_size, total_epochs, save_every,), nprocs=world_size)"
        }
      ],
      "id": "iUBzP4mv",
      "createdAt": 1706543184905,
      "updatedAt": 1746426061833
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "@thread",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "def threaded(func):\n    \"\"\"\n    Multi-threads a target function by default and returns the thread or function result.\n\n    Use as @threaded decorator. The function runs in a separate thread unless 'threaded=False' is passed.\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        \"\"\"Multi-threads a given function based on 'threaded' kwarg and returns the thread or function result.\"\"\"\n        if kwargs.pop(\"threaded\", True):  # run in thread\n            thread = threading.Thread(target=func, args=args, kwargs=kwargs, daemon=True)\n            thread.start()\n            return thread\n        else:\n            return func(*args, **kwargs)\n\n    return wrapper"
        }
      ],
      "id": "CBAeSmOT",
      "createdAt": 1706544304341,
      "updatedAt": 1706544314752
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "multiprocessing",
      "content": [
        {
          "label": "apply_async",
          "language": "plain_text",
          "value": "#apply  (阻塞，同步方式)\nfrom  multiprocessing import Pool\nimport time\n \n#apply_async   (非阻塞，异步方式)\ndef f1(i):\n    time.sleep(0.5)\n    print(i)\n    return i + 100\ndef f2(arg):\n    print(arg)\n \nif __name__ == \"__main__\":\n    pool = Pool(5)\n    for i in range(1,31):\n        pool.apply_async(func=f1,args=(i,),callback=f2)\n    pool.close()\n    pool.join()\n"
        },
        {
          "label": "cpu_count",
          "language": "plain_text",
          "value": "from multiprocessing import cpu_count\n\nprint(\"CPU的核数为：{}\".format(cpu_count()))\nprint(type(cpu_count()))"
        },
        {
          "label": "submit",
          "language": "plain_text",
          "value": "from concurrent.futures import ProcessPoolExecutor\nimport  time\ndef task(name):\n    print(\"name\",name)\n    time.sleep(1)\n\nif __name__ == \"__main__\":\n    start = time.time()\n    ex = ProcessPoolExecutor(2)\n\n    for i in range(5):\n        ex.submit(task,\"safly%d\"%i)\n    ex.shutdown(wait=True)\n\n    print(\"main\")\n    end = time.time()\n    print(end - start)"
        },
        {
          "label": "map",
          "language": "plain_text",
          "value": "from multiprocessing import Pool\n\ndef f(x):\n    return x*x\n\nif __name__ == '__main__':\n    with Pool(5) as p:\n        print(p.map(f, [1, 2, 3]))"
        },
        {
          "label": "apply",
          "language": "plain_text",
          "value": "#apply  (阻塞，同步方式)\nfrom  multiprocessing import Pool\nimport time\n \ndef f1(i):\n    time.sleep(0.5)\n    print(i)\n    return i + 100\n \nif __name__ == \"__main__\":\n    pool = Pool(5)\n    for i in range(1,31):\n        pool.apply(func=f1,args=(i,))"
        },
        {
          "label": "imap",
          "language": "python",
          "value": "from tqdm import tqdm    \nfrom torch.multiprocessing import Pool\n\nwith Pool(15) as pool:\n    results = pool.imap(func=get_image_sm, iterable=zip(repeat(path), image_list))\n    pbar = tqdm(results, desc=\"calc\", total=len(image_list))\n    for result in pbar:\n        if isinstance(result, tuple):\n            img_count += 1\n            mean += result[0]\n            std += result[1]\n            pbar.set_postfix({\"mean\": mean / img_count, \"std\": std / img_count})\n        else:\n            print(result)\n    pbar.close()"
        }
      ],
      "id": "CUsUEUiX",
      "createdAt": 1706577534588,
      "updatedAt": 1724908222026
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "concurrent",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed, wait, ALL_COMPLETED\nimport time, random, os\n\ndef piao(name, n):\n    print('%s is piaoing %s' % (name, os.getpid()))\n    time.sleep(1)\n    return n ** 2\n\n\nif __name__ == '__main__':\n\t\t########################################\n    p = ProcessPoolExecutor(2)\n    objs = []\n    start = time.time()\n    for i in range(5):\n        obj = p.submit(piao, 'safly %s' % i, i)  # 异步调用\n        objs.append(obj)\n\n    p.shutdown(wait=True)\n    print('主', os.getpid())\n    for obj in objs:\n        print(obj.done())\n        print(obj.result(timeout=None))\n\n    stop = time.time()\n    print(stop - start)\n\t\t########################################\n    p = ThreadPoolExecutor(2)\n    objs = []\n    start = time.time()\n    for i in range(5):\n        obj = p.submit(piao, '%s' % i, i)  # 异步调用\n        objs.append(obj)\n\n    print('主', os.getpid())\n    for obj in as_completed(objs):\n        print(obj.result())\n\t\t########################################\n    p = ThreadPoolExecutor(2)\n    objs = []\n    start = time.time()\n    for i in range(5):\n        obj = p.submit(piao, '%s' % i, i)  # 异步调用\n        objs.append(obj)\n\n    print('主', os.getpid())\n    wait(objs, return_when=ALL_COMPLETED)\n    for obj in objs:\n        print(obj.done())\n        print(obj.result(timeout=None))\n\n    stop = time.time()\n    print(stop - start)\n    p.shutdown(wait=True)"
        }
      ],
      "id": "v00hMsQs",
      "createdAt": 1706578242881,
      "updatedAt": 1727002786295
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "未命名程式碼片段",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": ""
        }
      ],
      "id": "RYf5I8fv",
      "createdAt": 1706580332307,
      "updatedAt": 1706580336957
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "OtjZFwbc",
      "tagsIds": [],
      "description": null,
      "name": "guard process",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "var fork = require('child_process').fork;\n\n//保存被子进程实例数组\nvar workers = [];\n\n//这里的被子进程理论上可以无限多\nvar appsPath = ['./app.js'];\n\nvar createWorker = function(appPath){\n　　//保存fork返回的进程实例\n　　var worker = fork(appPath);\n\n　　//监听子进程exit事件\n　　worker.on('exit',function(){\n　　　　console.log('worker:' + worker.pid + 'exited');\n　　　　delete workers[worker.pid];\n　　　　createWorker(appPath);\n　　 });\n\n　　workers[worker.pid] = worker;\n　　console.log('Create worker:' + worker.pid);\n};\n\n//启动所有子进程\nfor (var i = appsPath.length - 1; i >= 0; i--) {\n　　createWorker(appsPath[i]);\n}\n\n//父进程退出时杀死所有子进程\nprocess.on('exit',function(){\n　　 for(var pid in workers){\n　　　　workers[pid].kill();\n　　}\n});"
        }
      ],
      "id": "24sDH8Hh",
      "createdAt": 1706666147942,
      "updatedAt": 1706666155658
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "pickle",
      "content": [
        {
          "label": "dump",
          "language": "plain_text",
          "value": "with open('data.pickle', 'wb') as f:\n    pickle.dump(data, f)"
        },
        {
          "label": "dumps",
          "language": "plain_text",
          "value": "import pickle\ndic = {\"k1\":\"v1\",\"k2\":123}\ns = pickle.dumps(dic)\nprint(s)"
        },
        {
          "label": "load",
          "language": "plain_text",
          "value": "with open('data.pickle', 'rb') as f:\n    data = pickle.load(f)"
        },
        {
          "label": "loads",
          "language": "plain_text",
          "value": "import pickle\ndic = {\"k1\":\"v1\",\"k2\":123}\ns = pickle.dumps(dic)\ndic2 = pickle.loads(s)\nprint(dic2)"
        }
      ],
      "id": "gw3WAZqO",
      "createdAt": 1708936622268,
      "updatedAt": 1708936691956
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "progress",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# coding=utf-8\nfrom progress.bar import Bar\nimport time\n\n# 创建Bar类的实例\nbar = Bar('MyProcess:', max=100)\n# 循环处理某业务，调用bar对象的next()方法，循环次数等于max\nfor _ in range(100):\n # Do some work\n    time.sleep(0.05)\n    bar.next()\n# 循环完成后调用finish()方法\nbar.finish()\n\n\nwith Bar('Processing', max=20) as bar:\n    for i in range(20):\n        time.sleep(0.05)\n        bar.next()\n        \nfor i in Bar(\n    \t\tf\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(range(100)):\n    time.sleep(0.05)"
        },
        {
          "label": "sys.out/sys.flush",
          "language": "python",
          "value": "sys.stdout.write(f\"\\rLength: {length}\")  # 使用sys.stdout.write和sys.stdout.flush来更新长度\nsys.stdout.flush()"
        }
      ],
      "id": "54MBrGJN",
      "createdAt": 1709098599140,
      "updatedAt": 1738335905954
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "get_VOC_ds",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import xml.etree.ElementTree as ET\n\nfrom tqdm import tqdm\nfrom ultralytics.utils.downloads import download\nfrom pathlib import Path\nimport yaml as yl\nimport numpy as np\nimport copy\nfrom progress.bar import Bar\nimport os\nimport subprocess\n\nwith open(\"voc.yaml\", \"r\", encoding=\"utf8\") as f:\n    yaml = yl.safe_load(f)\n\n\ndef convert_label(path, lb_path, year, image_id, tho=0, class_filter=None):\n    def convert_box(size, box):\n        dw, dh = 1.0 / size[0], 1.0 / size[1]\n        x, y, w, h = (\n            (box[0] + box[1]) / 2.0 - 1,\n            (box[2] + box[3]) / 2.0 - 1,\n            box[1] - box[0],\n            box[3] - box[2],\n        )\n        return x * dw, y * dh, w * dw, h * dh\n\n    in_file = open(path / f\"VOC{year}/Annotations/{image_id}.xml\")\n    out_file = open(lb_path, \"w\")\n    tree = ET.parse(in_file)\n    root = tree.getroot()\n    size = root.find(\"size\")\n    w = int(size.find(\"width\").text)\n    h = int(size.find(\"height\").text)\n\n    names = list(yaml[\"names\"].values())  # names list\n    for obj in root.iter(\"object\"):\n        cls = obj.find(\"name\").text\n        if cls in names and int(obj.find(\"difficult\").text) != 1:\n            xmlbox = obj.find(\"bndbox\")\n            bb = convert_box(\n                (w, h),\n                [float(xmlbox.find(x).text) for x in (\"xmin\", \"xmax\", \"ymin\", \"ymax\")],\n            )\n            cls_id = names.index(cls)  # class id\n            if class_filter:\n                if class_filter(cls_id):\n                    out_file.write(\" \".join(str(a) for a in (cls_id, *bb)) + \"\\n\")\n            else:\n                if np.random.random() >= tho:\n                    out_file.write(\" \".join(str(a) for a in (cls_id, *bb)) + \"\\n\")\n                else:\n                    out_file.write(\" \".join(str(a) for a in (0, *bb)) + \"\\n\")\n\n\n# Download\ndir = Path(yaml[\"path\"])  # dataset root dir\n# url = 'https://mirror.ghproxy.com/github.com/ultralytics/yolov5/releases/download/v1.0/'\nurl = \"https://github.com/ultralytics/yolov5/releases/download/v1.0/\"\nurls = [\n    f\"{url}VOCtrainval_06-Nov-2007.zip\",  # 446MB, 5012 images\n    f\"{url}VOCtest_06-Nov-2007.zip\",  # 438MB, 4953 images\n    f\"{url}VOCtrainval_11-May-2012.zip\",\n]  # 1.95GB, 17126 images\n# download(\n#     urls,\n#     dir=dir / \"images\",\n#     curl=True,\n#     threads=1,\n#     exist_ok=True,\n# )  # download and unzip over existing paths (required)\n\n# Convert origin\ndir = Path(yaml[\"path\"]) / \"origin\"\nos.makedirs(dir, exist_ok=True)\nsubprocess.run(\n    [\n        \"rsync\",\n        \"-auvrt\",\n        str((Path(yaml[\"path\"]) / \"images\").absolute()),\n        str(dir.absolute()),\n    ]\n)\npath = dir / \"images/VOCdevkit\"\nfor year, image_set in (\n    (\"2012\", \"train\"),\n    (\"2012\", \"val\"),\n    (\"2007\", \"train\"),\n    (\"2007\", \"val\"),\n    (\"2007\", \"test\"),\n):\n    imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n    lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n    imgs_path.mkdir(exist_ok=True, parents=True)\n    lbs_path.mkdir(exist_ok=True, parents=True)\n\n    with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n        image_ids = f.read().strip().split()\n    for id in Bar(\n        f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(image_ids):\n        f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n        lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n        f.rename(imgs_path / f.name)  # move image\n        convert_label(path, lb_path, year, id)  # convert labels to YOLO format\n    new_yaml = copy.deepcopy(yaml)\n    new_yaml[\"path\"] = dir.absolute()\n    with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n        yl.dump(new_yaml, yaml_file)\n\n# Convert zen obj\ndir = Path(yaml[\"path\"]) / \"obj\"  # dataset root dir\nos.makedirs(dir, exist_ok=True)\nsubprocess.run(\n    [\n        \"rsync\",\n        \"-auvrt\",\n        str((Path(yaml[\"path\"]) / \"images\").absolute()),\n        str(dir.absolute()),\n    ]\n)\npath = dir / \"images/VOCdevkit\"\nfor year, image_set in (\n    (\"2012\", \"train\"),\n    (\"2012\", \"val\"),\n    (\"2007\", \"train\"),\n    (\"2007\", \"val\"),\n    (\"2007\", \"test\"),\n):\n    imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n    lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n    imgs_path.mkdir(exist_ok=True, parents=True)\n    lbs_path.mkdir(exist_ok=True, parents=True)\n\n    with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n        image_ids = f.read().strip().split()\n    for id in Bar(\n        f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(image_ids):\n        f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n        lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n        f.rename(imgs_path / f.name)  # move image\n        convert_label(path, lb_path, year, id, tho=1)  # convert labels to YOLO format\n    new_yaml = copy.deepcopy(yaml)\n    new_yaml[\"path\"] = dir.absolute()\n    new_yaml[\"names\"] = {0: \"unknown object\"}\n    for i in range(len(yaml[\"names\"])):\n        new_yaml[i + 1] = yaml[\"names\"][i]\n    with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n        yl.dump(new_yaml, yaml_file)\n\n# Convert han obj\ndir = Path(yaml[\"path\"]) / \"obj_50pa\"  # dataset root dir\nos.makedirs(dir, exist_ok=True)\nsubprocess.run(\n    [\n        \"rsync\",\n        \"-auvrt\",\n        str((Path(yaml[\"path\"]) / \"images\").absolute()),\n        str(dir.absolute()),\n    ]\n)\npath = dir / \"images/VOCdevkit\"\nfor year, image_set in (\n    (\"2012\", \"train\"),\n    (\"2012\", \"val\"),\n    (\"2007\", \"train\"),\n    (\"2007\", \"val\"),\n    (\"2007\", \"test\"),\n):\n    imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n    lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n    imgs_path.mkdir(exist_ok=True, parents=True)\n    lbs_path.mkdir(exist_ok=True, parents=True)\n\n    with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n        image_ids = f.read().strip().split()\n    for id in Bar(\n        f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n    ).iter(image_ids):\n        f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n        lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n        f.rename(imgs_path / f.name)  # move image\n        convert_label(path, lb_path, year, id, tho=0.5)  # convert labels to YOLO format\n    new_yaml = copy.deepcopy(yaml)\n    new_yaml[\"path\"] = dir.absolute()\n    new_yaml[\"names\"] = {0: \"unknown object\"}\n    for i in range(len(yaml[\"names\"])):\n        new_yaml[i + 1] = yaml[\"names\"][i]\n    with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n        yl.dump(new_yaml, yaml_file)\n\n# Convert continous learning dataset\nclass_stage = [[0, 6], [6, 13], [13, 20]]\nfor i, j in class_stage:\n    class_filter_testval = lambda x: x < j\n    class_filter_train = lambda x: x >= i and x < j\n    dir = Path(yaml[\"path\"]) / f\"split_{i}_{j}\"  # dataset root dir\n    os.makedirs(dir, exist_ok=True)\n    subprocess.run(\n        [\n            \"rsync\",\n            \"-auvrt\",\n            str((Path(yaml[\"path\"]) / \"images\").absolute()),\n            str(dir.absolute()),\n        ]\n    )\n    path = dir / \"images/VOCdevkit\"\n    for year, image_set in (\n        (\"2012\", \"train\"),\n        (\"2012\", \"val\"),\n        (\"2007\", \"train\"),\n        (\"2007\", \"val\"),\n        (\"2007\", \"test\"),\n    ):\n        imgs_path = dir / \"images\" / f\"{image_set}{year}\"\n        lbs_path = dir / \"labels\" / f\"{image_set}{year}\"\n        imgs_path.mkdir(exist_ok=True, parents=True)\n        lbs_path.mkdir(exist_ok=True, parents=True)\n\n        with open(path / f\"VOC{year}/ImageSets/Main/{image_set}.txt\") as f:\n            image_ids = f.read().strip().split()\n\n        for id in Bar(\n            f\"{image_set}{year}\", bar_prefix=\" [\", bar_suffix=\"] \", fill=\">\"\n        ).iter(image_ids):\n            f = path / f\"VOC{year}/JPEGImages/{id}.jpg\"  # old img path\n            lb_path = (lbs_path / f.name).with_suffix(\".txt\")  # new label path\n            f.rename(imgs_path / f.name)  # move image\n            convert_label(\n                path,\n                lb_path,\n                year,\n                id,\n                class_filter=(\n                    class_filter_testval if image_set == \"test\" else class_filter_train\n                ),\n            )  # convert labels to YOLO format\n        new_yaml = copy.deepcopy(yaml)\n        new_yaml[\"path\"] = dir.absolute()\n        new_yaml[\"names\"] = {}\n        for ii in range(j):\n            new_yaml[ii] = yaml[\"names\"][ii]\n        with open(str(dir / \"data.yaml\"), \"w\") as yaml_file:\n            yl.dump(new_yaml, yaml_file)\n"
        }
      ],
      "id": "SRdwFBY0",
      "createdAt": 1709358035263,
      "updatedAt": 1724662697548
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "NCg2YrWJ",
      "tagsIds": [],
      "description": null,
      "name": "shell echo font",
      "content": [
        {
          "label": "color",
          "language": "plain_text",
          "value": "字体颜色\n字体颜色：30-37\n\n默认=0\n黑色=30\n红色=31\n绿色=32\n黄色=33\n蓝色=34\n紫色=35\n天蓝色（青色）=36\n白色=37\n# echo -e \"\\e[30m 黑色 \\e[0m\"\n# echo -e \"\\e[31m 红色 \\e[0m\"\n# echo -e \"\\e[32m 绿色 \\e[0m\"\n# echo -e \"\\e[33m 黄色 \\e[0m\"\n# echo -e \"\\e[34m 蓝色 \\e[0m\"\n# echo -e \"\\e[35m 紫色 \\e[0m\"\n# echo -e \"\\e[36m 青色 \\e[0m\"\n# echo -e \"\\e[37m 白色 \\e[0m\"\n\n背景颜色\n背景颜色：40-47\n\n默认=0\n黑色=40\n红色=41\n绿色=42\n黄色=43\n蓝色=44\n紫色=45\n天蓝色（青色）=46\n白色=47\n# echo -e \"\\e[40m 黑底 \\e[0m\"\n# echo -e \"\\e[41m 红底 \\e[0m\"\n# echo -e \"\\e[42m 绿底 \\e[0m\"\n# echo -e \"\\e[43m 黄底 \\e[0m\"\n# echo -e \"\\e[44m 蓝底 \\e[0m\"\n# echo -e \"\\e[45m 紫底 \\e[0m\"\n# echo -e \"\\e[46m 青底 \\e[0m\"\n# echo -e \"\\e[47m 白底 \\e[0m\"\n\n黑底彩色\n黑底彩色：90-97\n\n黑=90\n深红=91\n绿=92\n黄色=93\n蓝色=94\n紫色=95\n深绿（青色）=96\n白色=97\n# echo -e \"\\e[90m 黑底黑字 \\e[0m\"\n# echo -e \"\\e[91m 黑底红字 \\e[0m\"\n# echo -e \"\\e[92m 黑底绿字 \\e[0m\"\n# echo -e \"\\e[93m 黑底黄字 \\e[0m\"\n# echo -e \"\\e[94m 黑底蓝字 \\e[0m\"\n# echo -e \"\\e[95m 黑底紫字 \\e[0m\"\n# echo -e \"\\e[96m 黑底青字 \\e[0m\"\n# echo -e \"\\e[97m 黑底白字 \\e[0m\"\n\n## 字体控制选项\n\\e[0m 关闭所有属性\n\\e[1m 设置高亮度\n\\e[4m 下划线\n\\e[5m 闪烁\n\\e[7m 反显，撞色显示，显示为白字黑底，或者显示为黑底白字\n\\e[8m 消影，字符颜色将会与背景颜色相同\n\\e[nA 光标上移 n 行\n\\e[nB 光标下移 n 行\n\\e[nC 光标右移 n 行\n\\e[nD 光标左移 n 行\n\\e[y;xH 设置光标位置\n\\e[2J 清屏\n\\e[K 清除从光标到行尾的内容\n\\e[s 保存光标位置\n\\e[u 恢复光标位置\n\\e[?25 隐藏光标\n\\e[?25h 显示光标"
        },
        {
          "label": "子片段 2",
          "language": "plain_text",
          "value": ""
        }
      ],
      "id": "blnb3Iy1",
      "createdAt": 1709523344717,
      "updatedAt": 1709523454756
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "NCg2YrWJ",
      "tagsIds": [],
      "description": null,
      "name": "tput",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "tput Color Capabilities:\n\ntput setab [0-7] – Set a background color using ANSI escape\ntput setb [0-7] – Set a background color\ntput setaf [0-7] – Set a foreground color using ANSI escape\ntput setf [0-7] – Set a foreground color\n\nColor Code for tput:\n\n0 – Black\n1 – Red\n2 – Green\n3 – Yellow\n4 – Blue\n5 – Magenta\n6 – Cyan\n7 – White\n\ntput Text Mode Capabilities:\n\ntput bold – Set bold mode\ntput dim – turn on half-bright mode\ntput smul – begin underline mode\ntput rmul – exit underline mode\ntput rev – Turn on reverse mode\ntput smso – Enter standout mode (bold on rxvt)\ntput rmso – Exit standout mode\ntput sgr0 – Turn off all attributes"
        },
        {
          "label": "子片段 2",
          "language": "sh",
          "value": "#!/bin/bash\n\nprintf $(tput setaf 2; tput bold)'color show\\n\\n'$(tput sgr0)\n\nfor((i=0; i<=7; i++)); do\n\techo $(tput setaf $i)\"show me the money\"$(tput sgr0)\ndone\n\nprintf '\\n'$(tput setaf 2; tput setab 0; tput bold)'background color show'$(tput sgr0)'\\n\\n'\n\nfor((i=0,j=7; i<=7; i++,j--)); do\n\techo $(tput setaf $i; tput setab $j; tput bold)\"show me the money\"$(tput sgr0)\ndone\n\nexit 0\n"
        }
      ],
      "id": "rl2tSchb",
      "createdAt": 1709523474208,
      "updatedAt": 1709526826833
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "RxpfS9zV",
      "tagsIds": [],
      "description": null,
      "name": "遍历数组",
      "content": [
        {
          "label": "子片段 1",
          "language": "typescript",
          "value": "/*TypeScript继承自JavaScript，因此可以使用JavaScript中的所有数组遍历方法，包括：\n\nfor循环\n可以使用传统的for循环遍历数组。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nfor (let i = 0; i < arr.length; i++) {\n  console.log(arr[i]);\n}\n/*forEach()方法\n可以使用forEach()方法遍历数组，它接受一个回调函数作为参数，回调函数接受三个参数：当前元素的值、当前元素的索引和数组本身。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\narr.forEach((value, index, array) => {\n  console.log(value);\n});\n/*map()方法\n可以使用map()方法遍历数组，它接受一个回调函数作为参数，回调函数返回一个新的数组，新数组的元素是根据原数组的元素经过处理后得到的。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nconst newArr = arr.map((value, index, array) => {\n  return value * 2;\n});\n\nconsole.log(newArr);\n/*filter()方法\n可以使用filter()方法遍历数组，它接受一个回调函数作为参数，回调函数返回一个布尔值，表示当前元素是否应该被包含在新的数组中。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nconst filteredArr = arr.filter((value, index, array) => {\n  return value % 2 === 0;\n});\n\nconsole.log(filteredArr);\n/*reduce()方法\n可以使用reduce()方法遍历数组，它接受一个回调函数作为参数，回调函数接受四个参数：累加器、当前元素的值、当前元素的索引和数组本身。回调函数返回的值作为下一次调用回调函数的累加器的值。例如：*/\n\nconst arr: number[] = [1, 2, 3, 4, 5];\n\nconst sum = arr.reduce((accumulator, currentValue, currentIndex, array) => {\n  return accumulator + currentValue;\n}, 0);\n\nconsole.log(sum);\n/*还有其他一些数组遍历方法，如some()、every()、find()、findIndex()等，它们的使用方法与上述方法类似，根据实际需求选择适合的方法即可。*/"
        }
      ],
      "id": "_qQRFf4S",
      "createdAt": 1709687898236,
      "updatedAt": 1709687973606
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "lxml",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "from lxml import etree\n\nroot=etree.Element('root')\nprint(root.tag)\nchild=etree.SubElement(root,'child') # 添加一个子节点\nchild.set('id','test_Id')\nprint(etree.tostring(root))          # tostring 为序列化"
        },
        {
          "label": "xpath",
          "language": "python",
          "value": "from lxml import etree\n\nhtml = etree.parse('./test.html', etree.HTMLParser())\nresult = etree.tostring(html)\nprint(result.decode('utf-8'))"
        },
        {
          "label": "basic sumary",
          "language": "markdown",
          "value": "`lxml` 是一个功能强大的 Python 库，用于处理 XML 和 HTML 文档。它结合了 libxml2 和 libxslt 的高效解析器和生成器，并提供了易于使用的 Python API。以下是 `lxml` 包的详细解析：\n\n### 安装 lxml\n\n可以通过 pip 安装 `lxml`：\n\n```bash\npip install lxml\n```\n\n### 主要模块\n\n`lxml` 提供了两个主要模块：`lxml.etree` 和 `lxml.html`。\n\n- **`lxml.etree`**：用于处理通用的 XML 和 HTML 文档。\n- **`lxml.html`**：专门用于处理 HTML 文档，提供了更方便的 HTML 操作方法。\n\n### 基本用法\n\n#### 1. 解析 XML/HTML 文档\n\n##### 使用 `etree` 解析 XML\n\n```python\nfrom lxml import etree\n\n# 从字符串解析 XML\nxml_string = '''<root>\n    <child>Content</child>\n</root>'''\nroot = etree.fromstring(xml_string)\n\n# 打印根元素标签\nprint(root.tag)  # 输出: root\n```\n\n##### 使用 `html` 解析 HTML\n\n```python\nfrom lxml import html\n\n# 从字符串解析 HTML\nhtml_string = '''<html>\n    <body>\n        <h1>Hello, World!</h1>\n    </body>\n</html>'''\ntree = html.fromstring(html_string)\n\n# 打印标题文本\nprint(tree.xpath('//h1/text()'))  # 输出: ['Hello, World!']\n```\n\n#### 2. 使用 XPath 查询\n\n`lxml` 支持使用 XPath 表达式来查询文档中的元素。\n\n```python\nfrom lxml import etree\n\nxml_string = '''<root>\n    <child id=\"1\">First</child>\n    <child id=\"2\">Second</child>\n</root>'''\nroot = etree.fromstring(xml_string)\n\n# 使用 XPath 查找所有 child 元素\nchildren = root.xpath('//child')\nfor child in children:\n    print(child.text)  # 输出: First Second\n\n# 使用 XPath 查找特定属性的元素\nspecific_child = root.xpath('//child[@id=\"2\"]')[0]\nprint(specific_child.text)  # 输出: Second\n```\n\n#### 3. 使用 CSS 选择器\n\n`lxml.html` 模块还支持使用 CSS 选择器来查找元素。\n\n```python\nfrom lxml import html\n\nhtml_string = '''<html>\n    <body>\n        <div class=\"content\">\n            <p class=\"title\">Title</p>\n            <p class=\"description\">Description</p>\n        </div>\n    </body>\n</html>'''\ntree = html.fromstring(html_string)\n\n# 使用 CSS 选择器查找元素\ntitle = tree.cssselect('.title')[0].text\ndescription = tree.cssselect('.description')[0].text\n\nprint(title)         # 输出: Title\nprint(description)  # 输出: Description\n```\n\n#### 4. 修改和创建文档\n\n可以使用 `lxml` 创建新的 XML 或 HTML 文档，或修改现有文档。\n\n```python\nfrom lxml import etree\n\n# 创建一个新的 XML 文档\nroot = etree.Element(\"root\")\nchild1 = etree.SubElement(root, \"child1\")\nchild1.text = \"Content of child1\"\n\nchild2 = etree.SubElement(root, \"child2\")\nchild2.text = \"Content of child2\"\n\n# 将文档转换为字符串\nxml_string = etree.tostring(root, pretty_print=True, encoding='unicode')\nprint(xml_string)\n```\n\n#### 5. 处理命名空间\n\n在处理包含命名空间的 XML 文档时，`lxml` 提供了简单的方法来处理命名空间。\n\n```python\nfrom lxml import etree\n\nxml_string = '''<root xmlns:ns=\"http://example.com/ns\">\n    <ns:child>Content</ns:child>\n</root>'''\n\nroot = etree.fromstring(xml_string)\n\n# 使用命名空间映射进行 XPath 查询\nnamespaces = {'ns': 'http://example.com/ns'}\nchild = root.xpath('//ns:child', namespaces=namespaces)[0]\nprint(child.text)  # 输出: Content\n```\n\n### 性能优化\n\n`lxml` 提供了一些性能优化选项，例如使用迭代解析器 `iterparse` 来处理大型文件，以减少内存占用。\n\n```python\nfrom lxml import etree\n\n# 迭代解析大型 XML 文件\ncontext = etree.iterparse('large_file.xml', events=('start', 'end'))\n\nfor event, elem in context:\n    if event == 'end' and elem.tag == 'record':\n        # 处理记录\n        print(elem.attrib)\n        # 清除已处理的元素以释放内存\n        elem.clear()\n        while elem.getprevious() is not None:\n            del elem.getparent()[0]\n```\n\n### 错误处理\n\n`lxml` 提供了详细的错误信息，可以帮助你调试解析问题。\n\n```python\nfrom lxml import etree\n\ntry:\n    xml_string = '<invalid>'\n    root = etree.fromstring(xml_string)\nexcept etree.XMLSyntaxError as e:\n    print(f\"XML syntax error: {e}\")\n```\n\n### 总结\n\n`lxml` 是一个强大且灵活的库，适用于各种 XML 和 HTML 处理任务。它不仅提供了高效的解析和生成功能，还支持 XPath、CSS 选择器等高级特性，是 Python 中处理结构化数据的强大工具。希望这些内容能帮助你更好地理解和使用 `lxml`。"
        }
      ],
      "id": "sVMMZEu2",
      "createdAt": 1709787008159,
      "updatedAt": 1737544666689
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "snowflake",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# pip install snowflake-id\nfrom snowflake import SnowflakeGenerator\n\ngen = SnowflakeGenerator(42)\n\nfor i in range(100):\n    val = next(gen)\n    print(val)"
        }
      ],
      "id": "izjU0ZO0",
      "createdAt": 1710000893638,
      "updatedAt": 1710000948908
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Process",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# 导入进程模块\nimport multiprocessing\n \n# 最多允许3个进程同时运行\npool = multiprocessing.Pool(processes = 3)\n \n1、apply() — 该函数用于传递不定参数，主进程会被阻塞直到函数执行结束（不建议使用，并且3.x以后不在出现），函数原型如下：\n\napply(func, args=(), kwds={})\n2、apply_async — 与apply用法一致，但它是非阻塞的且支持结果返回后进行回调，函数原型如下：\n\napply_async(func[, args=()[, kwds={}[, callback=None]]])\n3、map() — Pool类中的map方法，与内置的map函数用法基本一致，它会使进程阻塞直到结果返回，函数原型如下：\n\nmap(func, iterable, chunksize=None)\n注意：虽然第二个参数是一个迭代器，但在实际使用中，必须在整个队列都就绪后，程序才会运行子进程。\n\n4、map_async() — 与map用法一致，但是它是非阻塞的。其有关事项见apply_async，函数原型如下：\n\nmap_async(func, iterable, chunksize, callback)\n5、close() — 关闭进程池（pool），使其不在接受新的任务。\n\n6、terminal() — 结束工作进程，不在处理未处理的任务。\n\n7、join() — 主进程阻塞等待子进程的退出， join方法要在close或terminate之后使用。"
        }
      ],
      "id": "lapLuKwb",
      "createdAt": 1710003507218,
      "updatedAt": 1710003515804
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "sqlite3",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import sqlite3\ncon = sqlite3.connect(\"tutorial.db\")\n\ncur = con.cursor()\ncur.execute(\"CREATE TABLE movie(title, year, score)\")\nres = cur.execute(\"SELECT name FROM sqlite_master\")\nres.fetchone()"
        }
      ],
      "id": "jftvFjm0",
      "createdAt": 1710206891856,
      "updatedAt": 1710206929164
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "HRD2NCV8",
      "tagsIds": [],
      "description": null,
      "name": "gpupdate /force",
      "content": [
        {
          "label": "子片段 1",
          "language": "powershell",
          "value": "gpupdate /force"
        }
      ],
      "id": "59rdBTM8",
      "createdAt": 1711067467424,
      "updatedAt": 1711067493810
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "glob",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import glob\n\n1、返回目录的路径列表\n\npath_list1 = glob.glob('./test_dir/')\n\npath_list2 = glob.glob('./test_dir/*')\n\npath_list3 = glob.glob('./test_dir/*.py')\n\npath_list4 = glob.glob('./test_dir/*/*.py')\n\npath_list5 = glob.glob('./test_dir/**', recursive=True)\n\npath_list6 = glob.glob('./test_dir/**/*.py', recursive=True)"
        }
      ],
      "id": "Ld88RgtY",
      "createdAt": 1715163051153,
      "updatedAt": 1715163101262
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "4ojt5eME",
      "tagsIds": [],
      "description": null,
      "name": "dijkstra",
      "content": [
        {
          "label": "子片段 1",
          "language": "c_cpp",
          "value": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint inf = 999999;//不连通的点之间的距离设为无穷大\nlong long int e[10000][10000];\nint dis[10000];//最短距离数组\nint book[10000];//记录下哪些点被选中\n\n//计算单点到全部顶点的距离\nint Dijkstra(int &n, int &m, int &s, vector<vector<int>> &data, int &t)\n{\n\t//初始化任意两点之间的距离数组\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t{\n\t\t\tif (i == j)\n\t\t\t\te[i][j] = 0;\n\t\t\telse\n\t\t\t\te[i][j] = inf;\n\t\t}\n\t}\n\t//把权值加入到任意两点之间的距离数组中\n\tfor (int i = 1; i <= m; ++i)\n\t{\n\t\te[data[i - 1][0]][data[i - 1][1]] = data[i - 1][2];\n\t}\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tif (i != s)\n\t\t{\n\t\t\tdis[i] = e[s][i];//记录源点到其余所有点的最短路径\n\t\t\tbook[i] = 0;//记录哪些点被选取了\n\t\t}\n\t}\n\tint u, min;\n\tfor (int i = 1; i <= n - 1; ++i)\n\t{\n\t\tmin = inf;\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t{\n\t\t\tif (book[j] == 0 && dis[j] < min)//找到源点离还没有被选取的点中的最近顶点\n\t\t\t{\n\t\t\t\tmin = dis[j];\n\t\t\t\tu = j;//记录下最近顶点的位置\n\t\t\t}\n\t\t}\n\t\tbook[u] = 1;\n\t\t/*\n\t\t*例如存在一条从u到v的边，那么可以通过将边u->v添加到尾部来拓展一条从源点到v的路径，\n\t\t*这条路径的长度是dis[u]+e[u][v]。如果这个值比目前已知的dis[v]的值要小，\n\t\t*我们可以用新值来替代当前dis[v]中的值。\n\t\t*/\n\t\tfor (int v = 1; v <= n; ++v)\n\t\t{\n\t\t\tif (e[u][v] < inf)\n\t\t\t{\n\t\t\t\tif (dis[v] > dis[u] + e[u][v])\n\t\t\t\t\tdis[v] = dis[u] + e[u][v];//松弛\n\t\t\t}\n\t\t}\n\t}\n\treturn dis[t];\n}"
        }
      ],
      "id": "BaJf5Dyh",
      "createdAt": 1720877663687,
      "updatedAt": 1720877806903
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "4ojt5eME",
      "tagsIds": [],
      "description": null,
      "name": "floyd",
      "content": [
        {
          "label": "子片段 1",
          "language": "c_cpp",
          "value": "#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint inf = 999999;//不连通的点之间的距离设为无穷大\nlong long int e[10000][10000];\n\n//计算两两顶点之间的最短路径\nvoid Floyd(int &n, int &m, vector<vector<int>> &data)\n{\n\t//初始化任意两点之间的距离数组\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t{\n\t\t\tif (i == j)\n\t\t\t\te[i][j] = 0;\n\t\t\telse\n\t\t\t\te[i][j] = inf;\n\t\t}\n\t}\n\t//把权值加入到任意两点之间的距离数组中\n\tfor (int i = 1; i <= m; ++i)\n\t{\n\t\te[data[i - 1][0]][data[i - 1][1]] = data[i - 1][2];\n\t}\n\t/*\n\t*最开始只允许经过1号顶点进行中转，接下来只允许经过1和2号顶点进行中转……允许经过1~n号所有顶点\n\t*进行中转，求任意两点之间的最短路程。用一句话概括就是：从i号顶点到j号顶点只经过前k号点的最短路程。\n\t*/\n\tfor (int k = 1; k <= n; ++k)\n\t\tfor (int i = 1; i <= n; ++i)\n\t\t\tfor (int j = 1; j <= n; ++j)\n\t\t\t\tif (e[i][j] > e[i][k] + e[k][j])\n\t\t\t\t\te[i][j] = e[i][k] + e[k][j];\n\tfor (int i = 1; i <= n; ++i)\n\t{\n\t\tfor (int j = 1; j <= n; ++j)\n\t\t\tcout << e[i][j] << \" \";\n\t\tcout << endl;\n\t}\n}"
        }
      ],
      "id": "luMgxnlF",
      "createdAt": 1720877674998,
      "updatedAt": 1720877803451
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "4ojt5eME",
      "tagsIds": [],
      "description": null,
      "name": "kruskal & prim",
      "content": [
        {
          "label": "子片段 1",
          "language": "c_cpp",
          "value": "/************************************************************************\nCSDN 勿在浮沙筑高台 http://blog.csdn.net/luoshixian099算法导论--最小生成树（Prim、Kruskal）2016年7月14日\n************************************************************************/\n#include <iostream>\n#include <vector>\n#include <queue>\n#include <algorithm>\nusing namespace std;\n#define INFINITE 0xFFFFFFFF   \n#define VertexData unsigned int  //顶点数据\n#define UINT  unsigned int\n#define vexCounts 6  //顶点数量\nchar vextex[] = { 'A', 'B', 'C', 'D', 'E', 'F' };\nstruct node \n{\n    VertexData data;\n    unsigned int lowestcost;\n}closedge[vexCounts]; //Prim算法中的辅助信息\ntypedef struct \n{\n    VertexData u;\n    VertexData v;\n    unsigned int cost;  //边的代价\n}Arc;  //原始图的边信息\nvoid AdjMatrix(unsigned int adjMat[][vexCounts])  //邻接矩阵表示法\n{\n    for (int i = 0; i < vexCounts; i++)   //初始化邻接矩阵\n        for (int j = 0; j < vexCounts; j++)\n        {\n            adjMat[i][j] = INFINITE;\n        }\n    adjMat[0][1] = 6; adjMat[0][2] = 1; adjMat[0][3] = 5;\n    adjMat[1][0] = 6; adjMat[1][2] = 5; adjMat[1][4] = 3;\n    adjMat[2][0] = 1; adjMat[2][1] = 5; adjMat[2][3] = 5; adjMat[2][4] = 6; adjMat[2][5] = 4;\n    adjMat[3][0] = 5; adjMat[3][2] = 5; adjMat[3][5] = 2;\n    adjMat[4][1] = 3; adjMat[4][2] = 6; adjMat[4][5] = 6;\n    adjMat[5][2] = 4; adjMat[5][3] = 2; adjMat[5][4] = 6;\n}\nint Minmum(struct node * closedge)  //返回最小代价边\n{\n    unsigned int min = INFINITE;\n    int index = -1;\n    for (int i = 0; i < vexCounts;i++)\n    {\n        if (closedge[i].lowestcost < min && closedge[i].lowestcost !=0)\n        {\n            min = closedge[i].lowestcost;\n            index = i;\n        }\n    }\n    return index;\n}\nvoid MiniSpanTree_Prim(unsigned int adjMat[][vexCounts], VertexData s)\n{\n    for (int i = 0; i < vexCounts;i++)\n    {\n        closedge[i].lowestcost = INFINITE;\n    }      \n    closedge[s].data = s;      //从顶点s开始\n    closedge[s].lowestcost = 0;\n    for (int i = 0; i < vexCounts;i++)  //初始化辅助数组\n    {\n        if (i != s)\n        {\n            closedge[i].data = s;\n            closedge[i].lowestcost = adjMat[s][i];\n        }\n    }\n    for (int e = 1; e <= vexCounts -1; e++)  //n-1条边时退出\n    {\n        int k = Minmum(closedge);  //选择最小代价边\n        cout << vextex[closedge[k].data] << \"--\" << vextex[k] << endl;//加入到最小生成树\n        closedge[k].lowestcost = 0; //代价置为0\n        for (int i = 0; i < vexCounts;i++)  //更新v中顶点最小代价边信息\n        {\n            if ( adjMat[k][i] < closedge[i].lowestcost)\n            {\n                closedge[i].data = k;\n                closedge[i].lowestcost = adjMat[k][i];\n            }\n        }\n    }\n}\nvoid ReadArc(unsigned int  adjMat[][vexCounts],vector<Arc> &vertexArc) //保存图的边代价信息\n{\n    Arc * temp = NULL;\n    for (unsigned int i = 0; i < vexCounts;i++)\n    {\n        for (unsigned int j = 0; j < i; j++)\n        {\n            if (adjMat[i][j]!=INFINITE)\n            {\n                temp = new Arc;\n                temp->u = i;\n                temp->v = j;\n                temp->cost = adjMat[i][j];\n                vertexArc.push_back(*temp);\n            }\n        }\n    }\n}\nbool compare(Arc  A, Arc  B)\n{\n    return A.cost < B.cost ? true : false;\n}\nbool FindTree(VertexData u, VertexData v,vector<vector<VertexData> > &Tree)\n{\n    unsigned int index_u = INFINITE;\n    unsigned int index_v = INFINITE;\n    for (unsigned int i = 0; i < Tree.size();i++)  //检查u,v分别属于哪颗树\n    {\n        if (find(Tree[i].begin(), Tree[i].end(), u) != Tree[i].end())\n            index_u = i;\n        if (find(Tree[i].begin(), Tree[i].end(), v) != Tree[i].end())\n            index_v = i;\n    }\n \n    if (index_u != index_v)   //u,v不在一颗树上，合并两颗树\n    {\n        for (unsigned int i = 0; i < Tree[index_v].size();i++)\n        {\n            Tree[index_u].push_back(Tree[index_v][i]);\n        }\n        Tree[index_v].clear();\n        return true;\n    }\n    return false;\n}\nvoid MiniSpanTree_Kruskal(unsigned int adjMat[][vexCounts])\n{\n    vector<Arc> vertexArc;\n    ReadArc(adjMat, vertexArc);//读取边信息\n    sort(vertexArc.begin(), vertexArc.end(), compare);//边按从小到大排序\n    vector<vector<VertexData> > Tree(vexCounts); //6棵独立树\n    for (unsigned int i = 0; i < vexCounts; i++)\n    {\n        Tree[i].push_back(i);  //初始化6棵独立树的信息\n    }\n    for (unsigned int i = 0; i < vertexArc.size(); i++)//依次从小到大取最小代价边\n    {\n        VertexData u = vertexArc[i].u;  \n        VertexData v = vertexArc[i].v;\n        if (FindTree(u, v, Tree))//检查此边的两个顶点是否在一颗树内\n        {\n            cout << vextex[u] << \"---\" << vextex[v] << endl;//把此边加入到最小生成树中\n        }   \n    }\n}\n \nint main()\n{\n    unsigned int  adjMat[vexCounts][vexCounts] = { 0 };\n    AdjMatrix(adjMat);   //邻接矩阵\n    cout << \"Prim :\" << endl;\n    MiniSpanTree_Prim(adjMat,0); //Prim算法，从顶点0开始.\n    cout << \"-------------\" << endl << \"Kruskal:\" << endl;\n    MiniSpanTree_Kruskal(adjMat);//Kruskal算法\n    return 0;\n}"
        }
      ],
      "id": "Xig7I5Yc",
      "createdAt": 1720877781205,
      "updatedAt": 1720877799120
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "fnmatch",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import fnmatch\nimport os\n\nfor file in os.listdir('.'):\n    if fnmatch.fnmatch(file, '*.txt'):\n        print(file)"
        }
      ],
      "id": "Ivhp6eLe",
      "createdAt": 1721203676475,
      "updatedAt": 1721203681413
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "anki_db",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import sqlite3\nimport pandas as pd\nfrom tqdm import tqdm\nimport re\n\nif __name__ == \"__main__\":\n    con = sqlite3.connect(\"data.db\")\n    cur = con.cursor()\n    res = cur.execute(\"SELECT tags,sfld from notes\")\n    data = res.fetchall()\n"
        }
      ],
      "id": "60pjlgt8",
      "createdAt": 1722057259380,
      "updatedAt": 1722057293355
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "json objectification",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": ""
        }
      ],
      "id": "kmrtyaUH",
      "createdAt": 1724574340170,
      "updatedAt": 1724574347941
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "logging",
      "content": [
        {
          "label": "basic",
          "language": "python",
          "value": "import logging\n\nLOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\nDATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n\nlogging.basicConfig(filename='my.log', level=logging.DEBUG, format=LOG_FORMAT, datefmt=DATE_FORMAT)\n\nlogging.debug(\"This is a debug log.\")\nlogging.info(\"This is a info log.\")\nlogging.warning(\"This is a warning log.\")\nlogging.error(\"This is a error log.\")\nlogging.critical(\"This is a critical log.\")"
        },
        {
          "label": "advanced",
          "language": "python",
          "value": "import logging\nimport logging.handlers\nimport datetime\n\nlogger = logging.getLogger('mylogger')\nlogger.setLevel(logging.DEBUG)\n\nrf_handler = logging.handlers.TimedRotatingFileHandler('all.log', when='midnight', interval=1, backupCount=7, atTime=datetime.time(0, 0, 0, 0))\nrf_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n\nf_handler = logging.FileHandler('error.log')\nf_handler.setLevel(logging.ERROR)\nf_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(filename)s[:%(lineno)d] - %(message)s\"))\n\nlogger.addHandler(rf_handler)\nlogger.addHandler(f_handler)\n\nlogger.debug('debug message')\nlogger.info('info message')\nlogger.warning('warning message')\nlogger.error('error message')\nlogger.critical('critical message')"
        },
        {
          "label": "调用subprocess 使用logging打印日志",
          "language": "python",
          "value": "import sys\nimport logging\nfrom logging.handlers import TimedRotatingFileHandler\nimport os\nfrom subprocess import Popen, PIPE, STDOUT\nreload(sys)\nsys.setdefaultencoding('utf8')\n\n\nLOG_FILE_NAME = 'send_snmp_trap.log'\nlogger = logging.getLogger('SenSNMPTrap.py')\nlogger.setLevel(level=logging.INFO)\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(funcName)s - %(process)d - %(levelname)s - %(message)s')\nLOG_PATH = os.path.join('/tmp', LOG_FILE_NAME)\n\n# 每天午夜更新日志文件\nhandler = TimedRotatingFileHandler(LOG_PATH, when='midnight', backupCount=3, )\nhandler.setLevel(logging.INFO)\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\n\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\nconsole.setFormatter(formatter)\n# 输出到屏幕\nlogger.addHandler(console)\n\n\ndef log_subprocess_output(pipe):\n    for line in iter(pipe.readline, b''):  # b'\\n'-separated lines\n        logger.info('got line from subprocess: %r', line)\n\n\ndef run_command(command_line_args):\n    process = Popen(command_line_args, stdout=PIPE, stderr=STDOUT)\n    with process.stdout:\n        log_subprocess_output(process.stdout)\n    exitcode = process.wait()  # 0 means success\n    if exitcode == 0:\n        logger.info('success')\n    else:\n        logger.error(\"failed\")\n\nrun_command(command_line_args=['ls', '/tp/'])"
        }
      ],
      "id": "w2BFB5oy",
      "createdAt": 1724574359923,
      "updatedAt": 1724831165349
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "yolov5_to_coco",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# -*- encoding: utf-8 -*-\n# @File: yolov5_2_coco.py\n# @Author: lijunjie2232\n# @Contact: git@lijunjie2232\n\nimport argparse\nimport json\nimport shutil\nimport time\nimport warnings\nfrom pathlib import Path\n\nimport cv2\nfrom tqdm import tqdm\nimport yaml\n\nclass YOLOV5ToCOCO():\n    def __init__(self, data_dir):\n        self.raw_data_dir = Path(data_dir)\n\n        self.verify_exists(self.raw_data_dir / 'images')\n        self.verify_exists(self.raw_data_dir / 'labels')\n\n        save_dir_name = f'{Path(self.raw_data_dir).name}_COCO_format'\n        self.output_dir = self.raw_data_dir.parent / save_dir_name\n        self.mkdir(self.output_dir)\n\n        self._init_json()\n\n    def __call__(self, mode_list: list):\n        if not mode_list:\n            raise ValueError('mode_list is empty!!')\n\n        for mode in mode_list:\n            # Read the image txt.\n            txt_path = self.raw_data_dir / f'{mode}.txt'\n            self.verify_exists(txt_path)\n            img_list = self.read_txt(txt_path)\n            if mode == 'train':\n                img_list = self.append_bg_img(img_list)\n\n            # Create the directory of saving the new image.\n            save_img_dir = self.output_dir / f'{mode}2017'\n            self.mkdir(save_img_dir)\n\n            # Generate json file.\n            anno_dir = self.output_dir / \"annotations\"\n            self.mkdir(anno_dir)\n\n            save_json_path = anno_dir / f'instances_{mode}2017.json'\n            json_data = self.convert(img_list, save_img_dir, mode)\n\n            self.write_json(save_json_path, json_data)\n        print(f'Successfully convert, detail in {self.output_dir}')\n\n    def _init_json(self):\n        classes_path = self.raw_data_dir / 'classes.txt'\n        data_yaml_path = self.raw_data_dir / 'data.yaml'\n        if self.verify_exists(classes_path, raise_if_ne=False):\n            self.categories = self._get_category(classes_path)\n        elif self.verify_exists(data_yaml_path, raise_if_ne=False):\n            self.categories = self._get_category(data_yaml_path)\n        else:\n            raise(Exception('no dataset info file found'))\n\n        self.type = 'instances'\n        self.annotation_id = 1\n\n        self.cur_year = time.strftime('%Y', time.localtime(time.time()))\n        self.info = {\n            'year': int(self.cur_year),\n            'version': '1.0',\n            'description': 'For object detection',\n            'date_created': self.cur_year,\n        }\n\n        self.licenses = [{\n            'id': 1,\n            'name': 'Apache License v2.0',\n            'url': 'https://github.com/RapidAI/YOLO2COCO/LICENSE',\n        }]\n\n    def append_bg_img(self, img_list):\n        bg_dir = self.raw_data_dir / 'background_images'\n        if bg_dir.exists():\n            bg_img_list = list(bg_dir.iterdir())\n            for bg_img_path in bg_img_list:\n                img_list.append(str(bg_img_path))\n        return img_list\n\n    def _get_category(self, classes_path):\n        if classes_path.name.endswith('txt'):\n            class_list = self.read_txt(classes_path)\n        elif classes_path.name.endswith('yaml'):\n            with open(classes_path, 'r', encoding='utf-8') as f:\n                y = yaml.safe_load(f)\n            class_list = y['names']\n        else:\n            raise(Exception('invalid dataset info file'))\n        categories = []\n        for i, category in enumerate(class_list, 1):\n            categories.append({\n                'supercategory': category,\n                'id': i,\n                'name': category,\n            })\n        return categories\n\n    def convert(self, img_list, save_img_dir, mode):\n        images, annotations = [], []\n        cvt_process = tqdm(img_list, desc=mode)\n        anno_nums = 0\n        for img_id, img_path in enumerate(cvt_process, 1):\n            \n            image_dict = self.get_image_info(img_path, img_id, save_img_dir)\n            images.append(image_dict)\n\n            label_path = self.raw_data_dir / 'labels' / f'{Path(img_path).stem}.txt'\n            annotation = self.get_annotation(label_path,\n                                             img_id,\n                                             image_dict['height'],\n                                             image_dict['width'])\n            if len(annotation) > 0:\n                annotations.extend(annotation)\n                anno_nums += len(annotation)\n            \n            cvt_process.set_postfix(\n                {\n                    'processed': Path(img_path).name,\n                    'anno numbers': anno_nums,\n                }\n            )\n\n        json_data = {\n            'info': self.info,\n            'images': images,\n            'licenses': self.licenses,\n            'type': self.type,\n            'annotations': annotations,\n            'categories': self.categories,\n        }\n        return json_data\n\n    def get_image_info(self, img_path, img_id, save_img_dir):\n        img_path = Path(img_path)\n        if self.raw_data_dir.as_posix() not in img_path.as_posix():\n            # relative path (relative to the raw_data_dir)\n            # e.g. images/images(3).jpg\n            img_path = self.raw_data_dir / img_path\n\n        self.verify_exists(img_path)\n\n        new_img_name = f'{img_id:012d}.jpg'\n        save_img_path = save_img_dir / new_img_name\n        img_src = cv2.imread(str(img_path))\n        if img_path.suffix.lower() == \".jpg\":\n            shutil.copyfile(img_path, save_img_path)\n        else:\n            cv2.imwrite(str(save_img_path), img_src)\n\n        height, width = img_src.shape[:2]\n        image_info = {\n            'date_captured': self.cur_year,\n            'file_name': new_img_name,\n            'id': img_id,\n            'height': height,\n            'width': width,\n        }\n        return image_info\n\n    def get_annotation(self, label_path: Path, img_id, height, width):\n        def get_box_info(vertex_info, height, width):\n            cx, cy, w, h = [float(i) for i in vertex_info]\n\n            cx = cx * width\n            cy = cy * height\n            box_w = w * width\n            box_h = h * height\n\n            # left top\n            x0 = max(cx - box_w / 2, 0)\n            y0 = max(cy - box_h / 2, 0)\n\n            # right bottom\n            x1 = min(x0 + box_w, width)\n            y1 = min(y0 + box_h, height)\n\n            segmentation = [[x0, y0, x1, y0, x1, y1, x0, y1]]\n            bbox = [x0, y0, box_w, box_h]\n            area = box_w * box_h\n            return segmentation, bbox, area\n\n        if not label_path.exists():\n            # annotation = [{\n            #     'segmentation': [],\n            #     'area': 0,\n            #     'iscrowd': 0,\n            #     'image_id': img_id,\n            #     'bbox': [],\n            #     'category_id': -1,\n            #     'id': self.annotation_id,\n            # }]\n            # self.annotation_id += 1\n            # return annotation\n            return []\n\n        annotation = []\n        label_list = self.read_txt(str(label_path))\n        for i, one_line in enumerate(label_list):\n            label_info = one_line.split(' ')\n            if len(label_info) < 5:\n                warnings.warn(\n                    f'The {i+1} line of the {label_path} has been corrupted.')\n                continue\n\n            category_id, vertex_info = label_info[0], label_info[1:]\n            segmentation, bbox, area = get_box_info(vertex_info, height, width)\n            annotation.append({\n                'segmentation': segmentation,\n                'area': area,\n                'iscrowd': 0,\n                'image_id': img_id,\n                'bbox': bbox,\n                'category_id': int(category_id)+1,\n                'id': self.annotation_id,\n            })\n            self.annotation_id += 1\n        return annotation\n\n    @staticmethod\n    def read_txt(txt_path):\n        with open(str(txt_path), 'r', encoding='utf-8') as f:\n            data = list(map(lambda x: x.rstrip('\\n'), f))\n        return data\n\n    @staticmethod\n    def mkdir(dir_path):\n        Path(dir_path).mkdir(parents=True, exist_ok=True)\n\n    @staticmethod\n    def verify_exists(file_path, raise_if_ne=True):\n        file_path = Path(file_path)\n        if not file_path.exists():\n            if raise_if_ne:\n                raise FileNotFoundError(f'The {file_path} is not exists!!!')\n            else:\n                return False\n        else:\n            return True\n\n    @staticmethod\n    def write_json(json_path, content: dict):\n        with open(json_path, 'w', encoding='utf-8') as f:\n            json.dump(content, f, ensure_ascii=False)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser('Datasets converter from YOLOV5 to COCO')\n    parser.add_argument('--data_dir', type=str, default='datasets/YOLOV5',\n                        help='Dataset root path')\n    parser.add_argument('--mode_list', type=str, default='train,val',\n                        help='generate which mode')\n    args = parser.parse_args()\n\n    converter = YOLOV5ToCOCO(args.data_dir)\n    converter(mode_list=args.mode_list.split(','))\n\n"
        }
      ],
      "id": "aM9qIpVf",
      "createdAt": 1724574636984,
      "updatedAt": 1724574654722
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "make_index_4_yolov5",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# -*- encoding: utf-8 -*-\n# @File: makeIndex4yolov5ds.py\n# @Author: lijunjie2232\n# @Contact: git@lijunjie2232\n\nimport random\nimport os\nfrom tqdm import tqdm\nimport argparse\nimport yaml\nfrom pathlib import Path\n\ndef makeIndex(yaml_file=Path('./data.yaml'), out_path=None, ds_type='inner', ds_split='train,val,test'):\n    with open(yaml_file, 'r', encoding='utf-8') as f:\n        yaml_data = yaml.safe_load(f)\n    data_path = Path(yaml_data['path'])\n    train = yaml_data['train']\n    val = yaml_data['val']\n    train_img = []\n    val_img = []\n    if not isinstance(train, list):\n        train = [train]\n    if not isinstance(val, list):\n        val = [val]\n    for d in train:\n        train_img.extend(dataWalker(d, root=data_path))\n    for d in val:\n        val_img.extend(dataWalker(d, root=data_path))\n    saveIndex(train_img, Path(out_path)/\"train.txt\" if out_path else Path(yaml_file).parent/\"train.txt\")\n    saveIndex(val_img, Path(out_path)/\"val.txt\" if out_path else Path(yaml_file).parent/\"val.txt\")\n\n\ndef dataWalker(img_dir, anno_dir=None, root=Path('.')):\n    if not anno_dir:\n        anno_dir = str(img_dir).replace('images', 'labels')\n    img_list = []\n    for file in tqdm(os.listdir(root/img_dir), desc='walking ...', leave=False):\n        if os.path.isfile(os.path.join(root/anno_dir, os.path.splitext(file)[0]+'.txt')):\n            # img_list.append(os.path.abspath(os.path.join(img_dir, file)))\n            img_list.append(Path(os.path.join(img_dir, file)).__str__())\n    return img_list\n\ndef saveIndex(index_list, path):\n    with open(path, 'w') as f:\n        for line in tqdm(index_list, desc='save to '+str(path), leave=False):\n            f.write(line+'\\n')\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser('Datasets converter from YOLOV5 to COCO')\n    parser.add_argument('--data_dir', type=str, default='./',\n                        help='Dataset root path')\n    parser.add_argument('--out_dir', type=str, default='',\n                        help='Dataset split result output path')\n    parser.add_argument('--type', type=str, default='inner',\n                        help='Dataset construction type, inner:type dir in images/labels dir; outer:...')\n    parser.add_argument('--data_split', type=str, default='train,val',\n                        help='Dataset split')\n    args = parser.parse_args()\n\n    ROOT = Path('.')\n\n    makeIndex(ROOT/args.data_dir, args.out_dir, ds_type=args.type, ds_split=args.data_split)\n\n"
        }
      ],
      "id": "zXh0Znfi",
      "createdAt": 1724574687043,
      "updatedAt": 1724574709788
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "param & flops",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import torch\nimport torchvision\nfrom thop import profile\n\n# Model\nprint('==> Building model..')\nmodel = torchvision.models.alexnet(pretrained=False)\n\ndummy_input = torch.randn(1, 3, 224, 224)\nflops, params = profile(model, (dummy_input,))\nprint('flops: ', flops, 'params: ', params)\nprint('flops: %.2f M, params: %.2f M' % (flops / 1000000.0, params / 1000000.0))"
        },
        {
          "label": "子片段 2",
          "language": "python",
          "value": "freeze_param = 0\ntrain_param = 0\nfor i in model.parameters():\n    if i.requires_grad:\n        train_param += i.numel()\n    else:\n        freeze_param += i.numel()\nfor name, i in model.named_parameters():\n    if i.requires_grad:\n        train_param += i.numel()\n    else:\n        freeze_param += i.numel()\nprint(\"trainable params: %.2f M\" % (train_param / 1000000.0))\nprint(\"freeze params: %.2f M\" % (freeze_param / 1000000.0))"
        }
      ],
      "id": "AUEnTr0e",
      "createdAt": 1724579916146,
      "updatedAt": 1724776769307
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "time",
      "content": [
        {
          "label": "basic",
          "language": "python",
          "value": "import time\n\nlocaltime = time.localtime(time.time())\nprint \"本地时间为 :\", localtime\n# 本地时间为 : time.struct_time(tm_year=2016, tm_mon=4, tm_mday=7, tm_hour=10, tm_min=3, tm_sec=27, tm_wday=3, tm_yday=98, tm_isdst=0)\n\nlocaltime = time.asctime( time.localtime(time.time()) )\nprint \"本地时间为 :\", localtime\n# 本地时间为 : Thu Apr  7 10:05:21 2016"
        },
        {
          "label": "format",
          "language": "python",
          "value": "import time\n\n# 格式化成2016-03-20 11:45:39形式\nprint time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n# 2016-04-07 10:25:09\n\n# 格式化成Sat Mar 28 22:24:24 2016形式\nprint time.strftime(\"%a %b %d %H:%M:%S %Y\", time.localtime())\n# Thu Apr 07 10:25:09 2016\n\n# 将格式字符串转换为时间戳\na = \"Sat Mar 28 22:24:24 2016\"\nprint time.mktime(time.strptime(a,\"%a %b %d %H:%M:%S %Y\"))\n# 1459175064.0\n\n\"\"\"\npython中时间日期格式化符号：\n\n%y 两位数的年份表示（00-99）\n%Y 四位数的年份表示（000-9999）\n%m 月份（01-12）\n%d 月内中的一天（0-31）\n%H 24小时制小时数（0-23）\n%I 12小时制小时数（01-12）\n%M 分钟数（00-59）\n%S 秒（00-59）\n%a 本地简化星期名称\n%A 本地完整星期名称\n%b 本地简化的月份名称\n%B 本地完整的月份名称\n%c 本地相应的日期表示和时间表示\n%j 年内的一天（001-366）\n%p 本地A.M.或P.M.的等价符\n%U 一年中的星期数（00-53）星期天为星期的开始\n%w 星期（0-6），星期天为星期的开始\n%W 一年中的星期数（00-53）星期一为星期的开始\n%x 本地相应的日期表示\n%X 本地相应的时间表示\n%Z 当前时区的名称\n%% %号本身\n\"\"\""
        },
        {
          "label": "calender",
          "language": "python",
          "value": "#!/usr/bin/python\n# -*- coding: UTF-8 -*-\n \nimport calendar\n \ncal = calendar.month(2016, 1)\nprint \"以下输出2016年1月份的日历:\"\nprint cal"
        }
      ],
      "id": "WHxAFSQd",
      "createdAt": 1724660133793,
      "updatedAt": 1724660309591
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "yolo_objectify",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import argparse\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os\nimport shutil\nimport logging as lg\nfrom multiprocessing.pool import ThreadPool\n\nLOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\nlg.basicConfig(level=lg.DEBUG, format=LOG_FORMAT)\n\n\ndef txt_objectify(path: Path):\n    if not path.suffix == \".txt\":\n        return\n    bak_file = path.parent / f\"{path.name}_bak.txt\"\n    if not bak_file.is_file():\n        shutil.copy(path, bak_file)\n    with open(bak_file, \"r\", encoding=\"utf-8\") as old_f:\n        anns = old_f.read().strip(\"\\n\").split(\"\\n\")\n        with open(path, \"w\", encoding=\"utf-8\") as new_f:\n            for ann in anns:\n                ann = ann.strip(\" \").split(\" \")\n                ann[0] = \"0\"\n                new_f.write(\" \".join(ann))\n                new_f.write(\"\\n\")\n\n\ndef dir_walker(dir: Path, filter, func, pool=None):\n    for file in os.listdir(dir):\n        file = dir / file\n        if file.is_dir():\n            dir_walker(file, filter, func)\n        elif filter(file):\n            if pool:\n                pool.apply_async(func=func,args=(file))\n            else:\n                func(file)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"objectification yolo label directory\")\n    parser.add_argument(\"-d\", type=str, required=True)\n    args = parser.parse_args()\n\n    path = Path(args.d)\n\n    filter = lambda file: return file.suffix == \".txt\"\n    \n    pool = ThreadPool(16)\n    \n    dir_walker(path, filter, txt_objectify, pool=pool)\n    \n"
        }
      ],
      "id": "FLBLihaP",
      "createdAt": 1724908462822,
      "updatedAt": 1724908475930
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "v3det(threadpool image check)",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# %%\nimport json\nimport os\nimport shutil\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom copy import deepcopy\nfrom PIL import Image\nfrom multiprocessing.pool import ThreadPool\nfrom itertools import repeat\n\n\n# %%\nDATA = Path(\"./data/\")\nANN_DIR = DATA / \"annotations\"\nOUT_DIR = Path(\"./yolo_format\")\n\n# %%\nwith open(ANN_DIR / \"v3det_2023_v1_train.json\", \"r\", encoding=\"utf-8\") as f:\n    train_json = json.load(f)\n\n\n# %%\ndef img_checker(args):\n    dir, img = args\n    img_file = img[\"file_name\"]\n    if str(img_file).endswith('jpg') or str(img_file).endswith('jpg'):\n        try:\n            Image.open(dir/img_file).load()\n        except:\n            if (dir/img_file).is_file():\n                os.unlik(dir/img_file)\n            img[\"file_name\"] = None\n        finally:\n            return img\n    return None\n\n# %%\nnew_images = []\nnew_id = dict({})\nimg_count = 1\nos.makedirs((OUT_DIR / \"images\" / \"train\"), exist_ok=True)\nwith ThreadPool(32) as pool:\n    results = pool.imap(func=img_checker,iterable= zip(repeat(DATA), train_json[\"images\"]))\n    for i in tqdm(results, total=len(train_json[\"images\"])):\n        if not i:\n            continue\n        if i[\"file_name\"]:\n            img_file = DATA / i[\"file_name\"]\n            new_img_path = OUT_DIR / f\"images/train/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n            shutil.copy(img_file, new_img_path)\n            this_img = deepcopy(i)\n            this_img[\"file_name\"] = new_img_path.name\n            new_id[this_img[\"id\"]] = img_count\n            this_img[\"id\"] = img_count\n            new_images.append(this_img)\n            img_count += 1\n\n\"\"\"for i in tqdm(train_json[\"images\"]):\n    img_file = DATA / i[\"file_name\"]\n    new_img_path = OUT_DIR / f\"images/train/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n    try:\n        Image.open(img_file).load()\n    except:\n        print(img_file)\n        os.unlik(img_file)\n        continue\n    if not new_img_path.is_file():\n        shutil.copy(img_file, new_img_path)\n    this_img = deepcopy(i)\n    this_img[\"file_name\"] = new_img_path.name\n    new_id[this_img[\"id\"]] = img_count\n    this_img[\"id\"] = img_count\n    new_images.append(this_img)\n    img_count += 1\"\"\"\n\nnew_annotations = []\nann_count = 0\nfor a in tqdm(train_json[\"annotations\"]):\n    if a[\"image_id\"] in new_id:\n        this_ann = deepcopy(a)\n        this_ann[\"image_id\"] = new_id[this_ann[\"image_id\"]]\n        this_ann[\"id\"] = ann_count\n        new_annotations.append(this_ann)\n        ann_count += 1\n\nnew_train_json = deepcopy(train_json)\nnew_train_json[\"images\"] = new_images\nnew_train_json[\"annotations\"] = new_annotations\n\nwith open(OUT_DIR / \"annotations\" / \"instances_train.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(new_train_json, f)\n\n# %%\ni\n\n# %%\na\n\n\n# %%\nthis_img\n\n\n# %%\nthis_ann\n\n\n# %%\nwith open(ANN_DIR / \"v3det_2023_v1_val.json\", \"r\", encoding=\"utf-8\") as f:\n    val_json = json.load(f)\n\n\n# %%\nnew_images = []\nnew_id = dict({})\nimg_count = 1\nos.makedirs((OUT_DIR / \"images\" / \"val\"), exist_ok=True)\nwith ThreadPool(32) as pool:\n    results = pool.imap(target=img_checker,iterable= zip(repeat(DATA), val_json[\"images\"]))\n    for i in tqdm(results, total=len(val_json[\"images\"])):\n        if not i:\n            continue\n        if i[\"file_name\"]:\n            img_file = DATA / i[\"file_name\"]\n            new_img_path = OUT_DIR / f\"images/val/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n            shutil.copy(img_file, new_img_path)\n            this_img = deepcopy(i)\n            this_img[\"file_name\"] = new_img_path.name\n            new_id[this_img[\"id\"]] = img_count\n            this_img[\"id\"] = img_count\n            new_images.append(this_img)\n            img_count += 1\n\n\"\"\"for i in tqdm(val_json[\"images\"]):\n    img_file = DATA / i[\"file_name\"]\n    new_img_path = OUT_DIR / f\"images/val/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n    try:\n        image.open(img_file).load()\n    except:\n        print(img_file)\n        os.unlik(img_file)\n        continue\n    if not new_img_path.is_file():\n        shutil.copy(img_file, new_img_path)\n    this_img = deepcopy(i)\n    this_img[\"file_name\"] = new_img_path.name\n    new_id[this_img[\"id\"]] = img_count\n    this_img[\"id\"] = img_count\n    new_images.append(this_img)\n    img_count += 1\"\"\"\n\nnew_annotations = []\nann_count = 0\nfor a in tqdm(val_json[\"annotations\"]):\n    if a[\"image_id\"] in new_id:\n        this_ann = deepcopy(a)\n        this_ann[\"image_id\"] = new_id[this_ann[\"image_id\"]]\n        this_ann[\"id\"] = ann_count\n        new_annotations.append(this_ann)\n        ann_count += 1\n\nnew_val_json = deepcopy(val_json)\nnew_val_json[\"images\"] = new_images\nnew_val_json[\"annotations\"] = new_annotations\n\nwith open(OUT_DIR / \"annotations\" / \"instances_val.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(new_val_json, f)\n\n\n\n\n"
        }
      ],
      "id": "iXUs53Ff",
      "createdAt": 1724919224198,
      "updatedAt": 1724919274735
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "image checker",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "# %%\nimport json\nimport os\nimport shutil\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom copy import deepcopy\nfrom PIL import Image\nfrom multiprocessing.pool import ThreadPool\nfrom itertools import repeat\n\n\n# %%\nDATA = Path(\"./data/\")\nANN_DIR = DATA / \"annotations\"\nOUT_DIR = Path(\"./yolo_format\")\n\n# %%\nwith open(ANN_DIR / \"v3det_2023_v1_train.json\", \"r\", encoding=\"utf-8\") as f:\n    train_json = json.load(f)\n\n\n# %%\ndef img_checker(args):\n    dir, img = args\n    img_file = img[\"file_name\"]\n    if str(img_file).endswith('jpg') or str(img_file).endswith('jpg'):\n        try:\n            Image.open(dir / img_file).verify()\n            img = Image.open(dir / img_file)\n            img.load()\n        except:\n            if (dir/img_file).is_file():\n                os.unlik(dir/img_file)\n            img[\"file_name\"] = None\n        finally:\n            return img\n    return None\n\n# %%\nnew_images = []\nnew_id = dict({})\nimg_count = 1\nos.makedirs((OUT_DIR / \"images\" / \"train\"), exist_ok=True)\nwith ThreadPool(32) as pool:\n    results = pool.imap(func=img_checker,iterable= zip(repeat(DATA), train_json[\"images\"]))\n    for i in tqdm(results, total=len(train_json[\"images\"])):\n        if not i:\n            continue\n        if i[\"file_name\"]:\n            img_file = DATA / i[\"file_name\"]\n            new_img_path = OUT_DIR / f\"images/train/{str(img_count).rjust(10, '0')}{img_file.suffix}\"\n            shutil.copy(img_file, new_img_path)\n            this_img = deepcopy(i)\n            this_img[\"file_name\"] = new_img_path.name\n            new_id[this_img[\"id\"]] = img_count\n            this_img[\"id\"] = img_count\n            new_images.append(this_img)\n            img_count += 1\n"
        }
      ],
      "id": "OaCbxc8o",
      "createdAt": 1725756511234,
      "updatedAt": 1725770181958
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "pytorch ddp",
      "content": [
        {
          "label": "train",
          "language": "python",
          "value": "导入\ntorch.multiprocessing 是围绕 Python 原生多处理的 PyTorch 包装器\n\n分布式进程组包含所有可以相互通信和同步的进程。\n\nimport torch\nimport torch.nn.functional as F\nfrom utils import MyTrainDataset\n\n+ import torch.multiprocessing as mp\n+ from torch.utils.data.distributed import DistributedSampler\n+ from torch.nn.parallel import DistributedDataParallel as DDP\n+ from torch.distributed import init_process_group, destroy_process_group\n+ import os\n构建进程组\n首先，在初始化组进程之前，调用 set_device，它为每个进程设置默认 GPU。这对于防止 GPU:0 上的挂起或过度内存使用至关重要。\n\n进程组可以通过 TCP（默认）或从共享文件系统初始化。阅读有关 进程组初始化 的更多信息\n\ninit_process_group 初始化分布式进程组。\n\n了解有关 选择 DDP 后端 的更多信息\n\n+ def ddp_setup(rank: int, world_size: int):\n+   \"\"\"\n+   Args:\n+       rank: Unique identifier of each process\n+      world_size: Total number of processes\n+   \"\"\"\n+   os.environ[\"MASTER_ADDR\"] = \"localhost\"\n+   os.environ[\"MASTER_PORT\"] = \"12355\"\n+   torch.cuda.set_device(rank)\n+   init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n构建 DDP 模型\n- self.model = model.to(gpu_id)\n+ self.model = DDP(model, device_ids=[gpu_id])\n分发输入数据\nDistributedSampler 将输入数据跨所有分布式进程进行分块。\n\n每个进程将接收一个包含 32 个样本的输入批次；有效批次大小为 32 * nprocs，使用 4 个 GPU 时为 128。\n\ntrain_data = torch.utils.data.DataLoader(\n    dataset=train_dataset,\n    batch_size=32,\n-   shuffle=True,\n+   shuffle=False,\n+   sampler=DistributedSampler(train_dataset),\n)\n在每个 epoch 开始时调用 DistributedSampler 上的 set_epoch() 方法对于使跨多个 epoch 的混洗正常工作是必要的。否则，将在每个 epoch 中使用相同的排序。\n\ndef _run_epoch(self, epoch):\n    b_sz = len(next(iter(self.train_data))[0])\n+   self.train_data.sampler.set_epoch(epoch)\n    for source, targets in self.train_data:\n      ...\n      self._run_batch(source, targets)\n保存模型检查点\n我们只需要从一个进程保存模型检查点。如果没有这个条件，每个进程都会保存其相同模式的副本。阅读有关使用 DDP 保存和加载模型的更多信息 此处\n\n- ckp = self.model.state_dict()\n+ ckp = self.model.module.state_dict()\n...\n...\n- if epoch % self.save_every == 0:\n+ if self.gpu_id == 0 and epoch % self.save_every == 0:\n  self._save_checkpoint(epoch)\n警告\n\n集体调用 是在所有分布式进程上运行的函数，它们用于将某些状态或值收集到特定进程。集体调用要求所有等级都运行集体代码。在这个例子中，_save_checkpoint 不应该有任何集体调用，因为它只在 rank:0 进程上运行。如果您需要进行任何集体调用，则应在 if self.gpu_id == 0 检查之前进行。\n\n运行分布式训练作业\n包括新的参数 rank（替换 device）和 world_size。\n\nrank 是在调用 mp.spawn 时由 DDP 自动分配的。\n\nworld_size 是整个训练作业中的进程数量。对于 GPU 训练，这对应于使用的 GPU 数量，并且每个进程都在专用 GPU 上工作。\n\n- def main(device, total_epochs, save_every):\n+ def main(rank, world_size, total_epochs, save_every):\n+  ddp_setup(rank, world_size)\n   dataset, model, optimizer = load_train_objs()\n   train_data = prepare_dataloader(dataset, batch_size=32)\n-  trainer = Trainer(model, train_data, optimizer, device, save_every)\n+  trainer = Trainer(model, train_data, optimizer, rank, save_every)\n   trainer.train(total_epochs)\n+  destroy_process_group()\n\nif __name__ == \"__main__\":\n   import sys\n   total_epochs = int(sys.argv[1])\n   save_every = int(sys.argv[2])\n-  device = 0      # shorthand for cuda:0\n-  main(device, total_epochs, save_every)\n+  world_size = torch.cuda.device_count()\n+  mp.spawn(main, args=(world_size, total_epochs, save_every,), nprocs=world_size)"
        },
        {
          "label": "inference",
          "language": "python",
          "value": "import torch\nimport torch.distributed as dist\nimport json\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\n# 模拟推理结果\ndef inference_on_gpu(model, data_loader, device):\n    model.eval()\n    all_predictions = []\n    with torch.no_grad():\n        for images, image_ids in data_loader:\n            images = images.to(device)\n            outputs = model(images)  # 假设模型输出包含预测框和类别\n\n            # 将输出转换为 COCO 格式的预测结果\n            for i, output in enumerate(outputs):\n                pred_boxes = output['boxes'].cpu().numpy()\n                pred_scores = output['scores'].cpu().numpy()\n                pred_labels = output['labels'].cpu().numpy()\n\n                # 每张图片的预测框\n                for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n                    all_predictions.append({\n                        \"image_id\": image_ids[i].item(),\n                        \"category_id\": label.item(),\n                        \"bbox\": box.tolist(),  # COCO 格式的 [x_min, y_min, width, height]\n                        \"score\": score.item()\n                    })\n    return all_predictions\n\n# 收集所有 GPU 上的推理结果\ndef gather_predictions(predictions):\n    # 如果是分布式训练，需要收集每个 GPU 的结果\n    all_predictions = [None for _ in range(dist.get_world_size())]\n    dist.all_gather_object(all_predictions, predictions)  # 收集每个 GPU 的预测结果\n    # 展平收集到的预测结果\n    all_predictions = [item for sublist in all_predictions for item in sublist]\n    return all_predictions\n\n# 计算 COCO mAP\ndef evaluate_predictions(coco_gt, all_predictions, output_file='predictions.json'):\n    with open(output_file, 'w') as f:\n        json.dump(all_predictions, f)\n\n    coco_dt = coco_gt.loadRes(output_file)\n    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n    coco_eval.evaluate()\n    coco_eval.accumulate()\n    coco_eval.summarize()\n\n# 主推理与评估流程\ndef main():\n    # 初始化分布式环境\n    dist.init_process_group(backend='nccl')\n\n    # 设置设备\n    device = torch.device(f'cuda:{dist.get_rank()}')\n\n    # 加载模型和数据\n    model = YourModel().to(device)\n    data_loader = YourDataLoader()  # 假设 data_loader 返回 (images, image_ids)\n    \n    # COCO ground truth 数据\n    coco_gt = COCO(annotation_file='instances_val2017.json')\n\n    # 每个 GPU 执行推理\n    predictions = inference_on_gpu(model, data_loader, device)\n\n    # 收集所有 GPU 的推理结果\n    all_predictions = gather_predictions(predictions)\n\n    # 只有 rank 0 的进程负责计算 mAP\n    if dist.get_rank() == 0:\n        evaluate_predictions(coco_gt, all_predictions)\n\n    # 结束分布式进程组\n    dist.barrier()\n    dist.destroy_process_group()\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
          "label": "main_ddp",
          "language": "plain_text",
          "value": "import kagglehub\nfrom pathlib import Path\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torch\nimport torch.nn as nn\nfrom model import EmotionNet\nfrom utils import (\n    load,\n    save,\n    val_epoch,\n    train_epoch,\n    ddp_setup,\n    ddp_cleanup,\n    parse_args,\n    get_logger,\n)\nfrom tqdm import tqdm\nimport shutil\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.distributed import get_rank, get_world_size\nimport os\nimport numpy as np\nimport random\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nLOCAL_RANK = int(\n    os.getenv(\"LOCAL_RANK\", -1)\n)  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", -1))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\n\n\ndef main(local_rank, world_size, args):\n    # ddp init\n    ddp_setup(\n        local_rank,\n        world_size,\n        master_addr=\"127.0.0.1\",\n        master_port=29500,\n    )\n\n    # logger\n    logger = get_logger(local_rank)\n\n    # ## Hyper Parameters and Configs\n    # device = \"cuda:1\"\n    device = \"cuda\"\n\n    lr = args.lr\n    step_size = args.step_size\n    batch_size = args.batch_size\n    num_workers = args.num_workers\n    epochs = args.epochs\n    start_epoch = args.start_epoch\n    train_patience = args.train_patience\n    best_checkpoint = Path(args.best_checkpoint)\n    last_checkpoint = Path(args.last_checkpoint)\n    train_data_path = args.train_data_path\n    val_data_path = args.val_data_path\n\n    # ## cudnn acceleration\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.enabled = True\n\n    # ## random seed\n    seed = args.seed + get_rank()\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\n    # ## prepare dataset\n    # Download latest version\n    data_id = args.data_id\n    data_root = kagglehub.dataset_download(data_id)\n    logger.info(\"Path to dataset files: \" + data_root)\n    data_root = Path(data_root)\n\n    # ## build data transforms\n    train_transformer = transforms.Compose(\n        [\n            transforms.Resize((256, 256)),\n            transforms.RandomCrop(224),  # 224x224\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(degrees=15),\n            transforms.RandomVerticalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n        ]\n    )\n    val_transformer = transforms.Compose(\n        [\n            transforms.Resize((256, 256)),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n        ]\n    )\n\n    # ## build dataset\n    train_dataset = ImageFolder(\n        root=data_root / train_data_path,\n        transform=train_transformer,\n    )\n    val_dataset = ImageFolder(\n        root=data_root / val_data_path,\n        transform=val_transformer,\n    )\n\n    # ## build model\n    model = EmotionNet(\n        nc=len(train_dataset.classes),\n    ).cuda()\n\n    # ## build loss, optimizer and lr_scheduler\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))\n    scheduler = torch.optim.lr_scheduler.StepLR(\n        optimizer,\n        step_size=step_size,\n        gamma=0.1,\n    )\n    criterion = nn.CrossEntropyLoss()\n    scaler = torch.amp.GradScaler()\n\n    if last_checkpoint.is_file():\n        ckp_epoch = load(\n            model=model,\n            optimizer=optimizer,\n            path=last_checkpoint,\n        )\n        if start_epoch == -1:\n            start_epoch = ckp_epoch\n        logger.info(\n            f\"continue from {last_checkpoint.__str__()}, \"\n            + f\"start at epoch {start_epoch+1}\"\n        )\n\n    # ## model set ddp\n    ddp_model = DDP(\n        model,\n        device_ids=[local_rank],\n        find_unused_parameters=True,\n    )\n\n    # ## build dataloader\n    train_sampler = DistributedSampler(\n        train_dataset,\n        rank=get_rank(),\n        seed=seed,\n        num_replicas=get_world_size(),\n    )\n    train_sampler.set_epoch(start_epoch + 1)\n    train_dataloader = DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        shuffle=False,\n        sampler=train_sampler,\n    )\n    val_dataloader = DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n    )\n\n    # ## train model\n    loop = (\n        tqdm(range(start_epoch + 1, epochs))\n        if local_rank == 0\n        else range(start_epoch + 1, epochs)\n    )\n    best_acc = 0\n    patience = train_patience\n    for epoch in loop:\n        if local_rank == 0:\n            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n        # torch.distributed.barrier()\n        train_acc, train_loss = train_epoch(\n            ddp_model,\n            train_dataloader,\n            optimizer,\n            scheduler,\n            criterion,\n            scaler,\n            device=device,\n            progress=local_rank == 0,\n        )\n        if local_rank == 0:\n            loop.set_postfix(\n                train_acc=train_acc,\n                train_loss=train_loss,\n            )\n            val_acc, val_loss = val_epoch(\n                ddp_model,\n                val_dataloader,\n                criterion,\n                device=device,\n            )\n            loop.set_postfix(\n                train_acc=train_acc,\n                train_loss=train_loss,\n                val_acc=val_acc,\n                val_loss=val_loss,\n            )\n\n            save(ddp_model.module, optimizer, epoch, last_checkpoint)\n\n            if val_acc > best_acc:\n                shutil.copyfile(last_checkpoint, best_checkpoint)\n                best_acc = val_acc\n                patience = train_patience\n            else:\n                patience -= 1\n            if patience == 0:\n                logger.info(\"no patience, early stop...\")\n                break\n    ddp_cleanup()\n    logger.info(\"done.\")\n\n\nif __name__ == \"__main__\":\n\n    args = parse_args()\n    main(LOCAL_RANK, WORLD_SIZE, args)\n    exit(0)\n    # cmd: torchrun --nproc-per-node=2 --master-port 29500 main_ddp.py"
        },
        {
          "label": "util",
          "language": "python",
          "value": "def ddp_setup(\n    rank: int,\n    world_size: int,\n    backend=\"nccl\",\n    master_addr=\"localhost\",\n    master_port=12355,\n):\n    \"\"\"\n    Args:\n        rank: Unique identifier of each process\n    world_size: Total number of processes\n    \"\"\"\n    os.environ[\"MASTER_ADDR\"] = master_addr\n    os.environ[\"MASTER_PORT\"] = str(master_port)\n    torch.cuda.set_device(rank)\n    init_process_group(\n        backend=backend, rank=rank, world_size=world_size, init_method=\"env://\"\n    )\n\n\ndef ddp_cleanup():\n    destroy_process_group()"
        }
      ],
      "id": "PfEmpLuD",
      "createdAt": 1725932493707,
      "updatedAt": 1746436147572
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "memory_profiler",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import numpy as np\nfrom memory_profiler import profile\n \n@profile\ndef demo():\n    a = np.random.rand(10000000)\n    b = np.random.rand(10000000)\n    \n    a_ = a[a < b]\n    b_ = b[a < b]\n    \n    del a, b\n \n    return a_, b_\n \n \nif __name__ == '__main__':\n    demo()"
        }
      ],
      "id": "1mZKVtdM",
      "createdAt": 1726649105037,
      "updatedAt": 1726649118980
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "@timecalc",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "def timecalc(func):\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f\"[function]: {func.__name__}, [time]: {end - start}ms\")\n        return result\n    return wrapper"
        }
      ],
      "id": "JWFfVT6n",
      "createdAt": 1726819216801,
      "updatedAt": 1726819221854
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Queue",
      "content": [
        {
          "label": "get&put",
          "language": "plain_text",
          "value": "\"\"\"\nPython 中的消息队列\nPython 提供了 queue 模块来实现线程之间的消息队列。queue.Queue 是线程安全的，允许多个线程安全地访问和修改队列中的数据。\n\nqueue.Queue 的基本用法\nqueue.Queue 通过两个主要方法实现线程安全的队列操作：\n\nput(item)：将数据项放入队列。\nget()：从队列中取出数据项。如果队列为空，它会阻塞直到有数据可取。\n\"\"\"\n\nimport threading\nimport queue\nimport time\n\n# 创建队列对象\nq = queue.Queue()\n\n# 生产者线程\ndef producer():\n    for i in range(5):\n        item = f\"item_{i}\"\n        print(f\"Producing {item}\")\n        q.put(item)\n        time.sleep(1)\n\n# 消费者线程\ndef consumer():\n    while True:\n        item = q.get()\n        if item is None:\n            break\n        print(f\"Consuming {item}\")\n        q.task_done()\n\n# 创建线程\nproducer_thread = threading.Thread(target=producer)\nconsumer_thread = threading.Thread(target=consumer)\n\n# 启动线程\nproducer_thread.start()\nconsumer_thread.start()\n\n# 等待生产者结束\nproducer_thread.join()\n\n# 向队列发送终止信号\nq.put(None)\n\n# 等待消费者结束\nconsumer_thread.join()\n\nprint(\"All tasks finished\")\n\"\"\"\n分析：\n生产者线程：负责将数据项放入队列。这里每隔 1 秒向队列中添加一个数据项。\n消费者线程：负责从队列中取出数据并处理。如果队列为空，q.get() 会阻塞，直到有新数据项进入队列。当所有生产任务完成后，通过向队列中添加 None 来通知消费者线程结束。\n线程通信：queue.Queue 在多个线程之间安全地传递数据，避免了手动加锁的复杂性。\n\"\"\""
        },
        {
          "label": "Full&Empty",
          "language": "python",
          "value": "\"\"\"\n阻塞与非阻塞队列\n队列的 put() 和 get() 方法默认是阻塞的，但你可以通过设置 block=False 来让它们变为非阻塞模式。如果在非阻塞模式下调用 get() 时队列为空，或者 put() 时队列满了，它们会抛出 queue.Empty 或 queue.Full 异常。\n\n非阻塞队列示例：\n\"\"\"\n\nimport queue\n\nq = queue.Queue(maxsize=3)\n\n# 非阻塞地放入队列\ntry:\n    q.put(\"item\", block=False)\nexcept queue.Full:\n    print(\"Queue is full!\")\n\n# 非阻塞地获取队列\ntry:\n    item = q.get(block=False)\nexcept queue.Empty:\n    print(\"Queue is empty!\")"
        },
        {
          "label": "join&task_done",
          "language": "python",
          "value": "\"\"\"\nqueue.Queue 的其他方法\nq.task_done()：当消费者线程完成对某个任务的处理时，调用此方法通知队列该任务已完成。\nq.join()：阻塞主线程，直到队列中的所有任务都已完成。它会等待所有任务都调用 task_done()。\n\"\"\"\nimport threading\nimport queue\n\nq = queue.Queue()\n\ndef producer():\n    for i in range(5):\n        q.put(i)\n        print(f\"Produced {i}\")\n\ndef consumer():\n    while True:\n        item = q.get()\n        print(f\"Consumed {item}\")\n        q.task_done()\n\n# 启动生产者和消费者线程\nthreading.Thread(target=producer).start()\nthreading.Thread(target=consumer, daemon=True).start()\n\n# 等待所有任务完成\nq.join()\nprint(\"All tasks are done\")"
        },
        {
          "label": "子片段 4",
          "language": "python",
          "value": "\"\"\"\nPython queue 模块还提供了其他几种类型的队列：\n\nqueue.LifoQueue：后进先出（LIFO）的队列，类似于栈。\nqueue.PriorityQueue：优先级队列，数据项会按照优先级顺序排列。\n优先级队列示例：\n\"\"\"\nimport queue\n\npq = queue.PriorityQueue()\n\n# 将数据按照优先级放入队列\npq.put((2, \"Medium priority\"))\npq.put((1, \"High priority\"))\npq.put((3, \"Low priority\"))\n\n# 按照优先级顺序获取数据\nwhile not pq.empty():\n    priority, task = pq.get()\n    print(f\"Processing task with priority {priority}: {task}\")"
        },
        {
          "label": "子片段 5",
          "language": "python",
          "value": ""
        },
        {
          "label": "子片段 6",
          "language": "python",
          "value": ""
        }
      ],
      "id": "YcCA6Xx6",
      "createdAt": 1726991761016,
      "updatedAt": 1726993316352
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "re replace",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "re.sub(\"<.*?>\", \"\", word)"
        }
      ],
      "id": "zW1UeYgh",
      "createdAt": 1727353216088,
      "updatedAt": 1727425970531
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "cuda time",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "torch.cuda.synchronize()\nstart = time()\nmodel(x)\ntorch.cuda.synchronize()\nend = time()\nprint(end - start, \"ms\")"
        }
      ],
      "id": "HVTNDdUU",
      "createdAt": 1727425732121,
      "updatedAt": 1727425739504
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "cude mem",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "import torch\nfrom torchvision import models\nfrom memory_profiler import profile\nfrom inspect import unwrap\nfrom time import time\n\n\n@profile\ndef model_test():\n    device = torch.device(\"cuda:0\")\n    model = models.resnet50().cuda()\n    print(torch.cuda.memory_allocated() / 1024**2, \"MB\")\n    model = model.cpu()\n    print(torch.cuda.max_memory_allocated() / 1024**2, \"MB\")\n    print(torch.cuda.memory_summary())\n    model = model.cuda()\n\n    with torch.profiler.profile(\n        activities=[\n            torch.profiler.ProfilerActivity.CPU,\n            torch.profiler.ProfilerActivity.CUDA,\n        ],\n        # execution_trace_observer=(\n        #     torch.profiler.ExecutionTraceObserver().register_callback(\"./execution_trace.json\")\n        # ),\n        record_shapes=True,\n        profile_memory=True,  # 启用显存分析\n        with_stack=True,\n    ) as prof:\n        x = torch.randn(1, 3, 224, 224).cuda()\n        model(x)\n    print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n\n    x = torch.randn(32, 3, 224, 224).cuda()\n    torch.cuda.synchronize()\n    start = time()\n    model(x)\n    torch.cuda.synchronize()\n    end = time()\n    print(end - start, \"ms\")\n\n\nif __name__ == \"__main__\":\n    model_test()\n    unwrap(model_test)()\n"
        }
      ],
      "id": "7aNFOFbC",
      "createdAt": 1727425948490,
      "updatedAt": 1727425960495
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "pytorch cudnn enable",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import torch\ntorch.backends.cudnn.enabled = True\ntorch.backend.cudnn.benchmark=True"
        }
      ],
      "id": "9doO_wAe",
      "createdAt": 1727507206242,
      "updatedAt": 1727507218048
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "whisper inference with ddp",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import whisper\nfrom whisper.transcribe import *\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.distributed import init_process_group, barrier\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport argparse\n\nos.environ[\"MKL_NUM_THREADS\"] = \"1024\"\nos.environ[\"OMP_NUM_THREADS\"] = \"1024\"\ntorch.set_num_threads(1024)\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\nLOCAL_RANK = int(\n    os.getenv(\"LOCAL_RANK\", 0)\n)  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", 0))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\n\n\nclass input_files(Dataset):\n    def __init__(self, path, valid_suffix=[\".acc\", \".mp3\", \".wav\"]):\n        self.path = path\n        self.files = (self.path / file for file in os.listdir(path))\n        self.files = [\n            f.__str__() for f in filter(lambda f: f.suffix in valid_suffix, self.files)\n        ]\n\n    def __getitem__(self, index):\n        return self.files[index]\n\n    def __len__(self):\n        return len(self.files)\n\n\ndef ddp_setup(rank: int, world_size: int):\n    \"\"\"\n    Args:\n        rank: Unique identifier of each process\n    world_size: Total number of processes\n    \"\"\"\n    torch.cuda.set_device(rank)\n    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n\n\ndef get_args():\n    # fmt: off\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    # parser.add_argument(\"audio\", nargs=\"+\", type=str, help=\"audio file(s) to transcribe\")\n    parser.add_argument(\"--model\", default=\"small\", type=str, help=\"name of the Whisper model to use\")\n    parser.add_argument(\"--model_dir\", type=str, default=None, help=\"the path to save model files; uses ~/.cache/whisper by default\")\n    parser.add_argument(\"--device\", default=\"cuda\" if torch.cuda.is_available() else \"cpu\", help=\"device to use for PyTorch inference\")\n    parser.add_argument(\"--output_dir\", \"-o\", type=str, default=\"./output\", help=\"directory to save the outputs\")\n    parser.add_argument(\"--output_format\", \"-f\", type=str, default=\"all\", choices=[\"txt\", \"vtt\", \"srt\", \"tsv\", \"json\", \"all\"], help=\"format of the output file; if not specified, all available formats will be produced\")\n    parser.add_argument(\"--verbose\", type=str2bool, default=True, help=\"whether to print out the progress and debug messages\")\n\n    parser.add_argument(\"--task\", type=str, default=\"transcribe\", choices=[\"transcribe\", \"translate\"], help=\"whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')\")\n    parser.add_argument(\"--language\", type=str, default=None, choices=sorted(LANGUAGES.keys()) + sorted([k.title() for k in TO_LANGUAGE_CODE.keys()]), help=\"language spoken in the audio, specify None to perform language detection\")\n\n    parser.add_argument(\"--temperature\", type=float, default=0, help=\"temperature to use for sampling\")\n    parser.add_argument(\"--best_of\", type=optional_int, default=5, help=\"number of candidates when sampling with non-zero temperature\")\n    parser.add_argument(\"--beam_size\", type=optional_int, default=5, help=\"number of beams in beam search, only applicable when temperature is zero\")\n    parser.add_argument(\"--patience\", type=float, default=None, help=\"optional patience value to use in beam decoding, as in https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to conventional beam search\")\n    parser.add_argument(\"--length_penalty\", type=float, default=None, help=\"optional token length penalty coefficient (alpha) as in https://arxiv.org/abs/1609.08144, uses simple length normalization by default\")\n\n    parser.add_argument(\"--suppress_tokens\", type=str, default=\"-1\", help=\"comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations\")\n    parser.add_argument(\"--initial_prompt\", type=str, default=None, help=\"optional text to provide as a prompt for the first window.\")\n    parser.add_argument(\"--condition_on_previous_text\", type=str2bool, default=True, help=\"if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop\")\n    parser.add_argument(\"--fp16\", type=str2bool, default=True, help=\"whether to perform inference in fp16; True by default\")\n\n    parser.add_argument(\"--temperature_increment_on_fallback\", type=optional_float, default=0.2, help=\"temperature to increase when falling back when the decoding fails to meet either of the thresholds below\")\n    parser.add_argument(\"--compression_ratio_threshold\", type=optional_float, default=2.4, help=\"if the gzip compression ratio is higher than this value, treat the decoding as failed\")\n    parser.add_argument(\"--logprob_threshold\", type=optional_float, default=-1.0, help=\"if the average log probability is lower than this value, treat the decoding as failed\")\n    parser.add_argument(\"--no_speech_threshold\", type=optional_float, default=0.6, help=\"if the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence\")\n    parser.add_argument(\"--word_timestamps\", type=str2bool, default=False, help=\"(experimental) extract word-level timestamps and refine the results based on them\")\n    parser.add_argument(\"--prepend_punctuations\", type=str, default=\"\\\"\\'“¿([{-\", help=\"if word_timestamps is True, merge these punctuation symbols with the next word\")\n    parser.add_argument(\"--append_punctuations\", type=str, default=\"\\\"\\'.。,，!！?？:：”)]}、\", help=\"if word_timestamps is True, merge these punctuation symbols with the previous word\")\n    parser.add_argument(\"--highlight_words\", type=str2bool, default=False, help=\"(requires --word_timestamps True) underline each word as it is spoken in srt and vtt\")\n    parser.add_argument(\"--max_line_width\", type=optional_int, default=None, help=\"(requires --word_timestamps True) the maximum number of characters in a line before breaking the line\")\n    parser.add_argument(\"--max_line_count\", type=optional_int, default=None, help=\"(requires --word_timestamps True) the maximum number of lines in a segment\")\n    parser.add_argument(\"--max_words_per_line\", type=optional_int, default=None, help=\"(requires --word_timestamps True, no effect with --max_line_width) the maximum number of words in a segment\")\n    parser.add_argument(\"--threads\", type=optional_int, default=0, help=\"number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS\")\n    parser.add_argument(\"--clip_timestamps\", type=str, default=\"0\", help=\"comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process, where the last end timestamp defaults to the end of the file\")\n    parser.add_argument(\"--hallucination_silence_threshold\", type=optional_float, help=\"(requires --word_timestamps True) skip silent periods longer than this threshold (in seconds) when a possible hallucination is detected\")\n\n    return parser.parse_args().__dict__\n\n\nif __name__ == \"__main__\":\n    ddp_setup(RANK, WORLD_SIZE)\n    input_dir = Path(\"input\")\n    output_dir = Path(\"output\")\n    output_dir.mkdir(exist_ok=True)\n\n    args = get_args()\n    model_name = \"large-v3\"\n    model_dir = args[\"model_dir\"]\n    output_format = \"all\"\n    device = \"cuda\"\n    args[\"language\"] = \"Japanese\"\n\n    args.pop(\"model\")\n    args.pop(\"model_dir\")\n    args.pop(\"output_dir\")\n    args.pop(\"output_format\")\n    args.pop(\"device\")\n    args.pop(\"threads\")\n\n    model = whisper.load_model(\"large-v3\", device=\"cuda\", download_root=model_dir)\n    temperature = args.pop(\"temperature\")\n    if (increment := args.pop(\"temperature_increment_on_fallback\")) is not None:\n        temperature = tuple(np.arange(temperature, 1.0 + 1e-6, increment))\n    else:\n        temperature = [temperature]\n\n    writer = get_writer(output_format, output_dir)\n    word_options = [\n        \"highlight_words\",\n        \"max_line_count\",\n        \"max_line_width\",\n        \"max_words_per_line\",\n    ]\n    args[\"word_timestamps\"] = True\n    if not args[\"word_timestamps\"]:\n        for option in word_options:\n            assert args[option], Exception(\n                f\"--{option} requires --word_timestamps True\"\n            )\n    if args[\"max_line_count\"] and not args[\"max_line_width\"]:\n        warnings.warn(\"--max_line_count has no effect without --max_line_width\")\n    if args[\"max_words_per_line\"] and args[\"max_line_width\"]:\n        warnings.warn(\"--max_words_per_line has no effect with --max_line_width\")\n    writer_args = {arg: args.pop(arg) for arg in word_options}\n\n    dataset = input_files(input_dir)\n    loop = DataLoader(\n        dataset,\n        batch_size=1,\n        sampler=DistributedSampler(dataset, shuffle=False),\n    )\n    if not RANK:\n        loop = tqdm(loop)\n    for audio_path in loop:\n        assert len(audio_path) == 1\n        audio_path = audio_path[0]\n        result = transcribe(\n            model, audio_path.__str__(), temperature=temperature, **args\n        )\n        writer(result, audio_path, **writer_args)\n        # try:\n        #     result = transcribe(model, audio_path.__str__(), temperature=temperature, **args)\n        #     writer(result, audio_path, **writer_args)\n        # except Exception as e:\n        #     traceback.print_exc()\n        #     print(f\"Skipping {audio_path} due to {type(e).__name__}: {str(e)}\")\n    barrier()\n"
        }
      ],
      "id": "v8waXzoJ",
      "createdAt": 1727510394313,
      "updatedAt": 1727511239340
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "mp3 extractor",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import subprocess\nfrom pathlib import Path\nimport os\nimport sys\nfrom multiprocessing.pool import Pool\n\n\ndef mp3_extractor(input, output):\n    subprocess.run(\n        [\n            \"ffmpeg.exe\",\n            \"-i\",\n            input,\n            \"-vn\",\n            \"-c:a\",\n            \"mp3\",\n            output,\n        ]\n    )\n\n\nif __name__ == \"__main__\":\n    ROOT = Path(__file__).parent.parent\n    mp3_dir = ROOT / \"mp3\"\n    mp3_dir.mkdir(exist_ok=True)\n    with Pool(16) as pool:\n        for file in os.listdir(ROOT):\n            file = ROOT / file\n            if file.suffix != \".mp4\":\n                continue\n            input = file.absolute().__str__()\n            output = (mp3_dir / f\"{file.stem}.mp3\").absolute().__str__()\n            pool.apply_async(mp3_extractor, args=(input, output))\n        pool.close()\n        pool.join()\n"
        }
      ],
      "id": "wthzwaeG",
      "createdAt": 1727512632091,
      "updatedAt": 1727512640972
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "未命名程式碼片段",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": ""
        }
      ],
      "id": "YOzeI46J",
      "createdAt": 1729164388322,
      "updatedAt": 1731240823018
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "hamming",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "import torch\n\ndef hamming_distance_batchwise(hamming_codes):\n    \"\"\"\n    计算 m 个二进制向量两两之间的海明距离\n    :param hamming_codes: 二进制向量张量，形状为 [m, embedding_size]\n    :return: 海明距离矩阵，形状为 [m, m]\n    \"\"\"\n    m = hamming_codes.size(0)\n    \n    # 扩展维度，使每个向量可以与其他所有向量进行比较\n    # 形状从 [m, embedding_size] 变成 [m, 1, embedding_size] 和 [1, m, embedding_size]\n    hamming_codes_1 = hamming_codes.unsqueeze(1)  # [m, 1, embedding_size]\n    hamming_codes_2 = hamming_codes.unsqueeze(0)  # [1, m, embedding_size]\n    \n    # 进行逐位异或操作，得到异或结果矩阵，形状为 [m, m, embedding_size]\n    xor_result = torch.bitwise_xor(hamming_codes_1, hamming_codes_2)\n    \n    # 统计异或结果中 1 的数量，即海明距离\n    # 最后结果是 [m, m] 的矩阵，其中每个元素是对应向量之间的海明距离\n    hamming_distances = torch.sum(xor_result, dim=-1)\n    \n    return hamming_distances\n\n# 测试\nhamming_codes = torch.tensor([[0, 0, 1, 1, 0, 1, 1], \n                              [1, 0, 0, 1, 1, 0, 1], \n                              [1, 1, 1, 0, 0, 0, 1]], dtype=torch.int64)\n\n# 计算两两之间的海明距离矩阵\nhamming_distances = hamming_distance_batchwise(hamming_codes)\nprint(\"Hamming distance matrix:\\n\", hamming_distances)\n"
        }
      ],
      "id": "1V9l10Wh",
      "createdAt": 1729164391321,
      "updatedAt": 1729164399413
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "Date/SimpleDateFormat/Calendar",
      "content": [
        {
          "label": "format",
          "language": "markdown",
          "value": "#### Date 对象创建以后，可以调用下面的方法。\n\n| 序号 | 方法和描述                                                   |\n| :--- | :----------------------------------------------------------- |\n| 1    | **boolean after(Date date)** 若当调用此方法的Date对象在指定日期之后返回true,否则返回false。 |\n| 2    | **boolean before(Date date)** 若当调用此方法的Date对象在指定日期之前返回true,否则返回false。 |\n| 3    | **Object clone( )** 返回此对象的副本。                       |\n| 4    | **int compareTo(Date date)** 比较当调用此方法的Date对象和指定日期。两者相等时候返回0。调用对象在指定日期之前则返回负数。调用对象在指定日期之后则返回正数。 |\n| 5    | **int compareTo(Object obj)** 若obj是Date类型则操作等同于compareTo(Date) 。否则它抛出ClassCastException。 |\n| 6    | **boolean equals(Object date)** 当调用此方法的Date对象和指定日期相等时候返回true,否则返回false。 |\n| 7    | **long getTime( )** 返回自 1970 年 1 月 1 日 00:00:00 GMT 以来此 Date 对象表示的毫秒数。 |\n| 8    | **int hashCode( )**  返回此对象的哈希码值。                  |\n| 9    | **void setTime(long time)**   用自1970年1月1日00:00:00 GMT以后time毫秒数设置时间和日期。 |\n| 10   | **String toString( )** 把此 Date 对象转换为以下形式的 String： dow mon dd hh:mm:ss zzz yyyy 其中： dow 是一周中的某一天 (Sun, Mon, Tue, Wed, Thu, Fri, Sat)。 |\n\n#### printf格式\n| 转 换 符 | 说  明                      | 示  例                           |\n| :------- | :-------------------------- | :------------------------------- |\n| c        | 包括全部日期和时间信息      | 星期六 十月 27 14:21:20 CST 2007 |\n| F        | \"年-月-日\"格式              | 2007-10-27                       |\n| D        | \"月/日/年\"格式              | 10/27/07                         |\n| r        | \"HH:MM:SS PM\"格式（12时制） | 02:25:51 下午                    |\n| T        | \"HH:MM:SS\"格式（24时制）    | 14:28:16                         |\n| R        | \"HH:MM\"格式（24时制）       | 14:28                            |\n\n#### SimpleDateFormat 格式\n| **字母** | **描述**                 | **示例**                |\n| :------- | :----------------------- | :---------------------- |\n| G        | 纪元标记                 | AD                      |\n| y        | 四位年份                 | 2001                    |\n| M        | 月份                     | July or 07              |\n| d        | 一个月的日期             | 10                      |\n| h        | A.M./P.M. (1~12)格式小时 | 12                      |\n| H        | 一天中的小时 (0~23)      | 22                      |\n| m        | 分钟数                   | 30                      |\n| s        | 秒数                     | 55                      |\n| S        | 毫秒数                   | 234                     |\n| E        | 星期几                   | Tuesday                 |\n| D        | 一年中的日子             | 360                     |\n| F        | 一个月中第几周的周几     | 2 (second Wed. in July) |\n| w        | 一年中第几周             | 40                      |\n| W        | 一个月中第几周           | 1                       |\n| a        | A.M./P.M. 标记           | PM                      |\n| k        | 一天中的小时(1~24)       | 24                      |\n| K        | A.M./P.M. (0~11)格式小时 | 10                      |\n| z        | 时区                     | Eastern Standard Time   |\n| '        | 文字定界符               | Delimiter               |\n| \"        | 单引号                   | `                       |\n\n#### Calendar类对象字段类型\n\nCalendar类中用以下这些常量表示不同的意义，jdk内的很多类其实都是采用的这种思想\n\n| 常量                  | 描述                           |\n| :-------------------- | :----------------------------- |\n| Calendar.YEAR         | 年份                           |\n| Calendar.MONTH        | 月份                           |\n| Calendar.DATE         | 日期                           |\n| Calendar.DAY_OF_MONTH | 日期，和上面的字段意义完全相同 |\n| Calendar.HOUR         | 12小时制的小时                 |\n| Calendar.HOUR_OF_DAY  | 24小时制的小时                 |\n| Calendar.MINUTE       | 分钟                           |\n| Calendar.SECOND       | 秒                             |\n| Calendar.DAY_OF_WEEK  | 星期几                         |"
        },
        {
          "label": "Date",
          "language": "java",
          "value": "import java.util.Date;\n\npublic class DateDemo {\n \n    public static void main(String[] args) {\n        // 初始化 Date 对象\n        Date date = new Date();\n\n        //c的使用  \n        System.out.printf(\"全部日期和时间信息：%tc%n\",date);          \n        //f的使用  \n        System.out.printf(\"年-月-日格式：%tF%n\",date);  \n        //d的使用  \n        System.out.printf(\"月/日/年格式：%tD%n\",date);  \n        //r的使用  \n        System.out.printf(\"HH:MM:SS PM格式（12时制）：%tr%n\",date);  \n        //t的使用  \n        System.out.printf(\"HH:MM:SS格式（24时制）：%tT%n\",date);  \n        //R的使用  \n        System.out.printf(\"HH:MM格式（24时制）：%tR\",date);  \n        //b的使用，月份简称  \n        String str=String.format(Locale.US,\"英文月份简称：%tb\",date);       \n        System.out.println(str);\n        System.out.printf(\"本地月份简称：%tb%n\",date);  \n        //B的使用，月份全称  \n        str=String.format(Locale.US,\"英文月份全称：%tB\",date);  \n        System.out.println(str);  \n        System.out.printf(\"本地月份全称：%tB%n\",date);  \n        //a的使用，星期简称  \n        str=String.format(Locale.US,\"英文星期的简称：%ta\",date);  \n        System.out.println(str);  \n        //A的使用，星期全称  \n        System.out.printf(\"本地星期的简称：%tA%n\",date);  \n        //C的使用，年前两位  \n        System.out.printf(\"年的前两位数字（不足两位前面补0）：%tC%n\",date);  \n        //y的使用，年后两位  \n        System.out.printf(\"年的后两位数字（不足两位前面补0）：%ty%n\",date);  \n        //j的使用，一年的天数  \n        System.out.printf(\"一年中的天数（即年的第几天）：%tj%n\",date);  \n        //m的使用，月份  \n        System.out.printf(\"两位数字的月份（不足两位前面补0）：%tm%n\",date);  \n        //d的使用，日（二位，不够补零）  \n        System.out.printf(\"两位数字的日（不足两位前面补0）：%td%n\",date);  \n        //e的使用，日（一位不补零）  \n        System.out.printf(\"月份的日（前面不补0）：%te\",date);\n\n        // 如果你需要重复提供日期，那么利用这种方式来格式化它的每一部分就有点复杂了。因此，可以利用一个格式化字符串指出要被格式化的参数的索引。索引必须紧跟在%后面，而且必须以$结束。例如：\n        // 使用toString()显示日期和时间\n        System.out.printf(\"%1$s %2$tB %2$td, %2$tY\", \"Due date:\", date);\n\n        // 或者，你可以使用 < 标志。它表明先前被格式化的参数要被再次使用。例如：\n        System.out.printf(\"%s %tB %<te, %<tY\", \"Due date:\", date);\n    \n    }\n}"
        },
        {
          "label": "SimpleDateFormat",
          "language": "java",
          "value": "import  java.util.*;\nimport java.text.*;\n \npublic class DateDemo {\n    public static void main(String[] args) {\n\n        Date dNow = new Date( );\n        SimpleDateFormat ft = new SimpleDateFormat (\"yyyy-MM-dd hh:mm:ss\");\n\n        System.out.println(\"当前时间为: \" + ft.format(dNow));\n\n        ft = new SimpleDateFormat (\"yyyy-MM-dd\"); \n \n        String input = args.length == 0 ? \"1818-11-11\" : args[0]; \n    \n        System.out.print(input + \" Parses as \"); \n    \n        Date t; \n    \n        try { \n            t = ft.parse(input); \n            System.out.println(t); \n        } catch (ParseException e) { \n            System.out.println(\"Unparseable using \" + ft); \n        }\n\n    }\n}"
        },
        {
          "label": "Calendar",
          "language": "java",
          "value": "import  java.util.*;\nimport java.text.*;\n \npublic class CalendarDemo {\n    public static void main(String[] args) {\n\n        Calendar c1 = Calendar.getInstance();\n        // 调用：\n        public final void set(int year,int month,int date)\n        c1.set(2009, 6, 12);//把Calendar对象c1的年月日分别设这为：2009、6、12\n        // 利用字段类型设置\n        // 如果只设定某个字段，例如日期的值，则可以使用如下set方法：\n        public void set(int field,int value)\n        // 把 c1对象代表的日期设置为10号，其它所有的数值会被重新计算\n        c1.set(Calendar.DATE,10);\n        // 把c1对象代表的年份设置为2008年，其他的所有数值会被重新计算\n        c1.set(Calendar.YEAR,2008);\n        // 其他字段属性set的意义以此类推\n\n        // Add设置\n        Calendar c1 = Calendar.getInstance();\n        // 把c1对象的日期加上10，也就是c1也就表示为10天后的日期，其它所有的数值会被重新计算\n        c1.add(Calendar.DATE, 10);\n        // 把c1对象的日期减去10，也就是c1也就表示为10天前的日期，其它所有的数值会被重新计算\n        c1.add(Calendar.DATE, -10);\n        // 其他字段属性的add的意义以此类推\n        \n        // Calendar类对象信息的获得\n        Calendar c1 = Calendar.getInstance();\n        // 获得年份\n        int year = c1.get(Calendar.YEAR);\n        // 获得月份\n        int month = c1.get(Calendar.MONTH) + 1;\n        // 获得日期\n        int date = c1.get(Calendar.DATE);\n        // 获得小时\n        int hour = c1.get(Calendar.HOUR_OF_DAY);\n        // 获得分钟\n        int minute = c1.get(Calendar.MINUTE);\n        // 获得秒\n        int second = c1.get(Calendar.SECOND);\n        // 获得星期几（注意（这个与Date类是不同的）：1代表星期日、2代表星期1、3代表星期二，以此类推）\n        int day = c1.get(Calendar.DAY_OF_WEEK);\n\n    }\n}"
        }
      ],
      "id": "AbH3EmmW",
      "createdAt": 1729592837789,
      "updatedAt": 1729594147444
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "Enumeration",
      "content": [
        {
          "label": "子片段 1",
          "language": "java",
          "value": "Enumeration<String> contextParams = this.getServletConfig().getServletContext().getInitParameterNames();\nwhile (contextParams.hasMoreElements()) {\n    System.out.println(contextParams.nextElement());\n}"
        }
      ],
      "id": "H2H5bD0j",
      "createdAt": 1729686223232,
      "updatedAt": 1729686318683
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "file operation",
      "content": [
        {
          "label": "子片段 1",
          "language": "java",
          "value": ""
        }
      ],
      "id": "21KruGVN",
      "createdAt": 1729687924866,
      "updatedAt": 1729687930030
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "8qmQazwt",
      "tagsIds": [
        "7pTrIPxa"
      ],
      "description": null,
      "name": "sort",
      "content": [
        {
          "label": "子片段 1",
          "language": "plain_text",
          "value": "const iconDir = 'mdi-folder'\nconst iconFile = 'mdi-clipboard-text'\nconst classDir = 'bg-blue text-white'\nconst classFile = 'bg-grey-lighten-1 text-white'\n\nlet items = [\n    {\n        \"dir\": false,\n        \"modify\": 1729691508477,\n        \"name\": \"vk_swiftshader_icd.json\",\n        \"size\": 106,\n    },\n    { dir: true, name: 'dir1', modify: 1729691508177, size: 0, },\n    { dir: false, name: 'windows11.ios', modify: 1729691508476, size: 6768468768, },\n]\nconst sortBy = \"name\"\nconst sortRevert = false\nconst fileMae = false\nitems.sort((a, b) => {\n    // Sort by dir (true comes before false)\n    if (a.dir != b.dir) {\n        return fileMae ? a.dir - b.dir : b.dir - a.dir;\n    }\n    // Sort by name if dir is the same\n    return sortRevert ? b[sortBy].localeCompare(a.name) : a[sortBy].localeCompare(b.name);\n});"
        }
      ],
      "id": "PFkiSRvG",
      "createdAt": 1729698448452,
      "updatedAt": 1729698459429
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "twJ-w0RU",
      "tagsIds": [],
      "description": null,
      "name": "adb",
      "content": [
        {
          "label": "子片段 1",
          "language": "kotlin",
          "value": ""
        }
      ],
      "id": "c3yFPa0K",
      "createdAt": 1729995684313,
      "updatedAt": 1729995689739
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "twJ-w0RU",
      "tagsIds": [],
      "description": null,
      "name": "adb shell",
      "content": [
        {
          "label": "子片段 1",
          "language": "sh",
          "value": "cat /sys/class/thermal/thermal_zone0/temp\n=> 31000\n(31 degress)"
        }
      ],
      "id": "7R69n-CJ",
      "createdAt": 1729995696227,
      "updatedAt": 1729995763766
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mdpwqphi",
      "tagsIds": [],
      "description": null,
      "name": "index",
      "content": [
        {
          "label": "unique index",
          "language": "mysql",
          "value": "-- create unique index\nCREATE UNIQUE INDEX [index_name] ON [table_name]([col_name]);\n\n-- drop a index\nDROP INDEX [index_name];\n\n-- create unique constraint will auto create unique index\nALTER TABLE [table_name] ADD CONSTRAINT [constraint_name] UNIQUE ([col_name]);"
        },
        {
          "label": "子片段 2",
          "language": "mysql",
          "value": ""
        }
      ],
      "id": "wNyYssz6",
      "createdAt": 1730010827372,
      "updatedAt": 1730011205993
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "JDBCUtil",
      "content": [
        {
          "label": "子片段 1",
          "language": "java",
          "value": "import com.zaxxer.hikari.HikariConfig;\nimport com.zaxxer.hikari.HikariDataSource;\n\nimport javax.sql.DataSource;\nimport java.io.InputStream;\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.Date;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Properties;\n\n/**\n * JDBC Util class\n * 1. connection pool maintenance\n * 2. get connection\n * 3. recycle connection\n * 4. bind one connectino to one thread\n */\npublic class JDBCUtil {\n    private static volatile DataSource ds;\n    private static ThreadLocal<Connection> threadConn = new ThreadLocal<>();\n\n    private static void genDataSource() {\n        try {\n            Properties prop = new Properties();\n            InputStream in = JDBCUtil.class.getClassLoader().getResourceAsStream(\"db_h.properties\");\n            prop.load(in);\n            HikariConfig config = new HikariConfig(prop);\n            ds = new HikariDataSource(config);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static synchronized DataSource getDataSource() {\n        if (ds == null) {\n            System.out.println(\"construct DataSource\");\n            genDataSource();\n        }\n        return ds;\n    }\n\n    public static Connection getConnection() throws SQLException {\n        Connection conn = threadConn.get();\n        if (conn == null) {\n            conn = JDBCUtilWithThreadLocal.getDataSource().getConnection();\n            threadConn.set(conn);\n        }\n        return conn;\n    }\n\n    public static void release() throws SQLException {\n        Connection conn = threadConn.get();\n        if (conn != null && conn.getAutoCommit()) {\n            threadConn.remove();\n            conn.close();\n        } else {\n            System.out.println(\"change connection autocommit to true before release\");\n        }\n    }\n}\n"
        }
      ],
      "id": "_OfPgq3j",
      "createdAt": 1730442665245,
      "updatedAt": 1730443741203
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "Hikari",
      "content": [
        {
          "label": "Usage",
          "language": "java",
          "value": "package com.li.schedule.sqlTest.advanced;\n\nimport com.li.schedule.sqlTest.advanced.pojo.Employee;\nimport com.zaxxer.hikari.HikariConfig;\nimport com.zaxxer.hikari.HikariDataSource;\nimport org.junit.jupiter.api.Test;\n\nimport javax.sql.DataSource;\nimport java.io.InputStream;\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.util.Date;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Properties;\n\npublic class HikariTest {\n    @Test\n    public void hardTest() throws Exception {\n        // create hikari datasource and configure\n        HikariDataSource hds = new HikariDataSource();\n        hds.setDriverClassName(\"com.mysql.cj.jdbc.Driver\");\n        hds.setJdbcUrl(\"jdbc:mysql://127.0.0.1:13306/webtest\");\n        hds.setUsername(\"root\");\n        hds.setPassword(\"lijunjie\");\n        hds.setMinimumIdle(5);\n        hds.setMaximumPoolSize(10);\n\n        System.out.println(hds);\n\n        List<Thread> threads = new LinkedList<>();\n        for (int i = 1; i < 12; i++) {\n            final String emp_id = String.valueOf(i);\n            threads.add(new Thread(() -> {\n                System.out.println(Thread.currentThread().getId());\n                try (Connection conn = hds.getConnection()) {\n                    System.out.println(conn);\n                    Thread.sleep(2000);\n                    try (PreparedStatement ps = conn.prepareStatement(\"SELECT * FROM `t_emp` WHERE `emp_id`=?\")) {\n                        ps.setString(1, emp_id);\n                        try (ResultSet rs = ps.executeQuery()) {\n                            while (rs.next())\n                                System.out.println(\n                                        new Employee(\n                                                rs.getInt(\"emp_id\"),\n                                                rs.getString(\"emp_name\"),\n                                                rs.getInt(\"emp_age\"),\n                                                rs.getDouble(\"emp_salary\")\n                                        )\n                                );\n                        }\n                    }\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }));\n        }\n        for (Thread thread : threads)\n            thread.start();\n\n        for (Thread thread : threads)\n            thread.join();\n\n    }\n\n    @Test\n    public void softTest() throws Exception {\n        // create properties set\n        Properties hikariProperties = new Properties();\n        // read properties file\n        InputStream propertiesInputStream = this.getClass().getClassLoader().getResourceAsStream(\"db_h.properties\");\n        hikariProperties.load(propertiesInputStream);\n        // create HikariConfig object with properties set\n        HikariConfig hikariConfig = new HikariConfig(hikariProperties);\n        // create HikariDataSource with HikariConfig\n        HikariDataSource hds = new HikariDataSource(hikariConfig);\n\n        System.out.println(hds);\n\n        Date start = new Date();\n\n        List<Thread> threads = new LinkedList<>();\n        for (int i = 1; i < 12; i++) {\n            final String emp_id = String.valueOf(i);\n            threads.add(new Thread(() -> {\n                System.out.println(Thread.currentThread().getId());\n                try (Connection conn = hds.getConnection()) {\n                    System.out.println(conn);\n                    Thread.sleep(2000);\n                    try (PreparedStatement ps = conn.prepareStatement(\"SELECT * FROM `t_emp` WHERE `emp_id`=?\")) {\n                        ps.setString(1, emp_id);\n                        try (ResultSet rs = ps.executeQuery()) {\n                            while (rs.next())\n                                System.out.println(\n                                        new Employee(\n                                                rs.getInt(\"emp_id\"),\n                                                rs.getString(\"emp_name\"),\n                                                rs.getInt(\"emp_age\"),\n                                                rs.getDouble(\"emp_salary\")\n                                        )\n                                );\n                        }\n                    }\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }));\n        }\n        for (Thread thread : threads)\n            thread.start();\n\n        for (Thread thread : threads)\n            thread.join();\n\n        System.out.println(String.format(\"use time: %dms\", System.currentTimeMillis() - start.getTime()));\n    }\n}\n"
        },
        {
          "label": "properties",
          "language": "properties",
          "value": "driverClassName=com.mysql.cj.jdbc.Driver\njdbcUrl=jdbc:mysql://127.0.0.1:13306/webtest\nusername=root\npassword=lijunjie\nminimumIdle=5\nmaximumPoolSize=10"
        }
      ],
      "id": "Hk937jtY",
      "createdAt": 1730442723263,
      "updatedAt": 1730442804959
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "Druid",
      "content": [
        {
          "label": "Usage",
          "language": "java",
          "value": "package com.li.schedule.sqlTest.advanced;\n\nimport com.alibaba.druid.pool.DruidDataSource;\nimport com.alibaba.druid.pool.DruidDataSourceFactory;\nimport com.li.schedule.sqlTest.advanced.pojo.Employee;\nimport org.junit.jupiter.api.Test;\n\nimport javax.sql.DataSource;\nimport java.io.InputStream;\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.Date;\nimport java.util.LinkedList;\nimport java.util.List;\nimport java.util.Properties;\n\npublic class DruidTest {\n\n    @Test\n    public void hardDruid() throws Exception {\n        DruidDataSource dds = new DruidDataSource();\n        dds.setDriverClassName(\"com.mysql.cj.jdbc.Driver\");\n        dds.setUsername(\"root\");\n        dds.setPassword(\"lijunjie\");\n        dds.setUrl(\"jdbc:mysql://127.0.0.1:13306/webtest\");\n        dds.setInitialSize(5);\n        dds.setMaxActive(10);\n\n        List<Thread> threads = new LinkedList<>();\n        for (int i = 1; i < 12; i++) {\n            final String emp_id = String.valueOf(i);\n            threads.add(new Thread(() -> {\n                System.out.println(Thread.currentThread().getId());\n                try (Connection conn = dds.getConnection()) {\n                    System.out.println(conn);\n                    Thread.sleep(2000);\n                    try (PreparedStatement ps = conn.prepareStatement(\"SELECT * FROM `t_emp` WHERE `emp_id`=?\")) {\n                        ps.setString(1, emp_id);\n                        try (ResultSet rs = ps.executeQuery()) {\n                            while (rs.next())\n                                System.out.println(\n                                        new Employee(\n                                                rs.getInt(\"emp_id\"),\n                                                rs.getString(\"emp_name\"),\n                                                rs.getInt(\"emp_age\"),\n                                                rs.getDouble(\"emp_salary\")\n                                        )\n                                );\n                        }\n                    }\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }));\n        }\n        for (Thread thread : threads)\n            thread.start();\n\n        for (Thread thread : threads)\n            thread.join();\n\n    }\n\n    @Test\n    public void softDruid() throws Exception {\n        // get properties context\n        Properties druidProperties = new Properties();\n        InputStream propertiesInputStream = this.getClass().getClassLoader().getResourceAsStream(\"db.properties\");\n        druidProperties.load(propertiesInputStream);\n\n        // create DruidDataSource by DruidDataSourceFactory\n        DataSource dds = DruidDataSourceFactory.createDataSource(druidProperties);\n        System.out.println(dds);\n\n        Date start = new Date();\n\n        List<Thread> threads = new LinkedList<>();\n        for (int i = 1; i < 12; i++) {\n            final String emp_id = String.valueOf(i);\n            threads.add(new Thread(() -> {\n                System.out.println(Thread.currentThread().getId());\n                try (Connection conn = dds.getConnection()) {\n                    System.out.println(conn);\n                    Thread.sleep(2000);\n                    try (PreparedStatement ps = conn.prepareStatement(\"SELECT * FROM `t_emp` WHERE `emp_id`=?\")) {\n                        ps.setString(1, emp_id);\n                        try (ResultSet rs = ps.executeQuery()) {\n                            while (rs.next())\n                                System.out.println(\n                                        new Employee(\n                                                rs.getInt(\"emp_id\"),\n                                                rs.getString(\"emp_name\"),\n                                                rs.getInt(\"emp_age\"),\n                                                rs.getDouble(\"emp_salary\")\n                                        )\n                                );\n                        }\n                    }\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }));\n        }\n        for (Thread thread : threads)\n            thread.start();\n\n        for (Thread thread : threads)\n            thread.join();\n\n        System.out.println(String.format(\"use time: %dms\", System.currentTimeMillis() - start.getTime()));\n    }\n}\n"
        },
        {
          "label": "properties",
          "language": "properties",
          "value": "driverClassName=com.mysql.cj.jdbc.Driver\nurl=jdbc:mysql://127.0.0.1:13306/webtest\nusername=root\npassword=lijunjie\ninitialSize=5\nmaxAcitve=10"
        }
      ],
      "id": "Y92k6ez5",
      "createdAt": 1730442729363,
      "updatedAt": 1730443055717
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "BaseDao",
      "content": [
        {
          "label": "子片段 1",
          "language": "java",
          "value": "package com.li.schedule.dao.impl;\n\nimport com.li.schedule.utils.JDBCUtil;\n\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\n\nimport java.lang.reflect.Field;\nimport java.sql.*;\nimport java.util.LinkedList;\nimport java.util.List;\n\npublic class BaseDao {\n    /**\n     * general update one row\n     *\n     * @param sql:    sql setence\n     * @param params: variable in sql\n     * @return affect row\n     * @throws Exception\n     */\n    public int executeUpdate(String sql, Object... params) throws Exception {\n        Connection conn = JDBCUtil.getConnection();\n        System.out.println(String.format(\"[Connection]: %s, [autoCommit]: %s\" , conn, conn.getAutoCommit()));\n        int row = 0;\n        try (PreparedStatement ps = conn.prepareStatement(sql)) {\n            for (int i = 0; i < params.length; i++) {\n                ps.setObject(i + 1, params[i]);\n            }\n            row = ps.executeUpdate();\n        }\n        JDBCUtil.release();\n        return row;\n    }\n\n    /**\n     * general insert one row with generated keys return\n     *\n     * @param sql:    sql setence\n     * @param params: variable in sql\n     * @return affect row\n     * @throws Exception\n     */\n    public int executeInsertWithGenKey(String sql, Object... params) throws Exception {\n        Connection conn = JDBCUtil.getConnection();\n        int GENERATED_KEY = -1;\n        Timestamp TIMESTAMP = null;\n        try (PreparedStatement ps = conn.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS)) {\n            for (int i = 0; i < params.length; i++) {\n                ps.setObject(i + 1, params[i]);\n            }\n            int row = ps.executeUpdate();\n            if (row > 0) {\n                try (ResultSet rs = ps.getGeneratedKeys()) {\n                    if (rs.next()) {\n                        GENERATED_KEY = rs.getInt(1);\n                    }\n                }\n            }\n        }\n        JDBCUtil.release();\n        return GENERATED_KEY;\n    }\n\n    /**\n     * general query\n     *\n     * @param clazz:  DAO object class\n     * @param sql:    sql setence\n     * @param params: variable in sql\n     * @return query result\n     * @throws\n     */\n    public <T> List<T> executeQuery(Class<T> clazz, String sql, Object... params) throws Exception {\n        Connection conn = JDBCUtil.getConnection();\n        List<T> clazzList = new LinkedList<>();\n        try (PreparedStatement ps = conn.prepareStatement(sql)) {\n            for (int i = 0; i < params.length; i++) {\n                ps.setObject(i + 1, params[i]);\n            }\n            try (ResultSet rs = ps.executeQuery()) {\n                ResultSetMetaData rsmd = rs.getMetaData();\n                int columnCount = rsmd.getColumnCount();\n                while (rs.next()) {\n                    T t = clazz.getDeclaredConstructor().newInstance();\n                    for (int i = 1; i <= columnCount; i++) {\n                        String fieldName = rsmd.getColumnLabel(i);\n                        Field field = clazz.getDeclaredField(fieldName);\n                        field.setAccessible(true);\n                        field.set(t, rs.getObject(i));\n                        field.setAccessible(false);\n                    }\n                    clazzList.add(t);\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        JDBCUtil.release();\n        return clazzList;\n    }\n\n    /**\n     * general only first row of query\n     *\n     * @param clazz:  DAO object class\n     * @param sql:    sql setence\n     * @param params: variable in sql\n     * @return query result\n     * @throws\n     */\n    public <T> T executeQuery4OneRow(Class<T> clazz, String sql, Object... params) throws Exception {\n        List<T> result = this.executeQuery(clazz, sql, params);\n        if (result.size() > 0) {\n            return result.get(0);\n        } else return null;\n    }\n\n    public static String MD5(String input) {\n        try {\n            MessageDigest md = MessageDigest.getInstance(\"MD5\");\n            byte[] messageDigest = md.digest(input.getBytes());\n            // Convert byte array into signum representation\n            StringBuilder sb = new StringBuilder();\n            for (byte b : messageDigest) {\n                sb.append(String.format(\"%02x\", b));\n            }\n            return sb.toString();\n        } catch (NoSuchAlgorithmException e) {\n            throw new RuntimeException(e);\n        }\n    }\n}\n"
        }
      ],
      "id": "MHNAR16x",
      "createdAt": 1730443704269,
      "updatedAt": 1730443781611
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "YOLOV8",
      "content": [
        {
          "label": "TaskAlignedAssigner",
          "language": "python",
          "value": "# Ultralytics YOLO 🚀, AGPL-3.0 license\n\nimport torch\nimport torch.nn as nn\n\nfrom .checks import check_version\nfrom .metrics import bbox_iou, probiou\nfrom .ops import xywhr2xyxyxyxy\n\nTORCH_1_10 = check_version(torch.__version__, \"1.10.0\")\n\n\nclass TaskAlignedAssigner(nn.Module):\n    \"\"\"\n    A task-aligned assigner for object detection.\n\n    This class assigns ground-truth (gt) objects to anchors based on the task-aligned metric, which combines both\n    classification and localization information.\n\n    Attributes:\n        topk (int): The number of top candidates to consider.\n        num_classes (int): The number of object classes.\n        alpha (float): The alpha parameter for the classification component of the task-aligned metric.\n        beta (float): The beta parameter for the localization component of the task-aligned metric.\n        eps (float): A small value to prevent division by zero.\n    \"\"\"\n\n    def __init__(self, topk=13, num_classes=80, alpha=1.0, beta=6.0, eps=1e-9):\n        \"\"\"Initialize a TaskAlignedAssigner object with customizable hyperparameters.\"\"\"\n        super().__init__()\n        self.topk = topk\n        self.num_classes = num_classes\n        self.bg_idx = num_classes # 背景的类别编号\n        self.alpha = alpha\n        self.beta = beta\n        self.eps = eps\n\n    @torch.no_grad()\n    def forward(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt):\n        \"\"\"\n        Compute the task-aligned assignment. Reference code is available at\n        https://github.com/Nioolek/PPYOLOE_pytorch/blob/master/ppyoloe/assigner/tal_assigner.py.\n\n        Args:\n            pd_scores (Tensor): shape(bs, num_total_anchors, num_classes)，预测分类，锚点属于每一个分类的概率。\n            pd_bboxes (Tensor): shape(bs, num_total_anchors, 4)，预测偏移量，已经从 DFL 的一般分布转为标量（Scalar）。 \n            anc_points (Tensor): shape(num_total_anchors, 2)，辅助 Tensor，方便锚点偏移量和框坐标的转换。\n            gt_labels (Tensor): shape(bs, n_max_boxes, 1)，人工标记的 GT 框对应的分类编号\n            gt_bboxes (Tensor): shape(bs, n_max_boxes, 4)，人工标记的 GT 框坐标，xyxy\n            mask_gt (Tensor): shape(bs, n_max_boxes, 1)，由于 GT 框数量一般少于 n_max_boxes, 向量运算一般基于同一形状，该变量表示 gt_bboxes 的位置是否有真实 GT 还是空位补齐。\n\n        Returns:\n            target_labels (Tensor): shape(bs, num_total_anchors)\n            target_bboxes (Tensor): shape(bs, num_total_anchors, 4)\n            target_scores (Tensor): shape(bs, num_total_anchors, num_classes)\n            fg_mask (Tensor): shape(bs, num_total_anchors)\n            target_gt_idx (Tensor): shape(bs, num_total_anchors)\n        \"\"\"\n        self.bs = pd_scores.shape[0]\n        self.n_max_boxes = gt_bboxes.shape[1]\n\n        if self.n_max_boxes == 0:\n            device = gt_bboxes.device\n            return (\n                torch.full_like(pd_scores[..., 0], self.bg_idx).to(device),\n                torch.zeros_like(pd_bboxes).to(device),\n                torch.zeros_like(pd_scores).to(device),\n                torch.zeros_like(pd_scores[..., 0]).to(device),\n                torch.zeros_like(pd_scores[..., 0]).to(device),\n            )\n\n        mask_pos, align_metric, overlaps = self.get_pos_mask(\n            pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt\n        )\n\n        target_gt_idx, fg_mask, mask_pos = self.select_highest_overlaps(mask_pos, overlaps, self.n_max_boxes)\n\n        # Assigned target\n        target_labels, target_bboxes, target_scores = self.get_targets(gt_labels, gt_bboxes, target_gt_idx, fg_mask)\n\n        # Normalize\n        align_metric *= mask_pos\n        pos_align_metrics = align_metric.amax(dim=-1, keepdim=True)  # b, max_num_obj\n        pos_overlaps = (overlaps * mask_pos).amax(dim=-1, keepdim=True)  # b, max_num_obj\n        norm_align_metric = (align_metric * pos_overlaps / (pos_align_metrics + self.eps)).amax(-2).unsqueeze(-1)\n        target_scores = target_scores * norm_align_metric\n\n        return target_labels, target_bboxes, target_scores, fg_mask.bool(), target_gt_idx\n\n    def get_pos_mask(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt):\n        \"\"\"\n        该方法通过筛选锚点在 GT 框内的掩码、计算对齐分数和 IoU 值，\n        对每一个 GT 框，生成掩码锚点图（也就是说，获取锚点是否在任一 GT 内的掩码，不涉及预测值）\n        返回 mask_pos、align_metric 和 overlaps。\n\n        @return:\n            mask_in_gts: 标识锚点是否在 GT 框内。\n            align_metric: 根据分类得分和 IoU 计算的对齐分数。\n            overlaps: 锚点和 GT 框之间的 IoU 值。\n        \"\"\"\n        # mask_in_gts.shape -> (b, max_num_obj, h*w)\n        \"\"\"Get in_gts mask, (b, max_num_obj, h*w).\"\"\"\n        mask_in_gts = self.select_candidates_in_gts(anc_points, gt_bboxes)\n        # 获取锚点预测值和 GT 框的对齐分数及 IOU 值。\n        # 返回 shape(b, max_num_obj, h*w)\n        # Get anchor_align metric, (b, max_num_obj, h*w)\n        align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n        # Get topk_metric mask, (b, max_num_obj, h*w)\n        mask_topk = self.select_topk_candidates(align_metric, topk_mask=mask_gt.expand(-1, -1, self.topk).bool())\n        # Merge all mask to a final mask, (b, max_num_obj, h*w)\n        mask_pos = mask_topk * mask_in_gts * mask_gt\n\n        return mask_pos, align_metric, overlaps\n\n    def get_box_metrics(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_gt):\n        \"\"\"Compute alignment metric given predicted and ground truth bounding boxes.\n        （计算所有预测框和 GT 框的对齐分数、CIoU值，已经通过锚点在 GT 框内过滤）\n        \n        Args:\n            pd_scores (Tensor): shape(bs, num_total_anchors, num_classes)，预测分类，锚点属于每一个分类的概率。\n        \"\"\"\n        na = pd_bboxes.shape[-2] # num_total_anchors，锚点数量\n        mask_gt = mask_gt.bool()  # (b, max_num_obj, h*w)\n        overlaps = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_bboxes.dtype, device=pd_bboxes.device)\n\n        # 初始化为 0。 bbox_scores (Tensor): shape(bs, n_max_boxes, na)，注意，形状和 pd_scores 不相同。\n        bbox_scores = torch.zeros([self.bs, self.n_max_boxes, na], dtype=pd_scores.dtype, device=pd_scores.device)\n\n        ind = torch.zeros([2, self.bs, self.n_max_boxes], dtype=torch.long)  # 2, b, max_num_obj\n        # 【方便理解代码的示例】\n        #   代码：torch.arange(end=3).view(-1, 1).expand(-1, 4)\n        #   返回：tensor([[0, 0, 0, 0], \n        #                [1, 1, 1, 1], \n        #                [2, 2, 2, 2]])\n        # 返回 (b, max_num_obj)\n        ind[0] = torch.arange(end=self.bs).view(-1, 1).expand(-1, self.n_max_boxes)  \n        # gt_labels (Tensor): shape(bs, n_max_boxes, 1)。对最后一个维度挤压后，返回 (b, max_num_obj)\n        ind[1] = gt_labels.squeeze(-1)  \n        \n        # Get the scores of each grid for each gt cls\n        bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w\n\n        # pd_bboxes.unsqueeze(1): unsqueeze 操作用于增加一个维度。这里在索引为1的位置增加一个维度，使得 pd_bboxes 的形状从 (bs, h*w, 4) 变为 (bs, 1, h*w, 4)。\n        #           .expand(-1, self.n_max_boxes, -1, -1): expand 操作用于扩展张量的形状。参数 -1 表示该维度保持原样不变。因此，这个操作将 (bs, 1, h*w, 4) 形状的张量扩展为 (bs, n_max_boxes, h*w, 4)。\n        #           [mask_gt]: 最后，使用 mask_gt 张量作为索引来选择 expand 后张量中对应位置的元素。mask_gt 是一个布尔型张量，形状为 (bs, n_max_boxes, h*w)，其中 True 表示相应的锚点与某个真实目标匹配，False 表示不匹配。这个索引操作将 (bs, n_max_boxes, h*w, 4) 形状的张量中不匹配的位置（即 False 位置）设置为0（因为在前面创建的 overlaps 和 bbox_scores 中使用了 torch.zeros），而匹配的位置则保留了扩展后的值。\n        # (b, max_num_obj, 1, 4), (b, 1, h*w, 4)\n\t\tpd_boxes = pd_bboxes.unsqueeze(1).expand(-1, self.n_max_boxes, -1, -1)[mask_gt]\n        # 扩展后和 pd_boxes 形状一致。\n        gt_boxes = gt_bboxes.unsqueeze(2).expand(-1, -1, na, -1)[mask_gt]\n        # 计算预测框和 GT 框的 iou 得分\n        overlaps[mask_gt] = self.iou_calculation(gt_boxes, pd_boxes)\n        # 最终的对齐分数。参考论文 2108.07755 - 3.2.1 Task-aligned Sample Assignment。\n        align_metric = bbox_scores.pow(self.alpha) * overlaps.pow(self.beta)\n        # 每个 GT 框在锚点图上的的对齐得分、重叠度， shape(b, max_num_obj, na)\n        return align_metric, overlaps\n\n    def iou_calculation(self, gt_bboxes, pd_bboxes):\n        \"\"\"IoU calculation for horizontal bounding boxes.\"\"\"\n        return bbox_iou(gt_bboxes, pd_bboxes, xywh=False, CIoU=True).squeeze(-1).clamp_(0)\n\n    def select_topk_candidates(self, metrics, largest=True, topk_mask=None):\n        \"\"\"\n        Select the top-k candidates based on the given metrics.（对每个 GT 框，根据对齐分数，选取 topk 个锚点）\n\n        Args:\n            metrics (Tensor): A tensor of shape (b, max_num_obj, h*w), where b is the batch size,\n                              max_num_obj is the maximum number of objects, and h*w represents the\n                              total number of anchor points.\n            largest (bool): If True, select the largest values; otherwise, select the smallest values.\n            topk_mask (Tensor): An optional boolean tensor of shape (b, max_num_obj, topk), where\n                                topk is the number of top candidates to consider. If not provided,\n                                the top-k values are automatically computed based on the given metrics.\n\n        Returns:\n            (Tensor): A tensor of shape (b, max_num_obj, h*w) containing the selected top-k candidates.\n        \"\"\"\n        # (b, max_num_obj, topk)\n        topk_metrics, topk_idxs = torch.topk(metrics, self.topk, dim=-1, largest=largest)\n        if topk_mask is None:\n            topk_mask = (topk_metrics.max(-1, keepdim=True)[0] > self.eps).expand_as(topk_idxs)\n        # (b, max_num_obj, topk)\n        topk_idxs.masked_fill_(~topk_mask, 0)\n\n        # (b, max_num_obj, topk, h*w) -> (b, max_num_obj, h*w)\n        count_tensor = torch.zeros(metrics.shape, dtype=torch.int8, device=topk_idxs.device)\n        ones = torch.ones_like(topk_idxs[:, :, :1], dtype=torch.int8, device=topk_idxs.device)\n        for k in range(self.topk):\n            # Expand topk_idxs for each value of k and add 1 at the specified positions\n            count_tensor.scatter_add_(-1, topk_idxs[:, :, k : k + 1], ones)\n        # count_tensor.scatter_add_(-1, topk_idxs, torch.ones_like(topk_idxs, dtype=torch.int8, device=topk_idxs.device))\n        # Filter invalid bboxes\n        count_tensor.masked_fill_(count_tensor > 1, 0)\n\n        return count_tensor.to(metrics.dtype)\n\n    def get_targets(self, gt_labels, gt_bboxes, target_gt_idx, fg_mask):\n        \"\"\"\n        Compute target labels, target bounding boxes, and target scores for the positive anchor points.\n\n        Args:\n            gt_labels (Tensor): Ground truth labels of shape (b, max_num_obj, 1), where b is the\n                                batch size and max_num_obj is the maximum number of objects.\n            gt_bboxes (Tensor): Ground truth bounding boxes of shape (b, max_num_obj, 4).\n            target_gt_idx (Tensor): Indices of the assigned ground truth objects for positive\n                                    anchor points, with shape (b, h*w), where h*w is the total\n                                    number of anchor points.\n            fg_mask (Tensor): A boolean tensor of shape (b, h*w) indicating the positive\n                              (foreground) anchor points.\n\n        Returns:\n            (Tuple[Tensor, Tensor, Tensor]): A tuple containing the following tensors:\n                - target_labels (Tensor): Shape (b, h*w), containing the target labels for\n                                          positive anchor points.\n                - target_bboxes (Tensor): Shape (b, h*w, 4), containing the target bounding boxes\n                                          for positive anchor points.\n                - target_scores (Tensor): Shape (b, h*w, num_classes), containing the target scores\n                                          for positive anchor points, where num_classes is the number\n                                          of object classes.\n        \"\"\"\n        # Assigned target labels, (b, 1)\n        batch_ind = torch.arange(end=self.bs, dtype=torch.int64, device=gt_labels.device)[..., None]\n        target_gt_idx = target_gt_idx + batch_ind * self.n_max_boxes  # (b, h*w)\n        target_labels = gt_labels.long().flatten()[target_gt_idx]  # (b, h*w)\n\n        # Assigned target boxes, (b, max_num_obj, 4) -> (b, h*w, 4)\n        target_bboxes = gt_bboxes.view(-1, gt_bboxes.shape[-1])[target_gt_idx]\n\n        # Assigned target scores\n        target_labels.clamp_(0)\n\n        # 10x faster than F.one_hot()\n        target_scores = torch.zeros(\n            (target_labels.shape[0], target_labels.shape[1], self.num_classes),\n            dtype=torch.int64,\n            device=target_labels.device,\n        )  # (b, h*w, 80)\n        target_scores.scatter_(2, target_labels.unsqueeze(-1), 1)\n\n        fg_scores_mask = fg_mask[:, :, None].repeat(1, 1, self.num_classes)  # (b, h*w, 80)\n        target_scores = torch.where(fg_scores_mask > 0, target_scores, 0)\n\n        return target_labels, target_bboxes, target_scores\n\n    @staticmethod\n    def select_candidates_in_gts(xy_centers, gt_bboxes, eps=1e-9):\n        \"\"\"\n        Select positive anchor centers within ground truth bounding boxes.\n\t\t选择在 GT 内的锚点中心，用作正样本。即对每一个 GT 框，生成掩码锚点图。\n\n        Args:\n            xy_centers (torch.Tensor): Anchor center coordinates, shape (h*w, 2).，锚点中心坐标，不涉及模型预测值\n            gt_bboxes (torch.Tensor): Ground truth bounding boxes, shape (b, n_boxes, 4).\n            eps (float, optional): Small value for numerical stability. Defaults to 1e-9.\n\n        Returns:\n            (torch.Tensor): Boolean mask of positive anchors, shape (b, n_boxes, h*w).\n\n        Note:\n            b: batch size, n_boxes: number of ground truth boxes, h: height, w: width.\n            Bounding box format: [x_min, y_min, x_max, y_max].\n        \"\"\"\n        n_anchors = xy_centers.shape[0] # 锚点总数\n        bs, n_boxes, _ = gt_bboxes.shape # 获取批次大小bs和每个图片中真实目标的数量 n_boxes\n\n        # 将 gt_bboxes 拆分为左上角坐标 lt 和右下角坐标 rb\n        # lt (Tensor): shape(b*n_boxes, 1, 2)\n        lt, rb = gt_bboxes.view(-1, 1, 4).chunk(2, 2)  # left-top, right-bottom\n    \n        # 计算了每个锚点中心相对于每个 GT 左上角的差值以及每个 GT 右下角与锚点中心的差值，小于 0 表示不在框内。\n        # xy_centers[None] (Tensor):shape(1, h*w, 2)\n        # xy_centers[None] - lt (Tensor): shape(b*n_boxes, h*w, 2)，这里用到了第 0、1 维度的自动扩展（即广播）。\n        # bbox_deltas (Tensor): shape(b, n_boxes, n_anchors, 4)，\n        bbox_deltas = torch.cat((xy_centers[None] - lt, rb - xy_centers[None]), dim=2).view(bs, n_boxes, n_anchors, -1)\n        # return (bbox_deltas.min(3)[0] > eps).to(gt_bboxes.dtype)\n\t\t# amin(3)要求所有 4 个比对值都必须大于 0\n        return bbox_deltas.amin(3).gt_(eps)\n\n    @staticmethod\n    def select_highest_overlaps(mask_pos, overlaps, n_max_boxes):\n        \"\"\"\n        Select anchor boxes with highest IoU when assigned to multiple ground truths.\n\n        Args:\n            mask_pos (torch.Tensor): Positive mask, shape (b, n_max_boxes, h*w).\n            overlaps (torch.Tensor): IoU overlaps, shape (b, n_max_boxes, h*w).\n            n_max_boxes (int): Maximum number of ground truth boxes.\n\n        Returns:\n            target_gt_idx (torch.Tensor): Indices of assigned ground truths, shape (b, h*w).\n            fg_mask (torch.Tensor): Foreground mask, shape (b, h*w).\n            mask_pos (torch.Tensor): Updated positive mask, shape (b, n_max_boxes, h*w).\n\n        Note:\n            b: batch size, h: height, w: width.\n        \"\"\"\n        # Convert (b, n_max_boxes, h*w) -> (b, h*w)\n        fg_mask = mask_pos.sum(-2) # 对每一个锚点，统计对应的 GT 总数\n        if fg_mask.max() > 1:  # one anchor is assigned to multiple gt_bboxes\n            mask_multi_gts = (fg_mask.unsqueeze(1) > 1).expand(-1, n_max_boxes, -1)  # (b, n_max_boxes, h*w)\n            max_overlaps_idx = overlaps.argmax(1)  # (b, h*w)\n\n            is_max_overlaps = torch.zeros(mask_pos.shape, dtype=mask_pos.dtype, device=mask_pos.device)\n            is_max_overlaps.scatter_(1, max_overlaps_idx.unsqueeze(1), 1)\n\n            mask_pos = torch.where(mask_multi_gts, is_max_overlaps, mask_pos).float()  # (b, n_max_boxes, h*w)\n            fg_mask = mask_pos.sum(-2)\n        # Find each grid serve which gt(index)\n        target_gt_idx = mask_pos.argmax(-2)  # (b, h*w)\n        return target_gt_idx, fg_mask, mask_pos\n\n\nclass RotatedTaskAlignedAssigner(TaskAlignedAssigner):\n    \"\"\"Assigns ground-truth objects to rotated bounding boxes using a task-aligned metric.\"\"\"\n\n    def iou_calculation(self, gt_bboxes, pd_bboxes):\n        \"\"\"IoU calculation for rotated bounding boxes.\"\"\"\n        return probiou(gt_bboxes, pd_bboxes).squeeze(-1).clamp_(0)\n\n    @staticmethod\n    def select_candidates_in_gts(xy_centers, gt_bboxes):\n        \"\"\"\n        Select the positive anchor center in gt for rotated bounding boxes.\n\n        Args:\n            xy_centers (Tensor): shape(h*w, 2)\n            gt_bboxes (Tensor): shape(b, n_boxes, 5)\n\n        Returns:\n            (Tensor): shape(b, n_boxes, h*w)\n        \"\"\"\n        # (b, n_boxes, 5) --> (b, n_boxes, 4, 2)\n        corners = xywhr2xyxyxyxy(gt_bboxes)\n        # (b, n_boxes, 1, 2)\n        a, b, _, d = corners.split(1, dim=-2)\n        ab = b - a\n        ad = d - a\n\n        # (b, n_boxes, h*w, 2)\n        ap = xy_centers - a\n        norm_ab = (ab * ab).sum(dim=-1)\n        norm_ad = (ad * ad).sum(dim=-1)\n        ap_dot_ab = (ap * ab).sum(dim=-1)\n        ap_dot_ad = (ap * ad).sum(dim=-1)\n        return (ap_dot_ab >= 0) & (ap_dot_ab <= norm_ab) & (ap_dot_ad >= 0) & (ap_dot_ad <= norm_ad)  # is_in_box\n\n\ndef make_anchors(feats, strides, grid_cell_offset=0.5):\n    \"\"\"Generate anchors from features.\n        feats 为模型预测值，对于 Detect 任务，head.py 中 Detect 的输出为(x0,x1,x2)，x[0]的shape(N, reg_max*4+nc , H, W)\n        输出 anchor_points 为坐标点的集合，包括（x0,x1,x2）H,W 对应的所有坐标。\n    \"\"\"\n    anchor_points, stride_tensor = [], []\n    assert feats is not None\n    dtype, device = feats[0].dtype, feats[0].device\n    for i, stride in enumerate(strides):\n        _, _, h, w = feats[i].shape\n        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x\n        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y\n        sy, sx = torch.meshgrid(sy, sx, indexing=\"ij\") if TORCH_1_10 else torch.meshgrid(sy, sx)\n        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))\n        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n    return torch.cat(anchor_points), torch.cat(stride_tensor)\n\n\ndef dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n    \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\"\"\"\n    lt, rb = distance.chunk(2, dim)\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)  # xywh bbox\n    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox\n\n\ndef bbox2dist(anchor_points, bbox, reg_max):\n    \"\"\"Transform bbox(xyxy) to dist(ltrb).\n    将框由 xyxy 坐标形式变成相对锚点的偏移量形式（左上右下）。\n    anchor_points 为坐标点，如对于长宽为 8*5 的图，\n    [[0,0],[1,0], ...,  [7,0], \n     [0,1], [1,1], ..., [7,1],\n     [0,2], [1,2], ..., [7,2],\n     [0,3], [1,3], ..., [7,3],\n     [0,4], [1,4], ..., [7,4]]\n    基于 torch 的维度自动扩展，anchor_points 方便锚点位置转换的计算\n    \"\"\"\n    x1y1, x2y2 = bbox.chunk(2, -1)\n\t# 最后一个维度 [x1, y1, x2, y2]，分成 2 份，变成 [x1, y1] [x2,y2]。前面的维度不变。\n    # 先计算左、上、右、下的偏移量，然后将其取值范围压缩(clamp_) 到 [0, reg_max - 0.01] 之间\n    return torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -1).clamp_(0, reg_max - 0.01)  # dist (lt, rb)\n\n\ndef dist2rbox(pred_dist, pred_angle, anchor_points, dim=-1):\n    \"\"\"\n    Decode predicted rotated bounding box coordinates from anchor points and distribution.\n\n    Args:\n        pred_dist (torch.Tensor): Predicted rotated distance, shape (bs, h*w, 4).\n        pred_angle (torch.Tensor): Predicted angle, shape (bs, h*w, 1).\n        anchor_points (torch.Tensor): Anchor points, shape (h*w, 2).\n        dim (int, optional): Dimension along which to split. Defaults to -1.\n\n    Returns:\n        (torch.Tensor): Predicted rotated bounding boxes, shape (bs, h*w, 4).\n    \"\"\"\n    lt, rb = pred_dist.split(2, dim=dim)\n    cos, sin = torch.cos(pred_angle), torch.sin(pred_angle)\n    # (bs, h*w, 1)\n    xf, yf = ((rb - lt) / 2).split(1, dim=dim)\n    x, y = xf * cos - yf * sin, xf * sin + yf * cos\n    xy = torch.cat([x, y], dim=dim) + anchor_points\n    return torch.cat([xy, lt + rb], dim=dim)\n"
        },
        {
          "label": "loss",
          "language": "python",
          "value": "class DFLoss(nn.Module):\n    \"\"\"Criterion class for computing DFL losses during training.\"\"\"\n\n    def __init__(self, reg_max=16) -> None:\n        \"\"\"Initialize the DFL module.\"\"\"\n        super().__init__()\n        self.reg_max = reg_max\n\n    def __call__(self, pred_dist, target):\n        \"\"\"\n        Return sum of left and right DFL losses.\n\n        Distribution Focal Loss (DFL) proposed in Generalized Focal Loss\n        https://ieeexplore.ieee.org/document/9792391\n        \"\"\"\n        target = target.clamp_(0, self.reg_max - 1 - 0.01)\n        tl = target.long()  # target left\n        tr = tl + 1  # target right\n        wl = tr - target  # weight left\n        wr = 1 - wl  # weight right\n        return (\n            F.cross_entropy(pred_dist, tl.view(-1), reduction=\"none\").view(tl.shape) * wl\n            + F.cross_entropy(pred_dist, tr.view(-1), reduction=\"none\").view(tl.shape) * wr\n        ).mean(-1, keepdim=True)\n\n\nclass BboxLoss(nn.Module):\n    \"\"\"Criterion class for computing training losses during training.\"\"\"\n\n    def __init__(self, reg_max=16):\n        \"\"\"Initialize the BboxLoss module with regularization maximum and DFL settings.\"\"\"\n        super().__init__()\n        self.dfl_loss = DFLoss(reg_max) if reg_max > 1 else None\n\n    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):\n        \"\"\"IoU loss.\"\"\"\n        weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)\n        iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)\n        loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum\n\n        # DFL loss\n        if self.dfl_loss:\n            target_ltrb = bbox2dist(anchor_points, target_bboxes, self.dfl_loss.reg_max - 1)\n            loss_dfl = self.dfl_loss(pred_dist[fg_mask].view(-1, self.dfl_loss.reg_max), target_ltrb[fg_mask]) * weight\n            loss_dfl = loss_dfl.sum() / target_scores_sum\n        else:\n            loss_dfl = torch.tensor(0.0).to(pred_dist.device)\n\n        return loss_iou, loss_dfl\n\nclass v8DetectionLoss:\n    \"\"\"Criterion class for computing training losses.\"\"\"\n\n    def __init__(self, model, tal_topk=10):  # model must be de-paralleled\n        \"\"\"Initializes v8DetectionLoss with the model, defining model-related properties and BCE loss function.\"\"\"\n        device = next(model.parameters()).device  # get model device\n        h = model.args  # hyperparameters\n\n        m = model.model[-1]  # Detect() module\n        self.bce = nn.BCEWithLogitsLoss(reduction=\"none\")\n        self.hyp = h\n        self.stride = m.stride  # model strides\n        self.nc = m.nc  # number of classes\n        self.no = m.nc + m.reg_max * 4\n        self.reg_max = m.reg_max\n        self.device = device\n\n        self.use_dfl = m.reg_max > 1\n\n        self.assigner = TaskAlignedAssigner(topk=tal_topk, num_classes=self.nc, alpha=0.5, beta=6.0)\n        self.bbox_loss = BboxLoss(m.reg_max).to(device)\n        # 生成 0 到 reg_max-1（reg_max 取值 16）的整数列表，详见“如何表示偏移量”章节\n        self.proj = torch.arange(m.reg_max, dtype=torch.float, device=device)\n\n    def preprocess(self, targets, batch_size, scale_tensor):\n        \"\"\"Preprocesses the target counts and matches with the input batch size to output a tensor.\"\"\"\n        nl, ne = targets.shape\n        if nl == 0:\n            out = torch.zeros(batch_size, 0, ne - 1, device=self.device)\n        else:\n            i = targets[:, 0]  # image index\n            _, counts = i.unique(return_counts=True)\n            counts = counts.to(dtype=torch.int32)\n            out = torch.zeros(batch_size, counts.max(), ne - 1, device=self.device)\n            for j in range(batch_size):\n                matches = i == j\n                n = matches.sum()\n                if n:\n                    out[j, :n] = targets[matches, 1:]\n            out[..., 1:5] = xywh2xyxy(out[..., 1:5].mul_(scale_tensor))\n        return out\n\n    def bbox_decode(self, anchor_points, pred_dist):\n        \"\"\"Decode predicted object bounding box coordinates from anchor points and distribution.\"\"\"\n        if self.use_dfl: # 不使用偏移量的绝对值，而是用一般分布表示。\n            b, a, c = pred_dist.shape  # batch, anchors, channels\n            # 对最后一维（reg_max）做 softmax 转换成映射表 [0，15] 中每个整数的概率，再乘以映射表，得到均值，作为该锚点的某个偏移量的预估值。\n            # pred_dist 变为 shape（batch, anchors, 4)\n            pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n            # pred_dist = pred_dist.view(b, a, c // 4, 4).transpose(2,3).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n            # pred_dist = (pred_dist.view(b, a, c // 4, 4).softmax(2) * self.proj.type(pred_dist.dtype).view(1, 1, -1, 1)).sum(2)\n        return dist2bbox(pred_dist, anchor_points, xywh=False)\n\n    def __call__(self, preds, batch):\n        \"\"\"Calculate the sum of the loss for box, cls and dfl multiplied by batch size.\n        batch 为训练批次 dict（待确认），其中包括 GT 的 batch_idx, cls，bboxes 等属性\"\"\"\n        loss = torch.zeros(3, device=self.device)  # box, cls, dfl\n\n        # # Detect 推理时返回(y,x)，训练时返回 x，故这里根据返回类型提取特征。\n        # feats 为模型预测值，对于 Detect 任务，head.py 中 Detect 的输出为(x0,x1,x2)，x[0]的shape(N, reg_max*4+nc , H, W)\n        feats = preds[1] if isinstance(preds, tuple) else preds\n\n        # pred_distri 的形状为（N, reg_max*4, 锚点数为3个h*w的和）\n        # pred_scores 的形状为（N, nc, 锚点数为3个h*w的和）\n        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(\n            (self.reg_max * 4, self.nc), 1\n        )\n\n        # nn.Conv2d的维度是（N, C, H, W），为了后续方便基于锚点处理，这里维度顺序改变：\n        # pred_scores 的形状变为（N, 锚点数为3个h*w的和，nc）\n        # pred_distri 的形状变为（N, 锚点数为3个h*w的和，reg_max*4）\n        pred_scores = pred_scores.permute(0, 2, 1).contiguous()\n        pred_distri = pred_distri.permute(0, 2, 1).contiguous()\n\n        dtype = pred_scores.dtype\n        batch_size = pred_scores.shape[0]\n        imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)\n        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)\n\n        # Targets\n        targets = torch.cat((batch[\"batch_idx\"].view(-1, 1), batch[\"cls\"].view(-1, 1), batch[\"bboxes\"]), 1)\n        targets = self.preprocess(targets.to(self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n        gt_labels, gt_bboxes = targets.split((1, 4), 2)  # cls, xyxy\n        mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0.0)\n\n        # Pboxes\n        pred_bboxes = self.bbox_decode(anchor_points, pred_distri)  # xyxy, (b, h*w, 4)\n        # dfl_conf = pred_distri.view(batch_size, -1, 4, self.reg_max).detach().softmax(-1)\n        # dfl_conf = (dfl_conf.amax(-1).mean(-1) + dfl_conf.amax(-1).amin(-1)) / 2\n\n        _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n            # pred_scores.detach().sigmoid() * 0.8 + dfl_conf.unsqueeze(-1) * 0.2,\n            pred_scores.detach().sigmoid(),\n            (pred_bboxes.detach() * stride_tensor).type(gt_bboxes.dtype),\n            anchor_points * stride_tensor,\n            gt_labels,\n            gt_bboxes,\n            mask_gt,\n        )\n\n        target_scores_sum = max(target_scores.sum(), 1)\n\n        # Cls loss\n        # loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\n        loss[1] = self.bce(pred_scores, target_scores.to(dtype)).sum() / target_scores_sum  # BCE\n\n        # Bbox loss\n        if fg_mask.sum():\n            target_bboxes /= stride_tensor\n            loss[0], loss[2] = self.bbox_loss(\n                pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask\n            )\n\n        loss[0] *= self.hyp.box  # box gain\n        loss[1] *= self.hyp.cls  # cls gain\n        loss[2] *= self.hyp.dfl  # dfl gain\n\n        return loss.sum() * batch_size, loss.detach()  # loss(box, cls, dfl)"
        }
      ],
      "id": "jpwj_tIA",
      "createdAt": 1731240053320,
      "updatedAt": 1731244638136
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "未命名程式碼片段",
      "content": [
        {
          "label": "子片段 1",
          "language": "python",
          "value": "在 iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True) 中，fg_mask 确保了 pred_bboxes 和 target_bboxes 中的前景样本是一一对应的。这种对应关系是通过 正样本分配过程 (positive sample assignment) 实现的。我们可以详细来看：\n\n正样本分配过程：在 v8DetectionLoss 中，self.assigner 负责将预测框（pred_bboxes）与真实目标框（target_bboxes）进行匹配。这个过程包括计算预测框与真实框的匹配度（例如 IoU），并将较高匹配度的框标记为正样本（即前景）。self.assigner 会输出一些信息，包括匹配的 target_bboxes 和一个前景掩码 fg_mask，表示哪些预测框被分配到了正样本。\n\n生成前景掩码 fg_mask：fg_mask 是一个布尔掩码，标记了哪些预测框被分配为前景（正样本）。因此，fg_mask 适用于 pred_bboxes，只选择那些被分配为正样本的预测框。\n\n对应的 target_bboxes：在 self.assigner 的匹配过程中，真实框 target_bboxes 会被调整成与前景预测框相对应的顺序。也就是说，target_bboxes[fg_mask] 中的每个框都与 pred_bboxes[fg_mask] 中的框一一对应。这种一一对应是由 self.assigner 处理的，它确保了 target_bboxes 中的正样本和 pred_bboxes 中的正样本具有相同的索引。\n\n最终效果：当 iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True) 执行时，pred_bboxes[fg_mask] 和 target_bboxes[fg_mask] 包含了相同数量的框，并且这些框是一一对应的，因为正样本分配过程确保了这种对应关系。\n\n总结\nfg_mask 是在正样本分配时生成的，用于选择 pred_bboxes 和 target_bboxes 中相对应的正样本框。这样，pred_bboxes[fg_mask] 和 target_bboxes[fg_mask] 是一一对应的，从而可以直接计算它们之间的 IoU 损失。"
        }
      ],
      "id": "yQA1XUnQ",
      "createdAt": 1731243915456,
      "updatedAt": 1731243921155
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PoO2O3Rm",
      "tagsIds": [],
      "description": null,
      "name": "list stream map",
      "content": [
        {
          "label": "Fragment 1",
          "language": "java",
          "value": "public class EmployeeController {\n    @GetMapping(\"/employees\")\n    public Result getEmployees() {\n        List<Employee> employees = employeeService.getEmployees();\n        List<EmployeeVO> employeeVOs = employees.stream().map(employee -> {\n            EmployeeVO employeeVO = new EmployeeVO();\n            BeanUtils.copyProperties(employee, employeeVO);\n            return employeeVO;\n        }).collect(Collectors.toList());\n        return  Result.ok(employeeVOs);\n    }\n}"
        }
      ],
      "id": "CfowZH8X",
      "createdAt": 1736654638267,
      "updatedAt": 1736654661349
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mdpwqphi",
      "tagsIds": [],
      "description": null,
      "name": "auto timestamp",
      "content": [
        {
          "label": "insert auto time",
          "language": "mysql",
          "value": "CREATE TABLE `login` (\n    `id` int(11) NOT NULL AUTO_INCREMENT,\n    `username` varchar(255) NOT NULL,\n    `time` datetime DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (`id`)\n)"
        },
        {
          "label": "update auto time",
          "language": "mysql",
          "value": "CREATE TABLE `login` (\n    `id` int(11) NOT NULL AUTO_INCREMENT,\n    `username` varchar(255) NOT NULL,\n    `time` datetime DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\n    PRIMARY KEY (`id`)\n);\n"
        }
      ],
      "id": "EaRZhy-_",
      "createdAt": 1736825270694,
      "updatedAt": 1736825596084
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mdpwqphi",
      "tagsIds": [],
      "description": null,
      "name": "join",
      "content": [
        {
          "label": "Fragment 1",
          "language": "plain_text",
          "value": "INNER JOIN: 返回两个表中满足连接条件的所有行。\n\nLEFT JOIN: 返回左表中的所有行，以及右表中满足连接条件的行。如果右表中没有匹配的行，则右表的列将为 NULL。\n\nRIGHT JOIN: 返回右表中的所有行，以及左表中满足连接条件的行。如果左表中没有匹配的行，则左表的列将为 NULL。\n\nFULL JOIN: 返回两个表中的所有行，如果某个表中没有匹配的行，则该表的列将为 NULL。\n\nCROSS JOIN: 返回两个表的笛卡尔积，不需要指定连接条件。\n\nSELF JOIN: 一个表与自身进行连接，通常用于查找表中具有相同列值的行。\n"
        },
        {
          "label": "example",
          "language": "mysql",
          "value": "-- find all order by user including order_items with goods' name\nselect o.id as order_id, o.user_id, o.order_date, u.email, oi.good_name, oi.quantity, oi.price\nfrom `order` o\n         join `user` u on o.user_id = u.id\n         left join (select oi.order_id as order_id, oi.quantity as quantity, oi.price as price, g.name as good_name\n                    from `order_item` oi\n                             join `goods` g on oi.goods_id = g.id) as `oi` on oi.order_id = o.id;"
        },
        {
          "label": "INNER JOIN",
          "language": "mysql",
          "value": "-- INNER JOIN\n-- 定义: 返回两个表中满足连接条件的所有行。\n-- 行为: 只有当两个表中存在匹配的行时，才会返回这些行。\n-- 结果: 如果某个表中没有匹配的行，则该行不会出现在结果集中。\n\nSELECT \n    o.id AS order_id,\n    o.user_id,\n    o.order_date,\n    u.email AS email_address,\n    'personal' AS email_type,\n    oi.id AS order_item_id,\n    oi.goods_id,\n    oi.quantity,\n    oi.price\nFROM `order` o\nINNER JOIN user u ON o.user_id = u.id\nINNER JOIN order_item oi ON o.id = oi.order_id;\n"
        },
        {
          "label": "LEFT JOIN",
          "language": "mysql",
          "value": "-- LEFT JOIN (或 LEFT OUTER JOIN)\n-- 定义: 返回左表中的所有行，以及右表中满足连接条件的行。如果右表中没有匹配的行，则结果集中右表的列将包含 NULL 值。\n-- 行为: 即使右表中没有匹配的行，左表中的所有行仍然会出现在结果集中。\n-- 结果: 如果某个表中没有匹配的行，则该表的列将为 NULL。\n\nSELECT \n    o.id AS order_id,\n    o.user_id,\n    o.order_date,\n    u.email AS email_address,\n    'personal' AS email_type,\n    oi.id AS order_item_id,\n    oi.goods_id,\n    oi.quantity,\n    oi.price\nFROM `order` o\nLEFT JOIN user u ON o.user_id = u.id\nLEFT JOIN order_item oi ON o.id = oi.order_id;\n"
        },
        {
          "label": "RIGHT JOIN ",
          "language": "mysql",
          "value": "-- RIGHT JOIN (或 RIGHT OUTER JOIN)\n-- 定义: 返回右表中的所有行，以及左表中满足连接条件的行。如果左表中没有匹配的行，则结果集中左表的列将包含 NULL 值。\n-- 行为: 即使左表中没有匹配的行，右表中的所有行仍然会出现在结果集中。\n-- 结果: 如果某个表中没有匹配的行，则该表的列将为 NULL。\n\nSELECT \n    o.id AS order_id,\n    o.user_id,\n    o.order_date,\n    u.email AS email_address,\n    'personal' AS email_type,\n    oi.id AS order_item_id,\n    oi.goods_id,\n    oi.quantity,\n    oi.price\nFROM `order` o\nRIGHT JOIN user u ON o.user_id = u.id\nRIGHT JOIN order_item oi ON o.id = oi.order_id;\n"
        },
        {
          "label": "FULL JOIN",
          "language": "mysql",
          "value": "-- FULL JOIN (或 FULL OUTER JOIN)\n-- 定义: 返回两个表中的所有行，如果某个表中没有匹配的行，则结果集中该表的列将包含 NULL 值。\n-- 行为: 即使某个表中没有匹配的行，两个表中的所有行仍然会出现在结果集中。\n-- 结果: 如果某个表中没有匹配的行，则该表的列将为 NULL。\n\nSELECT \n    o.id AS order_id,\n    o.user_id,\n    o.order_date,\n    u.email AS email_address,\n    'personal' AS email_type,\n    oi.id AS order_item_id,\n    oi.goods_id,\n    oi.quantity,\n    oi.price\nFROM `order` o\nFULL JOIN user u ON o.user_id = u.id\nFULL JOIN order_item oi ON o.id = oi.order_id;\n"
        },
        {
          "label": "CROSS JOIN",
          "language": "mysql",
          "value": "-- CROSS JOIN\n-- 定义: 返回两个表的笛卡尔积，即左表中的每一行与右表中的每一行组合。\n-- 行为: 不需要指定连接条件。\n-- 结果: 结果集的大小是左表和右表大小的乘积。\n\nSELECT \n    o.id AS order_id,\n    o.user_id,\n    o.order_date,\n    u.email AS email_address,\n    'personal' AS email_type\nFROM `order` o\nCROSS JOIN user u;\n"
        },
        {
          "label": "SELF JOIN",
          "language": "mysql",
          "value": "-- SELF JOIN\n-- 定义: 一个表与自身进行连接。\n-- 行为: 通常用于查找表中具有相同列值的行。\n-- 结果: 返回表中满足连接条件的行。\n\nSELECT \n    e1.id AS employee_id,\n    e1.name AS employee_name,\n    e2.id AS manager_id,\n    e2.name AS manager_name\nFROM employee e1\nLEFT JOIN employee e2 ON e1.manager_id = e2.id;\n"
        }
      ],
      "id": "BlIH7Jdw",
      "createdAt": 1737171571568,
      "updatedAt": 1737172349667
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mgv1LCgf",
      "tagsIds": [],
      "description": null,
      "name": "morphology",
      "content": [
        {
          "label": "sumary",
          "language": "plain_text",
          "value": "OpenCV形态学方法介绍\n\n1. 腐蚀 (Erosion)\n  作用: 侵蚀图像中的白色区域，减少白色区域的大小。\n  应用场景: 去除小的噪声点、断开相连的对象。\n2. 膨胀 (Dilation)\n  作用: 膨胀图像中的白色区域，增加白色区域的大小。\n  应用场景: 填充对象中的小孔、连接相邻的对象。\n3. 开运算 (Opening)\n  作用: 先腐蚀后膨胀，用于去除小的物体和噪声。\n  应用场景: 清除图像中的小颗粒噪声。\n4. 闭运算 (Closing)\n  作用: 先膨胀后腐蚀，用于填充对象内部的小孔。\n  应用场景: 修复对象内部的小孔或裂痕。\n5. 梯度 (Morphological Gradient)\n  作用: 计算膨胀后的图像与腐蚀后的图像之间的差异。\n  应用场景: 边缘检测。\n6. 顶帽 (Top Hat)\n  作用: 原始图像减去开运算的结果。\n  应用场景: 提取比背景亮的细节。\n7. 黑帽 (Black Hat)\n  作用: 闭运算的结果减去原始图像。\n  应用场景: 提取比背景暗的细节。\n\n\n实际应用场景实例\n\n1. 文本识别前预处理\n\t使用开运算去除文本图像中的噪声，使OCR（光学字符识别）更准确。\n2. 医学图像处理\n\t使用闭运算修复CT扫描图像中血管的断裂部分，便于后续分析。\n3. 工业缺陷检测\n\t使用梯度检测金属表面的划痕或裂纹，确保产品质量。\n4. 车牌识别\n\t使用腐蚀和膨胀分离车牌字符，提高字符分割的准确性。"
        },
        {
          "label": "腐蚀 (Erosion)",
          "language": "python",
          "value": "# 腐蚀操作\n# 作用: 侵蚀图像中的白色区域，减少白色区域的大小。\n# 应用场景: 去除小的噪声点、断开相连的对象。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimg = cv2.imread('input_image.jpg', 0)\n\n# 定义结构元素\nkernel = np.ones((5, 5), np.uint8)\n\nerosion = cv2.erode(img, kernel, iterations=1)\n\n# 显示结果\ncv2.imshow('Original Image', img)\ncv2.imshow('Eroded Image', erosion)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "膨胀 (Dilation)",
          "language": "python",
          "value": "# 膨胀操作\n# 作用: 膨胀图像中的白色区域，增加白色区域的大小。\n# 应用场景: 填充对象中的小孔、连接相邻的对象。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimg = cv2.imread('input_image.jpg', 0)\n\n# 定义结构元素\nkernel = np.ones((5, 5), np.uint8)\n\ndilation = cv2.dilate(img, kernel, iterations=1)\n\n# 显示结果\ncv2.imshow('Original Image', img)\ncv2.imshow('Dilated Image', dilation)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "开运算 (Opening)",
          "language": "python",
          "value": "# 开运算\n# 作用: 先腐蚀后膨胀，用于去除小的物体和噪声。\n# 应用场景: 清除图像中的小颗粒噪声。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimg = cv2.imread('input_image.jpg', 0)\n\n# 定义结构元素\nkernel = np.ones((5, 5), np.uint8)\n\nopening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n\n# 显示结果\ncv2.imshow('Original Image', img)\ncv2.imshow('Opened Image', opening)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "闭运算 (Closing)",
          "language": "python",
          "value": "# 闭运算\n# 作用: 先膨胀后腐蚀，用于填充对象内部的小孔。\n# 应用场景: 修复对象内部的小孔或裂痕。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimg = cv2.imread('input_image.jpg', 0)\n\n# 定义结构元素\nkernel = np.ones((5, 5), np.uint8)\n\nclosing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n\n# 显示结果\ncv2.imshow('Original Image', img)\ncv2.imshow('Closed Image', closing)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "梯度 (Morphological Gradient)",
          "language": "python",
          "value": "# 梯度\n# 作用: 计算膨胀后的图像与腐蚀后的图像之间的差异。\n# 应用场景: 边缘检测。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimg = cv2.imread('input_image.jpg', 0)\n\n# 定义结构元素\nkernel = np.ones((5, 5), np.uint8)\n\ngradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n\n# 显示结果\ncv2.imshow('Original Image', img)\ncv2.imshow('Gradient Image', gradient)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "顶帽 (Top Hat)",
          "language": "python",
          "value": "# 顶帽\n# 作用: 原始图像减去开运算的结果。\n# 应用场景: 提取比背景亮的细节。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimg = cv2.imread('input_image.jpg', 0)\n\n# 定义结构元素\nkernel = np.ones((5, 5), np.uint8)\n\ntophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n\n# 显示结果\ncv2.imshow('Original Image', img)\ncv2.imshow('Top Hat Image', tophat)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "黑帽 (Black Hat)",
          "language": "python",
          "value": "# 黑帽\n# 作用: 闭运算的结果减去原始图像。\n# 应用场景: 提取比背景暗的细节。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimg = cv2.imread('input_image.jpg', 0)\n\n# 定义结构元素\nkernel = np.ones((5, 5), np.uint8)\n\nblackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n\n# 显示结果\ncv2.imshow('Original Image', img)\ncv2.imshow('Black Hat Image', blackhat)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        }
      ],
      "id": "Vlxg3TwD",
      "createdAt": 1737197469536,
      "updatedAt": 1737197922147
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mgv1LCgf",
      "tagsIds": [],
      "description": null,
      "name": "License Plate Recognition (LPR)",
      "content": [
        {
          "label": "1. 图像预处理",
          "language": "python",
          "value": "# 首先，我们需要对输入图像进行预处理，包括灰度化、去噪和平滑处理。\nimport cv2\nimport numpy as np\n\n# 读取图像\nimage = cv2.imread('car.jpg')\n\n# 转换为灰度图像\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n# 高斯模糊去噪\nblurred = cv2.GaussianBlur(gray, (5, 5), 0)\n\n# 显示预处理后的图像\ncv2.imshow('Blurred Image', blurred)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "2. 边缘检测",
          "language": "python",
          "value": "# 使用Canny边缘检测器来检测图像中的边缘。\n# Canny边缘检测\nedges = cv2.Canny(blurred, 50, 150)\n\n# 显示边缘检测结果\ncv2.imshow('Edges', edges)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "3. 形态学操作",
          "language": "python",
          "value": "# 3 膨胀操作\n# 膨胀操作可以增强车牌区域的边缘，使其更加明显。\n# 定义结构元素\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 1))\n\n# 膨胀操作\ndilation = cv2.dilate(edges, kernel, iterations=3)\n\n# 显示膨胀后的图像\ncv2.imshow('Dilated Image', dilation)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n"
        },
        {
          "label": "4. 查找轮廓",
          "language": "python",
          "value": "# 使用cv2.findContours函数查找图像中的轮廓，并筛选出可能的车牌区域。\n# 查找轮廓\ncontours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n# 筛选出可能的车牌区域\nplate_contours = []\nfor contour in contours:\n    # 计算轮廓的边界框\n    x, y, w, h = cv2.boundingRect(contour)\n    \n    # 根据宽高比筛选出可能的车牌区域\n    aspect_ratio = w / float(h)\n    if 2.5 <= aspect_ratio <= 5.5:\n        plate_contours.append(contour)\n\n# 绘制可能的车牌区域\nplate_image = image.copy()\ncv2.drawContours(plate_image, plate_contours, -1, (0, 255, 0), 2)\n\n# 显示可能的车牌区域\ncv2.imshow('Possible License Plates', plate_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "5. 提取车牌区域",
          "language": "python",
          "value": "# 从筛选出的轮廓中提取车牌区域，并进一步处理。\n# 提取车牌区域\nif len(plate_contours) > 0:\n    # 假设第一个轮廓是最可能的车牌区域\n    x, y, w, h = cv2.boundingRect(plate_contours[0])\n    plate_region = image[y:y+h, x:x+w]\n    \n    # 显示车牌区域\n    cv2.imshow('License Plate Region', plate_region)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\nelse:\n    print(\"No license plate found.\")"
        },
        {
          "label": "6. 车牌字符分割与识别",
          "language": "python",
          "value": "# 在提取出车牌区域后，可以进一步使用字符分割和字符识别技术来识别车牌上的字符。这里我们仅展示如何使用形态学操作来处理车牌区域。\n# 将车牌区域转换为灰度图像\nplate_gray = cv2.cvtColor(plate_region, cv2.COLOR_BGR2GRAY)\n\n# 二值化处理\n_, plate_binary = cv2.threshold(plate_gray, 150, 255, cv2.THRESH_BINARY_INV)\n\n# 显示二值化后的车牌图像\ncv2.imshow('Binary Plate Image', plate_binary)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n\n# 查找车牌中的字符轮廓\nchar_contours, _ = cv2.findContours(plate_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n# 筛选出可能的字符轮廓\nchar_contours = sorted(char_contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n\n# 绘制字符轮廓\nchar_image = plate_region.copy()\nfor contour in char_contours:\n    x, y, w, h = cv2.boundingRect(contour)\n    if w > 10 and h > 20:  # 过滤掉过小的轮廓\n        cv2.rectangle(char_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n\n# 显示字符轮廓\ncv2.imshow('Characters in License Plate', char_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        },
        {
          "label": "7. OCR",
          "language": "python",
          "value": "# 使用字符识别模型（如Tesseract OCR）来识别分割出的字符。\n# pip install pytesseract\n# 遍历分割出的字符轮廓，提取每个字符并进行识别。\n\nimport pytesseract\n\n# 初始化Tesseract\npytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # 根据你的安装路径修改\n\n# 存储识别结果\nrecognized_chars = []\n\n# 遍历字符轮廓\nfor contour in char_contours:\n    x, y, w, h = cv2.boundingRect(contour)\n    if w > 10 and h > 20:  # 过滤掉过小的轮廓\n        # 提取字符区域\n        char_image = plate_binary[y:y+h, x:x+w]\n        \n        # 识别字符\n        char = pytesseract.image_to_string(char_image, config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n        recognized_chars.append(char.strip())\n\n# 显示识别结果\nprint(\"Recognized Characters:\", ''.join(recognized_chars))\n\n# 输出识别结果\nrecognized_plate = ''.join(recognized_chars)\nprint(\"Recognized License Plate:\", recognized_plate)\n\n# 保存识别结果到文件\nwith open('recognized_plate.txt', 'w') as file:\n    file.write(recognized_plate)\n"
        },
        {
          "label": "Full Example",
          "language": "python",
          "value": "import cv2\nimport numpy as np\nimport pytesseract\n\n# 读取图像\nimage = cv2.imread('car.jpg')\n\n# 转换为灰度图像\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n# 高斯模糊去噪\nblurred = cv2.GaussianBlur(gray, (5, 5), 0)\n\n# Canny边缘检测\nedges = cv2.Canny(blurred, 50, 150)\n\n# 定义结构元素\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 1))\n\n# 膨胀操作\ndilation = cv2.dilate(edges, kernel, iterations=3)\n\n# 查找轮廓\ncontours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n# 筛选出可能的车牌区域\nplate_contours = []\nfor contour in contours:\n    x, y, w, h = cv2.boundingRect(contour)\n    aspect_ratio = w / float(h)\n    if 2.5 <= aspect_ratio <= 5.5:\n        plate_contours.append(contour)\n\n# 提取车牌区域\nif len(plate_contours) > 0:\n    x, y, w, h = cv2.boundingRect(plate_contours[0])\n    plate_region = image[y:y+h, x:x+w]\nelse:\n    print(\"No license plate found.\")\n    exit()\n\n# 将车牌区域转换为灰度图像\nplate_gray = cv2.cvtColor(plate_region, cv2.COLOR_BGR2GRAY)\n\n# 二值化处理\n_, plate_binary = cv2.threshold(plate_gray, 150, 255, cv2.THRESH_BINARY_INV)\n\n# 定义结构元素\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n\n# 膨胀操作\ndilation = cv2.dilate(plate_binary, kernel, iterations=1)\n\n# 查找字符轮廓\nchar_contours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n# 筛选出可能的字符轮廓\nchar_contours = sorted(char_contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n\n# 初始化Tesseract\npytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # 根据你的安装路径修改\n\n# 存储识别结果\nrecognized_chars = []\n\n# 遍历字符轮廓\nfor contour in char_contours:\n    x, y, w, h = cv2.boundingRect(contour)\n    if w > 10 and h > 20:  # 过滤掉过小的轮廓\n        # 提取字符区域\n        char_image = plate_binary[y:y+h, x:x+w]\n        \n        # 识别字符\n        char = pytesseract.image_to_string(char_image, config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n        recognized_chars.append(char.strip())\n\n# 输出识别结果\nrecognized_plate = ''.join(recognized_chars)\nprint(\"Recognized License Plate:\", recognized_plate)\n\n# 保存识别结果到文件\nwith open('recognized_plate.txt', 'w') as file:\n    file.write(recognized_plate)\n\n# 显示结果\ncv2.imshow('Original Image', image)\ncv2.imshow('License Plate Region', plate_region)\ncv2.imshow('Binary Plate Image', plate_binary)\ncv2.imshow('Dilated Plate Image', dilation)\ncv2.imshow('Characters in License Plate', char_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
        }
      ],
      "id": "5_P2lwzo",
      "createdAt": 1737198007215,
      "updatedAt": 1737198380503
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "mgv1LCgf",
      "tagsIds": [],
      "description": null,
      "name": "",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": ""
        }
      ],
      "id": "e_mKRscV",
      "createdAt": 1737212095408,
      "updatedAt": 1737212108722
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mgv1LCgf",
      "tagsIds": [],
      "description": null,
      "name": "pdf handling",
      "content": [
        {
          "label": "xg",
          "language": "python",
          "value": "import fitz  # PyMuPDF\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom copy import deepcopy\nfrom OCREngine import OCREngine\nimport traceback\n\n\nclass Word:\n    def __init__(self, meaning: str, kanji: str, hina: str = None):\n        self.meaning = meaning.strip() if meaning and isinstance(meaning, str) else \"\"\n        self.hina = hina.strip() if hina and isinstance(hina, str) else \"\"\n        self.kanji = kanji.strip() if kanji and isinstance(kanji, str) else \"\"\n\n    def __str__(self):\n        return f\"(meaning: {self.meaning}, kanji: {self.kanji}, hina: {self.hina})\"\n\n    def __repr__(self):\n        return self.__str__()\n\n\n# 第一步：将 PDF 转换为图片\ndef pdf_to_image(\n    pdf_path,\n    page=-1,\n    outDir=None,\n    dpi=300,\n):\n    pdf_document = fitz.open(pdf_path)\n    pageList = {}\n    namePattern = \"page_%0\" + str(np.ceil(np.log10(len(pdf_document)))) + \"d.png\"\n    if page <= 0:  # return all pages\n        for idx, page in enumerate(tqdm(pdf_document, desc=\"pdf process\", leave=False)):\n            pageList[idx] = page.get_pixmap(dpi=dpi)\n    else:\n        idx = page - 1\n        assert isinstance(page, int) and page < len(\n            pdf_document\n        ), f\"Invalid page number, specified page should between 1 and {len(pdf_document)}\"\n        page = pdf_document[idx]  # 获取第一页\n        pageList[idx] = page.get_pixmap(dpi=dpi)\n    if outDir is not None:\n        for idx, page in tqdm(pageList.items(), desc=\"save image file\", leave=False):\n            image_path = outDir / (namePattern % (idx + 1))\n            page.save(image_path)\n    return pageList\n\n\ndef extract_target_region(image, templates, maxWitdh=-1, cutKana=False):\n    \"\"\"\n    从图像中提取模板匹配后目标区域，右边界根据目标区域内的蓝色和黑色像素分隔。\n\n    参数:\n    - image_path: 目标图像的文件\n    - templates: 模板图像的文件\n\n    返回:\n    - 目标区域图像（裁剪后的图像）\n    \"\"\"\n    # 转为灰度图像\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    cropList = []\n\n    for template in tqdm(templates, desc=\"matching\", leave=False):\n\n        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n\n        # 执行模板匹配\n        result = cv2.matchTemplate(image_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n\n        # 获取匹配结果的最大值和位置\n        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n\n        # 获取模板的宽度和高度\n        template_height, template_width = template.shape[:2]\n\n        # 确定目标区域的左上角坐标\n        left, top = np.array(max_loc)\n        left += template_width\n        bottom = top + template_height\n        right = left + maxWitdh if maxWitdh > 0 else image.shape[1]\n\n        # 提取目标区域图像\n        target_region = image[top:bottom, left:right]\n\n        # 转换为HSV空间，便于分离颜色\n        hsv_region = cv2.cvtColor(target_region, cv2.COLOR_BGR2HSV)\n\n        # 设定目标区域内蓝色文字的颜色范围\n        lower_blue = np.array([90, 50, 100])  # 调整下限\n        upper_blue = np.array([130, 255, 255])  # 调整上限\n\n        # 创建蓝色的掩模\n        blue_mask = cv2.inRange(hsv_region, lower_blue, upper_blue)\n\n        # 创建黑色的掩模\n        lower_black = np.array([0, 0, 0])\n        upper_black = np.array([50, 50, 50])\n        black_mask = cv2.inRange(hsv_region, lower_black, upper_black)\n\n        # cv2.imwrite(\"blue.png\", blue_mask)\n        # cv2.imwrite(\"black.png\", black_mask)\n        # cv2.imwrite(\"target.png\", target_region)\n\n        # 查找左边最右的蓝色像素\n        leftmost_blue = None\n        for x in range(blue_mask.shape[1]):\n            if np.sum(blue_mask[:, x]) > 0:  # 如果该列包含蓝色\n                leftmost_blue = x\n\n        # 查找右边最左的黑色像素\n        rightmost_black = None\n        for x in range(blue_mask.shape[1]):  # 从右往左扫描\n            if np.sum(black_mask[:, x]) > 0:  # 如果该列包含黑色\n                rightmost_black = x\n                break\n\n        # 如果找到左边最右的蓝色像素和右边最左的黑色像素，计算中点作为右边界\n        if leftmost_blue is not None and rightmost_black is not None:\n            # 计算等距平分的位置\n            right_boundary = int((leftmost_blue + rightmost_black) / 2)\n\n            # 提取目标区域图片\n            cropped_image = target_region[:, :right_boundary]  # 裁剪到右边界\n\n            cropList.append(cropped_image)  # 返回裁剪后的目标区域图像\n        else:\n            # whole line is blue font\n            cropList.append(target_region)\n    return deepcopy(cropList)\n\n\ndef match_template(image, template):\n    result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n    _, max_val, _, max_loc = cv2.minMaxLoc(result)\n    if max_val > 0.8:\n        return max_loc\n    return None\n\n\ndef img_crop(image, left, top, right, bottom):\n    if left < 0:\n        left = 0\n    if top < 0:\n        top = 0\n    if right > image.shape[1]:\n        right = image.shape[1]\n    if bottom > image.shape[0]:\n        bottom = image.shape[0]\n    return deepcopy(image[top:bottom, left:right])\n\n\ndef getUnkownedName():\n    with unknownLock:\n        global unknownCount\n        name = unknownPattern % unknownCount\n        unknownCount += 1\n        return name\n\n\ndef box_ocr(img):\n    with zhEngineLock:\n        return zhEngine(img, det=True, rec=False, cls=False)[0]\n\n\ndef ja_ocr(img):\n    with jaEngineLock:\n        return jaEngine(img, det=False, rec=True, cls=False)[0]\n\n\ndef zh_ocr(img):\n    with zhEngineLock:\n        return zhEngine(img, det=False, rec=True, cls=False)[0]\n\n\ndef cht_ocr(img):\n    with chtEngineLock:\n        return chtEngine(img, det=False, rec=True, cls=False)[0]\n\n\ndef box_parse(box, start_y):\n    left, top, right, bottom = (\n        int(box[0][0]),\n        int(box[0][1]),\n        int(box[2][0]),\n        int(box[2][1]),\n    )\n    if top - bottom > 90:\n        bottom = top + 90\n    box_ = [(left, top), (right, bottom)]\n\n    txt_top = start_y + box_[0][1]\n    txt_bottom = start_y + box_[1][1]\n    l_txt_left = LREIGON_LEFT + box_[0][0]\n    l_txt_right = LREIGON_LEFT + box_[1][0] + 5\n    return txt_top, txt_bottom, l_txt_left, l_txt_right\n\n\ndef find_right_boundary(image):\n    \"\"\"Find the right boundary of black text on a white background.\n\n    Args:\n        image (np.ndarray): Input image.\n\n    Returns:\n        int: The x-coordinate of the right boundary of the black text.\n    \"\"\"\n    # 將圖像從 BGR 轉換到 HSV\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    # 定義黑色的 HSV 範圍\n    lower_black = np.array([0, 0, 0])\n    upper_black = np.array([180, 255, 50])\n\n    # 定義橘黃色的 HSV 範圍\n    lower_orange = np.array([10, 100, 100])\n    upper_orange = np.array([25, 255, 255])\n\n    # 創建黑色和橘黃色的掩碼\n    mask_black = cv2.inRange(hsv, lower_black, upper_black)\n    mask_orange = cv2.inRange(hsv, lower_orange, upper_orange)\n\n    # 合併掩碼\n    mask = cv2.bitwise_or(mask_black, mask_orange)\n\n    # 找到所有的非零點（黑色字體）\n    points = np.column_stack(np.where(mask > 0))\n\n    # 找到這些點的最大 x 值，即右邊界\n    right_boundary = points[:, 1].max()\n\n    # 找到這些點的最小 x 值，即左邊界\n    left_boundary = points[:, 1].min()\n\n    return left_boundary, right_boundary\n\n\ndef txtboxing(img):\n    try:\n        left, right = find_right_boundary(img)\n        left -= 5\n        right += 5\n        if left < 0:\n            left = 0\n        if right > img.shape[1]:\n            right = img.shape[1]\n        return img[:, left:right]\n    except Exception as e:\n        traceback.print_exc()\n        return img\n\n\ndef lineProcessor(lregion, mregion, rregion):\n\n    def txt_valid(txt, threshold=0.90):\n        if len(txt) > 1:\n            txt = [\n                \" \".join([(i[0]).strip() for i in txt]),\n                min([i[1] for i in txt]),\n            ]\n        return txt[0][0] if txt[0][1] > threshold else None\n\n    l_txt_region = txtboxing(lregion)\n    m_txt_region = txtboxing(mregion)\n    r_txt_region = txtboxing(rregion)\n\n    l_txt_cht = cht_ocr(l_txt_region)\n    l_txt_zh = zh_ocr(l_txt_region)\n    l_txt_ja = ja_ocr(l_txt_region)\n    l_txt = l_txt_cht\n    m_txt = ja_ocr(m_txt_region)\n    r_txt = ja_ocr(r_txt_region)\n\n    try:\n        l_txt = txt_valid(l_txt_cht)\n        if l_txt is None:\n            l_txt = txt_valid(l_txt_ja)\n        if l_txt is None:\n            l_txt = txt_valid(l_txt_zh)\n        m_txt = txt_valid(m_txt)\n        r_txt = txt_valid(r_txt)\n\n        assert l_txt is not None\n        assert m_txt is not None\n        assert r_txt is not None\n\n        wordList.append(Word(l_txt, m_txt, r_txt))\n\n    except Exception as e:\n        traceback.print_exc()\n        name = getUnkownedName()\n        # cv2.imwrite(OUTDIR / f\"{name}_l.png\", lregion)\n        # cv2.imwrite(OUTDIR / f\"{name}_m.png\", mregion)\n        # cv2.imwrite(OUTDIR / f\"{name}_r.png\", rregion)\n        cv2.imwrite(OUTDIR / f\"{name}_lt.png\", l_txt_region)\n        cv2.imwrite(OUTDIR / f\"{name}_mt.png\", m_txt_region)\n        cv2.imwrite(OUTDIR / f\"{name}_rt.png\", r_txt_region)\n\n\ndef extract_area(page):\n    img = cv2.imread(INDIR / page)\n    assert img is not None, f\"image {page} not found\"\n    header = match_template(img, headerTemplate)\n    divider = match_template(img, dividerTemplate)\n    kaiwa = match_template(img, kaiwaTemplate)\n    if divider is not None:\n        if header is None:\n            # divider front area\n            start_y = LREIGON_TOP\n            end_y = divider[1]\n            lregion_img = img_crop(img, LREIGON_LEFT, start_y, LREIGON_RIGHT, end_y)\n            cv2.imwrite(TMPDIR / \"lregine.png\", lregion_img)\n            boxes = box_ocr(lregion_img)\n            if boxes is None:\n                boxes = []\n            for box in boxes:\n                txt_top, txt_bottom, l_txt_left, l_txt_right = box_parse(box, start_y)\n                l_txt_region = img_crop(\n                    img, l_txt_left, txt_top, l_txt_right, txt_bottom\n                )\n                m_txt_region = img_crop(\n                    img, l_txt_right, txt_top, RREIGON_LEFT, txt_bottom\n                )\n                r_txt_region = img_crop(\n                    img, RREIGON_LEFT, txt_top, RREIGON_RIGHT, txt_bottom\n                )\n                lineProcessor(l_txt_region, m_txt_region, r_txt_region)\n\n        # divider bottom area\n        assert divider is not None, \"divider not found\"\n        # get y of start\n        start_y = divider[1] + dividerTemplate.shape[0] + 5\n        end_y = LREIGON_BOTTOM\n        lregion_img = img_crop(img, LREIGON_LEFT, start_y, LREIGON_RIGHT, end_y)\n        cv2.imwrite(TMPDIR / \"lregine.png\", lregion_img)\n        boxes = box_ocr(lregion_img)\n        for box in boxes:\n            txt_top, txt_bottom, l_txt_left, l_txt_right = box_parse(box, start_y)\n            l_txt_region = img_crop(img, l_txt_left, txt_top, l_txt_right, txt_bottom)\n            m_txt_region = img_crop(img, l_txt_right, txt_top, RREIGON_LEFT, txt_bottom)\n            r_txt_region = img_crop(\n                img, RREIGON_LEFT, txt_top, RREIGON_RIGHT, txt_bottom\n            )\n            lineProcessor(l_txt_region, m_txt_region, r_txt_region)\n\n    elif kaiwa is not None:\n        # ignore the bottom part of kaiwa\n        start_y = LREIGON_TOP\n        end_y = kaiwa[1]\n        lregion_img = img_crop(img, LREIGON_LEFT, start_y, LREIGON_RIGHT, end_y)\n        cv2.imwrite(TMPDIR / \"lregine.png\", lregion_img)\n        boxes = box_ocr(lregion_img)\n        for box in boxes:\n            txt_top, txt_bottom, l_txt_left, l_txt_right = box_parse(box, start_y)\n            l_txt_region = img_crop(img, l_txt_left, txt_top, l_txt_right, txt_bottom)\n            m_txt_region = img_crop(img, l_txt_right, txt_top, RREIGON_LEFT, txt_bottom)\n            r_txt_region = img_crop(\n                img, RREIGON_LEFT, txt_top, RREIGON_RIGHT, txt_bottom\n            )\n            lineProcessor(l_txt_region, m_txt_region, r_txt_region)\n    return page\n\n\nkanatukenugu = lambda area: area[-43:]\n\nif __name__ == \"__main__\":\n    import shutil\n    import os\n    import pickle\n    from multiprocessing import Lock\n    from multiprocessing.pool import ThreadPool\n\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\n    ROOT = Path(__file__).resolve().parent\n    TEMPLATEDIR = ROOT / \"xg_template\"\n    INDIR = ROOT / \"xg_in\"\n\n    TMPDIR = ROOT / \"xg_tmp\"\n    # delete file in TMPDIR\n    # shutil.rmtree(TMPDIR, ignore_errors=True)\n    TMPDIR.mkdir(exist_ok=True, parents=True)\n\n    OUTDIR = ROOT / \"xg_out\"\n    shutil.rmtree(OUTDIR, ignore_errors=True)\n    OUTDIR.mkdir(exist_ok=True, parents=True)\n\n    headerTemplate = cv2.imread(TEMPLATEDIR / \"header.png\")  # (167, 582)\n    dividerTemplate = cv2.imread(TEMPLATEDIR / \"divider.png\")  # (96, 59)\n    kaiwaTemplate = cv2.imread(TEMPLATEDIR / \"kaiwa.png\")  # (124, 217)\n\n    zhEngine = OCREngine(\"ch\")\n    zhEngineLock = Lock()\n    chtEngine = OCREngine(\"chinese_cht\")\n    chtEngineLock = Lock()\n    jaEngine = OCREngine(\"japan\")\n    jaEngineLock = Lock()\n    unknownPattern = \"unknown_%0.8d\"\n    unknownCount = 0\n    unknownLock = Lock()\n    wordList = []\n\n    # 158 261 365 1463(77*19)\n    LREIGON_LEFT = 158\n    LREIGON_TOP = 261\n    LREIGON_RIGHT = 158 + 365\n    LREIGON_BOTTOM = 261 + 1463\n    MREIGON_WIDTH = 458\n    RREIGON_LEFT = 980\n    RREIGON_RIGHT = 1390\n\n    # page = \"i-014.jpg\"  # header test\n    # page = \"i-016.jpg\"  # divider test\n    # page = \"i-017.jpg\" # kaiwa test\n    # extract_area(page)\n\n    with ThreadPool(6) as pool:\n        result = pool.imap(extract_area, os.listdir(INDIR))\n        loop = tqdm(\n            result, total=len(os.listdir(INDIR)), desc=\"processing\", leave=False\n        )\n        for _ in loop:\n            loop.set_postfix_str(f\"{_}\")\n\n\n    # use pickle to store wordList\n    with open(OUTDIR / \"data.pickle\", \"wb\") as f:\n        pickle.dump(wordList, f)\n\n    print(f\"处理完成，结果保存为：{TMPDIR}\")\n"
        },
        {
          "label": "xg_data",
          "language": "python",
          "value": "from xg import Word\nimport pickle\nfrom pathlib import Path\n\nif __name__ == \"__main__\":\n    ROOT = Path(__file__).parent\n    DATA_DIR = ROOT / \"xg_out\"\n    \n    with open(DATA_DIR / \"data.pickle\", \"rb\") as f:\n        word_list = pickle.load(f)\n    \n    wordtxt = DATA_DIR / \"words.txt\"\n    linePattern = \"%s,%s\\n\"\n    with wordtxt.open(\"w\") as f:\n        for word in word_list:\n            f.write(linePattern % (word.kanji, word.meaning))\n            f.write(linePattern % (word.hina, word.meaning))\n            \n        "
        },
        {
          "label": "OCREngine",
          "language": "python",
          "value": "from paddleocr import PaddleOCR\n\n\nclass OCREngine:\n    def __init__(self, lang=\"japan\"):\n        self.engine = PaddleOCR(lang=lang)\n\n    def __call__(\n        self,\n        *args,\n        det=False,\n        rec=True,\n        cls=False,\n        **kwds,\n    ):\n        return self.engine.ocr(\n            *args,\n            **kwds,\n            det=det,\n            rec=rec,\n            cls=cls,\n        )\n"
        },
        {
          "label": "cjs300",
          "language": "python",
          "value": "import fitz  # PyMuPDF\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom copy import deepcopy\nfrom OCREngine import OCREngine\n\n\n# 第一步：将 PDF 转换为图片\ndef pdf_to_image(\n    pdf_path,\n    page=-1,\n    outDir=None,\n    dpi=300,\n):\n    pdf_document = fitz.open(pdf_path)\n    pageList = {}\n    namePattern = \"page_%0\" + str(np.ceil(np.log10(len(pdf_document)))) + \"d.png\"\n    if page <= 0:  # return all pages\n        for idx, page in enumerate(tqdm(pdf_document, desc=\"pdf process\", leave=False)):\n            pageList[idx] = page.get_pixmap(dpi=dpi)\n    else:\n        idx = page - 1\n        assert isinstance(page, int) and page < len(\n            pdf_document\n        ), f\"Invalid page number, specified page should between 1 and {len(pdf_document)}\"\n        page = pdf_document[idx]  # 获取第一页\n        pageList[idx] = page.get_pixmap(dpi=dpi)\n    if outDir is not None:\n        for idx, page in tqdm(pageList.items(), desc=\"save image file\", leave=False):\n            image_path = outDir / (namePattern % (idx + 1))\n            page.save(image_path)\n    return pageList\n\n\ndef extract_target_region(image, templates, maxWitdh=-1, cutKana=False):\n    \"\"\"\n    从图像中提取模板匹配后目标区域，右边界根据目标区域内的蓝色和黑色像素分隔。\n\n    参数:\n    - image_path: 目标图像的文件\n    - templates: 模板图像的文件\n\n    返回:\n    - 目标区域图像（裁剪后的图像）\n    \"\"\"\n    # 转为灰度图像\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    cropList = []\n\n    for template in tqdm(templates, desc=\"matching\", leave=False):\n\n        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n\n        # 执行模板匹配\n        result = cv2.matchTemplate(image_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n\n        # 获取匹配结果的最大值和位置\n        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n\n        # 获取模板的宽度和高度\n        template_height, template_width = template.shape[:2]\n\n        # 确定目标区域的左上角坐标\n        left, top = np.array(max_loc)\n        left += template_width\n        bottom = top + template_height\n        right = left + maxWitdh if maxWitdh > 0 else image.shape[1]\n\n        # 提取目标区域图像\n        target_region = image[top:bottom, left:right]\n\n        # 转换为HSV空间，便于分离颜色\n        hsv_region = cv2.cvtColor(target_region, cv2.COLOR_BGR2HSV)\n\n        # 设定目标区域内蓝色文字的颜色范围\n        lower_blue = np.array([90, 50, 100])  # 调整下限\n        upper_blue = np.array([130, 255, 255])  # 调整上限\n\n        # 创建蓝色的掩模\n        blue_mask = cv2.inRange(hsv_region, lower_blue, upper_blue)\n\n        # 创建黑色的掩模\n        lower_black = np.array([0, 0, 0])\n        upper_black = np.array([50, 50, 50])\n        black_mask = cv2.inRange(hsv_region, lower_black, upper_black)\n\n        # cv2.imwrite(\"blue.png\", blue_mask)\n        # cv2.imwrite(\"black.png\", black_mask)\n        # cv2.imwrite(\"target.png\", target_region)\n\n        # 查找左边最右的蓝色像素\n        leftmost_blue = None\n        for x in range(blue_mask.shape[1]):\n            if np.sum(blue_mask[:, x]) > 0:  # 如果该列包含蓝色\n                leftmost_blue = x\n\n        # 查找右边最左的黑色像素\n        rightmost_black = None\n        for x in range(blue_mask.shape[1]):  # 从右往左扫描\n            if np.sum(black_mask[:, x]) > 0:  # 如果该列包含黑色\n                rightmost_black = x\n                break\n\n        # 如果找到左边最右的蓝色像素和右边最左的黑色像素，计算中点作为右边界\n        if leftmost_blue is not None and rightmost_black is not None:\n            # 计算等距平分的位置\n            right_boundary = int((leftmost_blue + rightmost_black) / 2)\n\n            # 提取目标区域图片\n            cropped_image = target_region[:, :right_boundary]  # 裁剪到右边界\n\n            cropList.append(cropped_image)  # 返回裁剪后的目标区域图像\n        else:\n            # whole line is blue font\n            cropList.append(target_region)\n    return deepcopy(cropList)\n\n\ndef match_template(image, template):\n    result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n    _, max_val, _, max_loc = cv2.minMaxLoc(result)\n    if max_val > 0.8:\n        return max_loc\n    return None\n\n\ndef get_area(image, left_top_template, right_top_template, bottom_template):\n    \"\"\"Summary\n    divide image into 3 areas: left_top, right_top, bottom by template matching;\n    left_top area is between left_top_template, width is the same as left_top_template;\n    right_top area is between right_top_template and upper border of bottom_template, width is the same as right_top_template;\n    bottom area is below lower border of bottom_template, width is the same as left_top_template;\n\n    Args:\n        image (_type_): image to be divided\n        left_top_template (_type_): left top template\n        right_top_template (_type_): right top template\n        bottom_template (_type_): bottom template\n\n    Returns:\n        list of 3 areas box (x, y, w, h)\n    \"\"\"\n\n    left_top_loc = match_template(image, left_top_template)\n    right_top_loc = match_template(image, right_top_template)\n    bottom_loc = match_template(image, bottom_template)\n\n    left_top_x, left_top_y = left_top_loc\n    right_top_x, right_top_y = right_top_loc\n    bottom_x, bottom_y = bottom_loc\n\n    left_top_w, left_top_h = left_top_template.shape[1], left_top_template.shape[0]\n    right_top_w, right_top_h = right_top_template.shape[1], right_top_template.shape[0]\n    bottom_w, bottom_h = bottom_template.shape[1], bottom_template.shape[0]\n\n    left_top_area = (\n        left_top_x,\n        left_top_y + left_top_h,\n        left_top_w,\n        bottom_y - (left_top_y + left_top_h),\n    )\n    right_top_area = (\n        right_top_x,\n        right_top_y + right_top_h,\n        right_top_w,\n        bottom_y - (right_top_y + right_top_h),\n    )\n    bottom_area = (\n        bottom_x,\n        bottom_y + bottom_h,\n        bottom_w,\n        image.shape[0] - (bottom_y + bottom_h) - 130,\n    )\n\n    # return [left_top_area, right_top_area, bottom_area]\n\n    left_top_img = image[\n        left_top_area[1] : left_top_area[1] + left_top_area[3],\n        left_top_area[0] : left_top_area[0] + left_top_area[2],\n    ]\n    right_top_img = image[\n        right_top_area[1] : right_top_area[1] + right_top_area[3],\n        right_top_area[0] : right_top_area[0] + right_top_area[2],\n    ]\n    bottom_img = image[\n        bottom_area[1] : bottom_area[1] + bottom_area[3],\n        bottom_area[0] : bottom_area[0] + bottom_area[2],\n    ]\n\n    return deepcopy([left_top_img, right_top_img, bottom_img])\n\n\nkanatukenugu = lambda area: area[-43:]\n\nif __name__ == \"__main__\":\n    import shutil\n\n    ROOT = Path(__file__).resolve().parent\n    TEMPLATEDIR = ROOT / \"cjs300_template\"\n    DPI = 300\n    pdf_path = ROOT / \"cjs300.pdf\"\n\n    TMPDIR = ROOT / \"cjs300_tmp\"\n    # delete file in TMPDIR\n    shutil.rmtree(TMPDIR, ignore_errors=True)\n    TMPDIR.mkdir(exist_ok=True, parents=True)\n\n    OUTDIR = ROOT / \"cjs300_out\"\n    shutil.rmtree(OUTDIR, ignore_errors=True)\n    OUTDIR.mkdir(exist_ok=True, parents=True)\n    \n\n    engine = OCREngine(\"japan\")\n    mainWordList = []\n    additionalWordList = []\n    WordList = []\n    notSureCount = 0\n    notSurePattern = \"ns_%016d.png\"\n    notSureCount_a = 0\n    notSurePattern_a = \"nsa_%016d.png\"\n\n    page = -1\n    image_path = pdf_to_image(\n        pdf_path, page=page, outDir=TMPDIR, dpi=DPI\n    )  # 将 PDF 转换为图片\n\n    # 加载模板\n    wordTemplates = []\n    templateNamePattern = \"order_%d.png\"\n\n    for i in tqdm(range(1, 16), desc=\"load template\", leave=False):\n        wordTemplates.append(\n            cv2.imread(TEMPLATEDIR / (templateNamePattern % i))\n        )  # 模板图像\n\n    # 加载图像 -> ocr\n    imgSuffix = [\".png\", \".jpg\", \".jpeg\", \".bmp\"]\n    for img in tqdm(list(TMPDIR.iterdir()), desc=\"ocr\", leave=True):\n        if img.suffix.lower() not in imgSuffix:\n            continue\n        image = cv2.imread(img)  # 目标图像\n\n        left_top_template = cv2.imread(TEMPLATEDIR / \"word.png\")\n        right_top_template = cv2.imread(TEMPLATEDIR / \"conver.png\")\n        bottom_template = cv2.imread(TEMPLATEDIR / \"addon.png\")\n\n        [left_top_img, right_top_img, bottom_img] = get_area(\n            image, left_top_template, right_top_template, bottom_template\n        )\n\n        try:\n            wordAreas = extract_target_region(\n                left_top_img,\n                wordTemplates,\n                cutKana=False,\n            )\n            wordAreas = [kanatukenugu(i) for i in wordAreas]\n            results = engine(wordAreas)[0]\n            for idx, (result, score) in enumerate(results):\n                if score < 0.8:\n                    area = cv2.cvtColor(wordAreas[idx], cv2.COLOR_BGR2GRAY)\n                    _, area = cv2.threshold(area, 200, 255, cv2.THRESH_BINARY)\n                    area = cv2.cvtColor(area, cv2.COLOR_GRAY2BGR)\n\n                    cv2.imwrite(OUTDIR / (notSurePattern%notSureCount), area)\n                    notSureCount += 1\n                else:\n                    mainWordList.append(result)\n                    WordList.append(result)\n        except:\n            import traceback\n            traceback.print_exc()\n\n        try:\n            addonAreas = extract_target_region(\n                bottom_img,\n                wordTemplates[:10],\n                maxWitdh=705,\n                cutKana=False\n            )\n            \n            addonAreas = [kanatukenugu(i) for i in addonAreas]\n\n            results = engine(addonAreas)[0]\n            for idx, (result, score) in enumerate(results):\n                if score < 0.8:\n                    area = cv2.cvtColor(addonAreas[idx], cv2.COLOR_BGR2GRAY)\n                    _, area = cv2.threshold(area, 200, 255, cv2.THRESH_BINARY)\n                    area = cv2.cvtColor(area, cv2.COLOR_GRAY2BGR)\n                \n                    cv2.imwrite(OUTDIR / (notSurePattern_a%notSureCount_a), area)\n                    notSureCount_a += 1\n                else:\n                    additionalWordList.append(result)\n                    WordList.append(result)\n        except:\n            import traceback\n            traceback.print_exc()\n        # pass\n    \n    # write world list to txt file\n    with open(OUTDIR / \"mainWordList.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(mainWordList))\n    with open(OUTDIR / \"additionalWordList.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(additionalWordList))\n    with open(OUTDIR / \"WordList.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(WordList))\n    \n    \n    print(f\"处理完成，结果保存为：{TMPDIR}\")\n"
        },
        {
          "label": "zn",
          "language": "python",
          "value": "import cv2\nimport os\nfrom pathlib import Path\nimport shutil\nimport numpy as np\nfrom copy import deepcopy\nfrom traceback import print_exc\nfrom tqdm import tqdm\nfrom pprint import pprint\n\n\ndef calc_contours(gray, cvt=cv2.COLOR_BGR2GRAY):\n    \"\"\"\n    计算图像中的轮廓。\n\n    参数:\n    gray (numpy.array): 输入的图像。\n\n    返回:\n    list: 图像中检测到的轮廓列表。\n    \"\"\"\n    # 将输入图像转换为灰度图像\n    if len(gray.shape) == 3:\n        gray = cv2.cvtColor(gray, cvt)\n    # _, thresh = cv2.threshold(gray, 245, 255, cv2.THRESH_BINARY_INV)\n    # cv2.imwrite(str(TMP_DIR / \"thresh.jpg\"), thresh)\n    # # 添加形态学闭运算以连接细长且垂直的矩形\n    # kernel_x = np.ones((3, 1), np.uint8)\n    # kernel_y = np.ones((1, 3), np.uint8)\n    # closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_x, iterations=2)\n    # closed = cv2.morphologyEx(closed, cv2.MORPH_CLOSE, kernel_y, iterations=2)\n    # cv2.imwrite(str(TMP_DIR / \"closed.jpg\"), closed)  # 保存闭运算后的图像\n\n    # 高斯模糊去噪\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n    # cv2.imwrite(str(TMP_DIR / \"blurred.jpg\"), blurred)\n\n    # 二值化处理\n    _, binary = cv2.threshold(blurred, 245, 255, cv2.THRESH_BINARY_INV)\n    # cv2.imwrite(str(TMP_DIR / \"binary.jpg\"), binary)\n\n    # 添加开运算以去除噪声\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)\n    # cv2.imwrite(str(TMP_DIR / \"opening.jpg\"), opening)  # 保存开运算后的图像\n\n    # 膨胀操作\n    dilation = cv2.dilate(opening, kernel, iterations=2)\n\n    # 腐蚀操作\n    erosion = cv2.erode(dilation, kernel, iterations=2)\n    # cv2.imwrite(str(TMP_DIR / \"new_handled.jpg\"), erosion)  # 保存闭运算后的图像\n\n    # 查找轮廓\n    contours, _ = cv2.findContours(erosion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    return contours, erosion\n\n\ndef expand_box(box, padding=5):\n    \"\"\"\n    扩展边界框的大小。\n\n    参数:\n    box (tuple): 原始边界框坐标 (x, y, w, h)。\n    padding (int): 边界框扩展的像素值，默认为5。\n\n    返回:\n    tuple: 扩展后的边界框坐标 (x, y, w, h)。\n    \"\"\"\n    x, y, w, h = box\n    x -= padding\n    y -= padding\n    w += 2 * padding\n    h += 2 * padding\n    return (x, y, w, h)\n\n\ndef calculate_min_area_rect(contour):\n    \"\"\"\n    计算轮廓的最小外接矩形。\n\n    参数:\n    contour (numpy.array): 轮廓点的数组。\n\n    返回:\n    tuple: 最小外接矩形的顶点坐标 (box)、矩形参数 (rect) 和边界框坐标 (xywh)。\n    \"\"\"\n    rect = cv2.minAreaRect(contour)\n    box = cv2.boxPoints(rect)\n    box = np.int0(box)\n    x, y, w, h = cv2.boundingRect(contour)\n    xywh = (x, y, w, h)\n    return box, rect, xywh\n\n\ndef crop_box_region(img, box):\n    \"\"\"\n    裁剪图像中的指定边界框区域。\n\n    参数:\n    img (numpy.array): 原始图像。\n    box (tuple): 边界框坐标 (x, y, w, h)。\n\n    返回:\n    numpy.array: 裁剪后的图像区域。\n    \"\"\"\n    x, y, w, h = box\n    cropped_img = img[y : y + h, x : x + w].copy()\n    return cropped_img\n\n\ndef crop_and_extract_main_color(img, top_height=None):\n    \"\"\"\n    剪切图片顶部指定高度的区域并提取返回主要颜色。\n\n    参数:\n    img (numpy.array): 原始图像。\n    top_height (int): 剪切的顶部高度，默认为50像素。\n\n    返回:\n    tuple: 主要颜色的RGB值。\n    \"\"\"\n    if top_height:\n        image = img[:top_height].copy()\n    else:\n        image = img\n    # 判断图像是否为灰度图像\n    if len(image.shape) == 2:\n        # 灰度图像\n        hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n        main_color_gray = np.argmax(hist)\n        return np.array([main_color_gray], dtype=np.uint8)\n    else:\n        # 彩色图像\n        return np.array(\n            [\n                crop_and_extract_main_color(image[:, :, i])\n                for i in range(image.shape[2])\n            ],\n            dtype=np.uint8,\n        ).reshape(-1)\n\n\ndef compare_colors(color1, color2, threshold=30):\n    \"\"\"\n    比较两个颜色是否相同。\n\n    参数:\n    color1 (tuple): 第一个颜色的RGB值。\n    color2 (tuple): 第二个颜色的RGB值。\n    threshold (int): 颜色比较的阈值，默认为30。\n\n    返回:\n    bool: 如果颜色相同返回True，否则返回False。\n    \"\"\"\n    distance = np.linalg.norm(np.array(color1) - np.array(color2))\n    return distance < threshold\n\n\ndef color_index(color_list, color, threshold=30):\n    \"\"\"\n    将颜色添加到列表中，如果颜色不同则插入新颜色。\n\n    参数:\n    color_list (list): 颜色列表。\n    color (tuple): 待比较的颜色。\n    threshold (int): 颜色比较的阈值，默认为30。\n\n    返回:\n    int: 相同颜色的索引。\n    \"\"\"\n    for index, existing_color in enumerate(color_list):\n        if compare_colors(existing_color, color, threshold):\n            return index\n    return -1\n\n\ndef calc_rect_area(contours, draw_img=None, draw=False):\n    # 筛选出符合固定高度但宽度可变的非矩形外框\n    fixed_height = 80  # 假设固定高度为30像素\n    tolerance = 20  # 容差范围\n\n    filtered_contours = []\n    for contour in contours:\n        x, y, w, h = cv2.boundingRect(contour)\n        if abs(h - fixed_height) <= tolerance:\n            filtered_contours.append(contour)\n\n    # 使用近似多边形来检测非矩形外框\n    detected_boxes = []\n    for contour in filtered_contours:\n        epsilon = 0.02 * cv2.arcLength(contour, True)\n        approx = cv2.approxPolyDP(contour, epsilon, True)\n\n        # 检查近似多边形是否为非矩形\n        if len(approx) == 4:\n            x, y, w, h = cv2.boundingRect(contour)\n            _, _, xywh = calculate_min_area_rect(contour)\n            detected_boxes.append((*xywh, approx))\n\n    # # 绘制检测到的非矩形外框\n    box_image = draw_img.copy()\n    for box in detected_boxes:\n        x, y, w, h, approx = box\n        cv2.rectangle(box_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n\n    return detected_boxes\n\n\ndef box_classification(img, x, y, w, h, box_type_threshold=150 * 3):\n    crop_img = crop_box_region(img, (x, y, w, h))\n    box_main_color = crop_and_extract_main_color(crop_img)\n    # print(f\"box主要颜色的RGB值: {box_main_color}\")\n    # print(box_main_color.sum() >= box_type_threshold)\n    return box_main_color.sum() >= box_type_threshold * sum(box_main_color.shape)\n\n\ndef img_handling(image, output_dir):\n\n    contours, handled_pic = calc_contours(image)\n    detected_boxes = calc_rect_area(contours, draw_img=image, draw=True)\n\n    #     # 调用新封装的函数\n    main_color = crop_and_extract_main_color(image, 50)\n    # print(f\"主要颜色的RGB值: {main_color}\")\n\n    # 将颜色添加到列表中，并获取相同颜色的索引\n    theme = color_index(THEMES, main_color)\n    if theme == -1:\n        THEMES.append(main_color)\n        theme += len(THEMES)\n        THEME_COUNT[str(theme)] = 0\n    # print(f\"颜色索引: {theme}\")\n\n    # 腐蚀操作\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n    erosion = cv2.erode(handled_pic, kernel, iterations=2)\n\n    # cv2.imwrite(str(output_dir / \"box_eroded_image.jpg\"), erosion)\n    for box in detected_boxes:\n        try:\n            box_type = int(\n                box_classification(erosion, *box[:4], box_type_threshold=150)\n            )\n            area_a = crop_box_region(image, box[:4])\n            box_b = [*box[:4]]\n            box_b_shape = BOX_SHAPE[box_type]\n            box_b[1] += box_b[3] + box_b_shape[0]\n            box_b[3] = box_b_shape[1]\n            area_b = crop_box_region(image, box_b)\n            cv2.imwrite(\n                str(\n                    output_dir\n                    / (BOX_NAME_PATTERN % (theme, THEME_COUNT[str(theme)], \"a\"))\n                ),\n                area_a,\n            )\n            cv2.imwrite(\n                str(\n                    output_dir\n                    / (BOX_NAME_PATTERN % (theme, THEME_COUNT[str(theme)], \"b\"))\n                ),\n                area_b,\n            )\n            THEME_COUNT[str(theme)] += 1\n        except Exception as e:\n            print_exc()\n            raise (e)\n\n\nif __name__ == \"__main__\":\n    ROOT = Path(__file__).resolve().parent\n    IN_DIR = ROOT / \"zn_in\"\n    OUT_DIR = ROOT / \"zn_out\"\n    TMP_DIR = ROOT / \"zn_tmp\"\n\n    shutil.rmtree(TMP_DIR, ignore_errors=True)\n    shutil.rmtree(OUT_DIR, ignore_errors=True)\n    TMP_DIR.mkdir(exist_ok=True, parents=True)\n    OUT_DIR.mkdir(exist_ok=True, parents=True)\n    THEMES = []\n    THEME_COUNT = {}\n    EXP_COUNT = 0\n\n    # box_type:\n    # 0: offset=4, height=85\n    # 1: offset=4, height=90\n    BOX_SHAPE = {\n        0: (4, 85),\n        1: (4, 90),\n    }\n    BOX_NAME_PATTERN = (\n        \"%s_%0.8d_%s.png\"  # \"{THEME}_{THEME_COUNT[str(theme)]}_{[a|b]}.png\"\n    )\n\n    loop = tqdm(sorted(os.listdir(IN_DIR)))\n    for img in loop:\n        # image = cv2.imread(str(IN_DIR / \"i-034.jpg\"))\n        image = cv2.imread(str(IN_DIR / img))\n        try:\n            img_handling(image, OUT_DIR)\n        except Exception as e:\n            print_exc()\n            cv2.imwrite(str(TMP_DIR / img), image)\n            EXP_COUNT += 1\n        finally:\n            loop.set_postfix(\n                {\n                    \"processed\": img,\n                    \"错误图片数量\": EXP_COUNT,\n                    **THEME_COUNT,\n                }\n            )\n    pprint(\"处理完成，错误图片数量: %d\" % EXP_COUNT)\n    pprint(THEME_COUNT)\n"
        },
        {
          "label": "zn_anki",
          "language": "python",
          "value": "# anki 批量制卡\nimport genanki\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nif __name__ == \"__main__\":\n    # 创建一个模型\n    model_id = 1607392319\n    model = genanki.Model(\n        model_id,\n        \"Picture Card\",\n        fields=[\n            {\"name\": \"FrontImage\"},\n            {\"name\": \"BackImage\"},\n        ],\n        templates=[\n            {\n                \"name\": \"Card 1\",\n                \"qfmt\": \"{{FrontImage}}\",\n                \"afmt\": \"{{BackImage}}\",\n            },\n        ],\n    )\n\n    # 创建一个牌组\n    deck_id = 2059400110\n    deck = genanki.Deck(deck_id, \"JA情景短语\")\n\n    ROOT = Path(__file__).resolve().parent\n\n    # 图片文件夹路径\n    IMG_DIR = ROOT / \"zn_out\"  # 根据实际情况调整路径\n\n    media_files = []\n\n    THEME_COUNT = {\"0\": 621, \"1\": 219, \"2\": 228, \"3\": 136, \"4\": 146}\n\n    # 遍历文件夹中的图片\n    loop = tqdm(sorted(IMG_DIR.glob(\"*.png\")))\n\n    # 遍历THEME_COUNT字典\n    for theme, count in tqdm(THEME_COUNT.items(), leave=False):\n        for i in tqdm(range(count), leave=False):\n            front_image_path = f\"{theme}_{i:04d}_a.png\"\n            back_image_path = f\"{theme}_{i:04d}_b.png\"\n            front_full_path = IMG_DIR / front_image_path\n            back_full_path = IMG_DIR / back_image_path\n\n            # 检查图片是否存在\n            assert front_full_path.exists() and back_full_path.exists()\n            media_files.append(str(front_full_path))\n            media_files.append(str(back_full_path))\n            note = genanki.Note(\n                model=model,\n                fields=[\n                    \"\"\"<img src=\"%s\", alt=\"%s\">\"\"\"\n                    % (\n                        front_image_path,\n                        front_image_path,\n                    ),\n                    \"\"\"<img src=\"%s\", alt=\"%s\">\"\"\"\n                    % (\n                        back_image_path,\n                        back_image_path,\n                    ),\n                ],\n            )\n            deck.add_note(note)\n\n    # 生成APKG文件\n    my_package = genanki.Package(deck)\n    my_package.media_files = media_files\n    my_package.write_to_file(ROOT / \"zn_cards.apkg\")\n"
        }
      ],
      "id": "NFUu-RrP",
      "createdAt": 1737212114180,
      "updatedAt": 1737616801574
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mdpwqphi",
      "tagsIds": [],
      "description": null,
      "name": "limit",
      "content": [
        {
          "label": "Fragment 1",
          "language": "mysql",
          "value": "-- 基本用法(Mysql/Sqlite/PostgreSql)\n-- 1. 获取前 N 行：LIMIT N\nSELECT * FROM table_name LIMIT 10;\n-- 这个查询会返回表中的前 10 行记录。\n\n-- 2. 分页查询：LIMIT offset, row_count\nSELECT * FROM table_name LIMIT 5, 10;\n-- 这个查询会跳过前 5 行，然后返回接下来的 10 行记录。注意这里的偏移量是从 0 开始计数的。\n \n -- 3. 使用 OFFSET 来实现同样的效果：\n SELECT * FROM table_name LIMIT 10 OFFSET 5;\n -- 这与例子2等价，即跳过前 5 行并取接下来的 10 行。\n \n -- Oracle\n -- 4. Oracle 不直接支持 LIMIT 关键字，而是使用 ROWNUM 或者 ROW_NUMBER() 函数来达到类似的效果：\n SELECT * FROM table_name WHERE ROWNUM <= 10;\n \nSELECT * FROM (\n  SELECT a.*, ROWNUM rnum FROM (\n    SELECT * FROM table_name ORDER BY some_column\n  ) a WHERE ROWNUM <= 15\n) WHERE rnum > 5;\n\n-- 从 Oracle 12c 开始，可以使用 FETCH FIRST 子句进行更简洁的分页查询：\nSELECT * FROM table_name ORDER BY some_column OFFSET 5 ROWS FETCH NEXT 10 ROWS ONLY;\n\n-- SQL Server\n-- SQL Server 2012 及以后版本支持 OFFSET-FETCH 语法来进行分页查询：\n-- 5. 获取前 N 行：\nSELECT TOP (10) * FROM table_name;\n-- 6. 分页查询：\nSELECT * FROM table_name ORDER BY some_column OFFSET 5 ROWS FETCH NEXT 10 ROWS ONLY;"
        }
      ],
      "id": "RMF9Kr6k",
      "createdAt": 1737428922605,
      "updatedAt": 1737429347395
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "list slicing",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": "# 切片赋值\n# 你可以使用切片来修改列表的一部分。\n\n# 替换子列表：\nmy_list = [0, 1, 2, 3, 4, 5]\nmy_list[1:4] = [10, 20, 30]  # 替换索引 1 到 3 的元素\nprint(my_list)  # 输出: [0, 10, 20, 30, 4, 5]\n\n# 插入元素：\nmy_list = [0, 1, 2, 3, 4, 5]\nmy_list[3:3] = [100, 200]  # 在索引 3 处插入元素\nprint(my_list)  # 输出: [0, 1, 2, 100, 200, 3, 4, 5]\n\n# 删除元素：\nmy_list = [0, 1, 2, 3, 4, 5]\nmy_list[1:4] = []  # 删除索引 1 到 3 的元素\nprint(my_list)  # 输出: [0, 4, 5]"
        }
      ],
      "id": "HVH5gAcQ",
      "createdAt": 1737451383912,
      "updatedAt": 1737451571394
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Counter",
      "content": [
        {
          "label": "Fragment 1",
          "language": "markdown",
          "value": "### `collections.Counter` 详细介绍\n\n`Counter` 是 Python 的 `collections` 模块中提供的一个字典子类，专门用于计数哈希对象。它非常适合统计元素出现的频率，并提供了多种便捷的方法来操作和查询这些计数。\n\n#### 1. **导入和初始化**\n\n首先，你需要从 `collections` 模块中导入 `Counter`：\n\n```python\nfrom collections import Counter\n```\n\n##### 1.1 初始化方式\n\n- **从可迭代对象初始化**：\n  \n  ```python\n  c = Counter('abracadabra')\n  print(c)  # 输出: Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1})\n  ```\n\n- **从列表初始化**：\n  \n  ```python\n  c = Counter(['apple', 'banana', 'apple', 'orange', 'banana', 'apple'])\n  print(c)  # 输出: Counter({'apple': 3, 'banana': 2, 'orange': 1})\n  ```\n\n- **从字典初始化**：\n  \n  ```python\n  c = Counter({'red': 4, 'blue': 2})\n  print(c)  # 输出: Counter({'red': 4, 'blue': 2})\n  ```\n\n- **使用关键字参数初始化**：\n  \n  ```python\n  c = Counter(red=4, blue=2)\n  print(c)  # 输出: Counter({'red': 4, 'blue': 2})\n  ```\n\n#### 2. **常用方法**\n\n##### 2.1 访问元素\n\n- **获取单个元素的计数**：\n  \n  ```python\n  c = Counter('abracadabra')\n  print(c['a'])  # 输出: 5\n  print(c['z'])  # 输出: 0 (不存在的元素返回 0 而不是抛出 KeyError)\n  ```\n\n- **列出所有元素**：\n  \n  ```python\n  c = Counter('abracadabra')\n  print(list(c.elements()))  # 输出: ['a', 'a', 'a', 'a', 'a', 'b', 'b', 'r', 'r', 'c', 'd']\n  ```\n\n##### 2.2 统计最常见元素\n\n- **获取最常见的 n 个元素**：\n  \n  ```python\n  c = Counter('abracadabra')\n  print(c.most_common(3))  # 输出: [('a', 5), ('b', 2), ('r', 2)]\n  ```\n\n##### 2.3 更新计数\n\n- **更新计数器**：\n  \n  ```python\n  c = Counter('which')\n  c.update('witch')  # 更新后：Counter({'w': 2, 'i': 2, 'c': 2, 'h': 2, 't': 2, 'e': 1})\n  print(c)\n  ```\n\n- **减去计数**：\n  \n  ```python\n  c = Counter(a=4, b=2, c=0, d=-2)\n  d = Counter(a=1, b=2, c=3, d=4)\n  c.subtract(d)\n  print(c)  # 输出: Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})\n  ```\n\n##### 2.4 数学运算\n\n`Counter` 支持加法、减法、交集和并集等数学运算。\n\n- **加法**：\n  \n  ```python\n  c1 = Counter(a=3, b=1)\n  c2 = Counter(a=1, b=2)\n  c3 = c1 + c2  # 结果为 Counter({'a': 4, 'b': 3})\n  print(c3)\n  ```\n\n- **减法**：\n  \n  ```python\n  c1 = Counter(a=3, b=1)\n  c2 = Counter(a=1, b=2)\n  c3 = c1 - c2  # 结果为 Counter({'a': 2})\n  print(c3)\n  ```\n\n- **交集（取最小值）**：\n  \n  ```python\n  c1 = Counter(a=3, b=1)\n  c2 = Counter(a=1, b=2)\n  c3 = c1 & c2  # 结果为 Counter({'a': 1, 'b': 1})\n  print(c3)\n  ```\n\n- **并集（取最大值）**：\n  \n  ```python\n  c1 = Counter(a=3, b=1)\n  c2 = Counter(a=1, b=2)\n  c3 = c1 | c2  # 结果为 Counter({'a': 3, 'b': 2})\n  print(c3)\n  ```\n\n#### 3. **其他功能**\n\n##### 3.1 清空计数器\n\n```python\nc = Counter('abracadabra')\nc.clear()\nprint(c)  # 输出: Counter()\n```\n\n##### 3.2 元素总数\n\n```python\nc = Counter('abracadabra')\nprint(sum(c.values()))  # 输出: 11\n```\n\n##### 3.3 转换为其他类型\n\n- **转换为列表**：\n  \n  ```python\n  c = Counter('abracadabra')\n  print(list(c))  # 输出: ['a', 'b', 'r', 'c', 'd']\n  ```\n\n- **转换为集合**：\n  \n  ```python\n  c = Counter('abracadabra')\n  print(set(c))  # 输出: {'a', 'b', 'r', 'c', 'd'}\n  ```\n\n- **转换为字典**：\n  \n  ```python\n  c = Counter('abracadabra')\n  print(dict(c))  # 输出: {'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1}\n  ```\n\n#### 4. **实际应用示例**\n\n##### 4.1 统计单词频率\n\n```python\nfrom collections import Counter\n\ntext = \"hello world hello python hello world\"\nwords = text.split()\nword_counts = Counter(words)\n\nprint(word_counts)  # 输出: Counter({'hello': 3, 'world': 2, 'python': 1})\n```\n\n##### 4.2 查找最常见的字符\n\n```python\nfrom collections import Counter\n\ntext = \"abracadabra\"\nchar_counts = Counter(text)\n\nmost_common_chars = char_counts.most_common(3)\nprint(most_common_chars)  # 输出: [('a', 5), ('b', 2), ('r', 2)]\n```\n\n#### 总结\n\n`Counter` 是一个非常强大且易于使用的工具，适用于各种需要统计元素频率的场景。它不仅简化了代码，还提供了丰富的内置方法来处理和分析数据。如果你有更具体的问题或需要进一步的帮助，请随时告诉我！"
        }
      ],
      "id": "eoj270FA",
      "createdAt": 1737451579097,
      "updatedAt": 1737451597702
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "spacy",
      "content": [
        {
          "label": "basic sumary",
          "language": "markdown",
          "value": "### spaCy 模块和用法详细介绍\n\nspaCy 是一个用于自然语言处理（NLP）的高效库，广泛应用于文本分析、信息提取、语义理解等任务。以下是 spaCy 的主要模块和功能的详细介绍：\n\n#### 1. **安装和导入**\n\n首先，确保你已经安装了 spaCy 和所需的语言模型。\n\n```bash\npip install spacy\npython -m spacy download en_core_web_sm\n```\n\n然后在 Python 中导入 spaCy：\n\n```python\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n```\n\n#### 2. **核心模块**\n\n##### 2.1 `nlp` 对象\n\n`nlp` 对象是 spaCy 的核心，它加载预训练的语言模型，并提供各种 NLP 功能。\n\n- **加载模型**：\n  ```python\n  nlp = spacy.load(\"en_core_web_sm\")  # 加载英语模型\n  ```\n\n- **处理文本**：\n  ```python\n  doc = nlp(\"This is a sentence.\")\n  ```\n\n##### 2.2 `Doc` 对象\n\n`Doc` 对象表示经过 spaCy 处理后的文本，包含多个 `Token` 对象。\n\n- **遍历文档中的词**：\n  ```python\n  for token in doc:\n      print(token.text, token.pos_, token.dep_)\n  ```\n\n- **访问句子**：\n  ```python\n  for sent in doc.sents:\n      print(sent.text)\n  ```\n\n##### 2.3 `Token` 对象\n\n`Token` 对象表示文档中的单个词或标点符号，包含丰富的属性和方法。\n\n- **常见属性**：\n  - `token.text`：原始文本\n  - `token.lemma_`：词形还原形式\n  - `token.pos_`：词性标注（POS）\n  - `token.tag_`：详细的词性标签\n  - `token.dep_`：依存关系标签\n  - `token.shape_`：单词形状（如大小写、数字等）\n  - `token.is_alpha`：是否为字母\n  - `token.is_stop`：是否为停用词\n\n##### 2.4 `Span` 对象\n\n`Span` 对象表示文档中的子序列，通常用于命名实体识别（NER）和其他片段操作。\n\n- **创建 Span**：\n  ```python\n  span = doc[0:2]  # 创建一个包含前两个词的 Span\n  ```\n\n- **访问实体**：\n  ```python\n  for ent in doc.ents:\n      print(ent.text, ent.label_)\n  ```\n\n##### 2.5 `Matcher` 和 `PhraseMatcher`\n\n用于模式匹配，可以查找特定模式的词语或短语。\n\n- **使用 Matcher**：\n  ```python\n  from spacy.matcher import Matcher\n\n  matcher = Matcher(nlp.vocab)\n  pattern = [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n  matcher.add(\"HelloWorldPattern\", [pattern])\n\n  matches = matcher(doc)\n  for match_id, start, end in matches:\n      span = doc[start:end]\n      print(span.text)\n  ```\n\n- **使用 PhraseMatcher**：\n  ```python\n  from spacy.matcher import PhraseMatcher\n\n  phrase_matcher = PhraseMatcher(nlp.vocab)\n  patterns = [nlp.make_doc(text) for text in (\"New York\", \"Big Apple\")]\n  phrase_matcher.add(\"CityNames\", patterns)\n\n  matches = phrase_matcher(doc)\n  for match_id, start, end in matches:\n      span = doc[start:end]\n      print(span.text)\n  ```\n\n#### 3. **命名实体识别 (NER)**\n\nspaCy 提供了强大的命名实体识别功能，可以识别文本中的实体并分类。\n\n- **常见实体类型**：\n  - `PERSON`：人名\n  - `ORG`：组织名\n  - `GPE`：地理位置\n  - `DATE`：日期\n  - `TIME`：时间\n  - `MONEY`：货币金额\n  - `PRODUCT`：产品名\n\n- **示例代码**：\n  ```python\n  doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n\n  for ent in doc.ents:\n      print(ent.text, ent.label_)\n  ```\n\n#### 4. **依存句法分析**\n\nspaCy 可以解析句子的依存关系，帮助理解句子结构。\n\n- **示例代码**：\n  ```python\n  doc = nlp(\"The quick brown fox jumps over the lazy dog.\")\n\n  for token in doc:\n      print(f\"{token.text} -> {token.dep_} -> {token.head.text}\")\n  ```\n\n#### 5. **词汇和统计特征**\n\nspaCy 提供了多种词汇和统计特征，可用于进一步的文本分析。\n\n- **词频统计**：\n  ```python\n  from collections import Counter\n\n  words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n  word_freq = Counter(words)\n  print(word_freq.most_common(5))\n  ```\n\n#### 6. **自定义管道组件**\n\n你可以扩展 spaCy 的处理管道，添加自定义组件。\n\n- **添加自定义组件**：\n  ```python\n  def custom_component(doc):\n      print(\"Custom component executed!\")\n      return doc\n\n  nlp.add_pipe(\"custom_component\", last=True)\n  ```\n\n#### 7. **训练和更新模型**\n\nspaCy 支持通过自己的数据训练或微调模型。\n\n- **训练新模型**：\n  使用 `spacy train` 命令行工具或 API 进行训练。\n\n- **微调现有模型**：\n  ```python\n  import spacy\n  from spacy.util import minibatch, compounding\n\n  nlp = spacy.load(\"en_core_web_sm\")\n  optimizer = nlp.begin_training()\n\n  for i in range(10):\n      losses = {}\n      batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n      for batch in batches:\n          texts, annotations = zip(*batch)\n          nlp.update(texts, annotations, sgd=optimizer, losses=losses)\n  ```\n\n### 总结\n\nspaCy 提供了丰富的功能和灵活的接口，适用于各种自然语言处理任务。无论是简单的文本处理还是复杂的机器学习应用，spaCy 都是一个强大且易于使用的工具。如果你有更具体的问题或需要进一步的帮助，请随时告诉我！"
        },
        {
          "label": "Doc",
          "language": "markdown",
          "value": "### `Doc` 对象详细介绍\n\n`Doc` 对象是 spaCy 中的核心数据结构之一，表示经过处理的文本。它由一系列 `Token` 对象组成，并且包含了丰富的属性和方法，用于访问和操作文档中的信息。以下是关于 `Doc` 对象的详细说明：\n\n#### 1. **创建 `Doc` 对象**\n\n通常情况下，`Doc` 对象是由 `nlp` 处理器生成的：\n\n```python\nimport spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"This is a sentence.\")\n```\n\n你也可以手动创建 `Doc` 对象，但这通常不常见：\n\n```python\nfrom spacy.tokens import Doc\nfrom spacy.vocab import Vocab\n\nvocab = Vocab()\nwords = [\"This\", \"is\", \"a\", \"sentence\", \".\"]\nspaces = [True, True, True, False, False]\ndoc = Doc(vocab, words=words, spaces=spaces)\n```\n\n#### 2. **主要属性**\n\n##### 2.1 文本和词汇\n\n- **`doc.text`**：返回整个文档的原始文本。\n- **`doc.text_with_ws`**：返回包含空格的原始文本。\n- **`doc.vocab`**：返回文档使用的词汇表（`Vocab` 对象）。\n\n##### 2.2 句子分割\n\n- **`doc.sents`**：返回一个生成器，按句子分割文档。\n  \n  ```python\n  for sent in doc.sents:\n      print(sent.text)\n  ```\n\n##### 2.3 实体识别\n\n- **`doc.ents`**：返回文档中所有命名实体的生成器。\n  \n  ```python\n  for ent in doc.ents:\n      print(ent.text, ent.label_)\n  ```\n\n##### 2.4 依存句法分析\n\n- **`doc.root`**：返回文档的根节点（通常是主句的主语或谓语）。\n- **`doc.to_array([spacy.attrs.HEAD, spacy.attrs.DEP])`**：将文档转换为 NumPy 数组，包含指定的属性（如依存关系头和标签）。\n\n##### 2.5 其他属性\n\n- **`doc.is_parsed`**：是否已经进行了句法解析。\n- **`doc.is_tagged`**：是否已经进行了词性标注。\n- **`doc.is_nered`**：是否已经进行了命名实体识别。\n- **`doc.user_data`**：用户自定义的数据字典，可用于存储额外的信息。\n\n#### 3. **遍历 `Doc` 对象**\n\n你可以通过遍历 `Doc` 对象来访问每个 `Token` 或者特定的子序列（如句子、实体等）。\n\n##### 3.1 遍历所有词\n\n```python\nfor token in doc:\n    print(token.text, token.pos_, token.dep_)\n```\n\n##### 3.2 遍历句子\n\n```python\nfor sent in doc.sents:\n    print(f\"Sentence: {sent.text}\")\n```\n\n##### 3.3 遍历实体\n\n```python\nfor ent in doc.ents:\n    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n```\n\n#### 4. **常用方法**\n\n##### 4.1 获取子序列 (`Span`)\n\n使用切片语法可以轻松获取文档的子序列，返回一个 `Span` 对象。\n\n```python\nspan = doc[0:2]  # 获取前两个词\nprint(span.text)  # 输出: This is\n```\n\n##### 4.2 查找句子边界\n\n`sent_starts` 属性可以帮助你找到句子的起始位置。\n\n```python\nfor i, token in enumerate(doc):\n    if token.is_sent_start:\n        print(f\"Sentence starts at token index {i}: {token.text}\")\n```\n\n##### 4.3 序列化和反序列化\n\n`Doc` 对象可以被序列化为二进制格式，便于保存和加载。\n\n```python\n# 序列化\nbytes_data = doc.to_bytes()\n\n# 反序列化\nnew_doc = Doc(doc.vocab).from_bytes(bytes_data)\n```\n\n#### 5. **自定义扩展**\n\nspaCy 支持为 `Doc` 对象添加自定义属性和方法，以便在处理过程中附加更多功能。\n\n```python\nfrom spacy.tokens import Doc\nfrom spacy.language import Language\n\n@Language.factory(\"custom_component\")\ndef create_custom_component(nlp, name):\n    def custom_method(self):\n        return \"Custom method called!\"\n\n    Doc.set_extension(\"custom_attr\", default=None)\n    Doc.set_extension(\"custom_method\", method=custom_method)\n\n    return lambda doc: doc\n\nnlp.add_pipe(\"custom_component\")\n\ndoc = nlp(\"This is a test.\")\nprint(doc._.custom_attr)  # 输出: None\nprint(doc._.custom_method())  # 输出: Custom method called!\n```\n\n#### 6. **性能优化**\n\n对于大规模文本处理，可以通过以下方式优化性能：\n\n- **禁用不必要的管道组件**：\n  \n  ```python\n  nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n  ```\n\n- **批量处理**：\n  \n  使用 `nlp.pipe` 方法进行批量处理，提高效率。\n\n  ```python\n  texts = [\"Text one\", \"Text two\", \"Text three\"]\n  docs = list(nlp.pipe(texts))\n  ```\n\n### 总结\n\n`Doc` 对象是 spaCy 中非常重要的数据结构，提供了丰富的属性和方法来处理和分析自然语言文本。无论是简单的文本遍历还是复杂的依存句法分析，`Doc` 对象都能满足各种需求。如果你有更具体的问题或需要进一步的帮助，请随时告诉我！"
        }
      ],
      "id": "DRspPSpv",
      "createdAt": 1737451673715,
      "updatedAt": 1737451708483
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "lemma table",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": "git "
        }
      ],
      "id": "QMfhY94W",
      "createdAt": 1737451772925,
      "updatedAt": 1738552866113
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "seaborn",
      "content": [
        {
          "label": "Fragment 1",
          "language": "markdown",
          "value": "### Seaborn 详细介绍\n\nSeaborn 是一个基于 Matplotlib 的 Python 数据可视化库，旨在提供一个简单易用的接口来创建美观且信息丰富的统计图形。Seaborn 提供了多种高级接口，可以方便地绘制常见的统计图表，如直方图、箱线图、热图、时间序列图等。\n\n#### 1. **安装和导入**\n\n首先，确保你已经安装了 Seaborn 和 Matplotlib。你可以使用以下命令进行安装：\n\n```bash\npip install seaborn\npip install matplotlib\n```\n\n然后在 Python 中导入 Seaborn 和 Matplotlib：\n\n```python\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n```\n\n#### 2. **基本用法**\n\n##### 2.1 设置样式\n\nSeaborn 提供了多种预定义的样式，可以快速设置图表的外观。\n\n```python\nsns.set(style=\"whitegrid\")\n```\n\n##### 2.2 加载示例数据集\n\nSeaborn 提供了一些内置的数据集，方便进行示例和学习。\n\n```python\ntips = sns.load_dataset(\"tips\")\nprint(tips.head())\n```\n\n输出：\n\n```\n   total_bill  tip     sex smoker  day    time  size\n0       16.99  1.01  Female     No  Sun  Dinner     2\n1       10.34  1.66    Male     No  Sun  Dinner     3\n2       21.01  3.50    Male     No  Sun  Dinner     3\n3       23.68  3.31    Male     No  Sun  Dinner     2\n4       24.59  3.61  Female     No  Sun  Dinner     4\n```\n\n##### 2.3 绘制基本图表\n\n- **直方图**：\n  \n  ```python\n  sns.histplot(tips[\"total_bill\"], bins=10, kde=True)\n  plt.title(\"Distribution of Total Bill\")\n  plt.show()\n  ```\n\n- **箱线图**：\n  \n  ```python\n  sns.boxplot(x=\"day\", y=\"total_bill\", data=tips)\n  plt.title(\"Total Bill by Day\")\n  plt.show()\n  ```\n\n- **散点图**：\n  \n  ```python\n  sns.scatterplot(x=\"total_bill\", y=\"tip\", hue=\"sex\", data=tips)\n  plt.title(\"Tip vs Total Bill by Sex\")\n  plt.show()\n  ```\n\n- **热图**：\n  \n  ```python\n  corr = tips.corr()\n  sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n  plt.title(\"Correlation Heatmap\")\n  plt.show()\n  ```\n\n#### 3. **高级功能**\n\n##### 3.1 分面网格\n\nSeaborn 提供了 `FacetGrid` 和 `PairGrid` 等高级功能，可以创建复杂的多面板图表。\n\n- **FacetGrid**：\n  \n  ```python\n  g = sns.FacetGrid(tips, col=\"time\", row=\"sex\", margin_titles=True)\n  g.map(sns.histplot, \"total_bill\", bins=10, kde=True)\n  plt.show()\n  ```\n\n- **PairGrid**：\n  \n  ```python\n  g = sns.PairGrid(tips)\n  g.map_diag(sns.histplot)\n  g.map_offdiag(sns.scatterplot)\n  plt.show()\n  ```\n\n##### 3.2 类别数据\n\nSeaborn 提供了多种方法来处理类别数据。\n\n- **条形图**：\n  \n  ```python\n  sns.barplot(x=\"day\", y=\"total_bill\", hue=\"sex\", data=tips)\n  plt.title(\"Average Total Bill by Day and Sex\")\n  plt.show()\n  ```\n\n- **计数图**：\n  \n  ```python\n  sns.countplot(x=\"day\", hue=\"sex\", data=tips)\n  plt.title(\"Count of Observations by Day and Sex\")\n  plt.show()\n  ```\n\n##### 3.3 时间序列数据\n\nSeaborn 可以用于绘制时间序列数据。\n\n- **时间序列图**：\n  \n  ```python\n  import pandas as pd\n\n  # 创建示例时间序列数据\n  dates = pd.date_range(\"2023-01-01\", periods=100)\n  data = pd.DataFrame({\"value\": range(100)}, index=dates)\n\n  sns.lineplot(data=data, x=data.index, y=\"value\")\n  plt.title(\"Time Series Data\")\n  plt.show()\n  ```\n\n#### 4. **自定义图表**\n\nSeaborn 提供了丰富的自定义选项，可以调整图表的外观和样式。\n\n- **调整颜色**：\n  \n  ```python\n  sns.histplot(tips[\"total_bill\"], bins=10, kde=True, color=\"skyblue\")\n  plt.title(\"Distribution of Total Bill\")\n  plt.show()\n  ```\n\n- **添加标签和标题**：\n  \n  ```python\n  sns.scatterplot(x=\"total_bill\", y=\"tip\", hue=\"sex\", data=tips)\n  plt.xlabel(\"Total Bill\")\n  plt.ylabel(\"Tip\")\n  plt.title(\"Tip vs Total Bill by Sex\")\n  plt.show()\n  ```\n\n- **使用不同的调色板**：\n  \n  ```python\n  sns.heatmap(corr, annot=True, cmap=\"viridis\")\n  plt.title(\"Correlation Heatmap\")\n  plt.show()\n  ```\n\n#### 5. **实际应用示例**\n\n##### 5.1 分析鸢尾花数据集\n\nSeaborn 提供了经典的鸢尾花数据集，可以用于分类任务的可视化。\n\n```python\niris = sns.load_dataset(\"iris\")\nprint(iris.head())\n```\n\n输出：\n\n```\n   sepal_length  sepal_width  petal_length  petal_width species\n0           5.1          3.5           1.4          0.2  setosa\n1           4.9          3.0           1.4          0.2  setosa\n2           4.7          3.2           1.3          0.2  setosa\n3           4.6          3.1           1.5          0.2  setosa\n4           5.0          3.6           1.4          0.2  setosa\n```\n\n- **散点图矩阵**：\n  \n  ```python\n  sns.pairplot(iris, hue=\"species\")\n  plt.show()\n  ```\n\n- **箱线图**：\n  \n  ```python\n  sns.boxplot(x=\"species\", y=\"petal_length\", data=iris)\n  plt.title(\"Petal Length by Species\")\n  plt.show()\n  ```\n\n##### 5.2 分析泰坦尼克号数据集\n\nSeaborn 提供了泰坦尼克号数据集，可以用于生存预测的可视化。\n\n```python\ntitanic = sns.load_dataset(\"titanic\")\nprint(titanic.head())\n```\n\n输出：\n\n```\n   survived  pclass     sex   age  sibsp  parch  fare embarked  class    who  adult_male deck  embark_town alive  alone\n0         0       3    male  22.0      1      0  7.25        S  Third    man       True  NaN  Southampton    no  False\n1         1       1  female  38.0      1      0  71.28        C  First  woman      False    C    Cherbourg   yes  False\n2         1       3  female  26.0      0      0   7.92        S  Third  woman      False  NaN  Southampton   yes   True\n3         1       1  female  35.0      1      0  53.10        S  First  woman      False    C  Southampton   yes  False\n4         0       3    male  35.0      0      0   8.05        S  Third    man       True  NaN  Southampton    no   True\n```\n\n- **生存率按性别**：\n  \n  ```python\n  sns.barplot(x=\"sex\", y=\"survived\", data=titanic)\n  plt.title(\"Survival Rate by Sex\")\n  plt.show()\n  ```\n\n- **生存率按舱位**：\n  \n  ```python\n  sns.barplot(x=\"pclass\", y=\"survived\", hue=\"sex\", data=titanic)\n  plt.title(\"Survival Rate by Pclass and Sex\")\n  plt.show()\n  ```\n\n#### 总结\n\nSeaborn 是一个功能强大且易于使用的数据可视化库，特别适合绘制统计图表。通过简单的接口和丰富的功能，你可以快速创建美观且信息丰富的图形。如果你有更具体的问题或需要进一步的帮助，请随时告诉我！"
        }
      ],
      "id": "5VF5YT0E",
      "createdAt": 1737451843003,
      "updatedAt": 1737451854070
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "scrapy",
      "content": [
        {
          "label": "Fragment 1",
          "language": "markdown",
          "value": "Scrapy是一个用于抓取网站并提取结构化数据的Python框架，广泛应用于数据挖掘、信息处理和历史记录归档等领域。以下是Scrapy的主要特点：\n\n- **高效且可扩展**：Scrapy基于Twisted异步网络库构建，能够高效地处理大量请求。\n- **内置功能丰富**：提供了诸如选择器（Selectors）、中间件（Middlewares）、管道（Pipelines）等组件，简化了开发流程。\n- **支持多种协议**：除了HTTP/HTTPS外，还支持Sitemap、Robots.txt等协议。\n- **强大的社区支持**：拥有活跃的开源社区，提供了丰富的插件和扩展。\n\n### 安装Scrapy\n\n可以通过pip安装Scrapy：\n\n```bash\npip install scrapy\n```\n\n### 创建一个简单的Scrapy项目\n\n1. 创建项目：\n   ```bash\n   scrapy startproject myproject\n   ```\n\n2. 进入项目目录并创建爬虫：\n   ```bash\n   cd myproject\n   scrapy genspider example example.com\n   ```\n\n3. 编辑爬虫文件 `myproject/spiders/example.py`：\n\n   ```python\n   import scrapy\n\n   class ExampleSpider(scrapy.Spider):\n       name = 'example'\n       allowed_domains = ['example.com']\n       start_urls = ['http://example.com/']\n\n       def parse(self, response):\n           self.log('Visited %s' % response.url)\n           # 提取数据或跟进链接\n   ```\n\n4. 运行爬虫：\n   ```bash\n   scrapy crawl example\n   ```\n\n### 数据提取\n\n使用XPath或CSS选择器从网页中提取数据：\n\n```python\ndef parse(self, response):\n    for title in response.css('h2.entry-title'):\n        yield {\n            'title': title.css('a ::text').get()\n        }\n```\n\n### 保存结果\n\n可以将抓取的数据保存为JSON、CSV等格式：\n\n```bash\nscrapy crawl example -o items.json\n```\n\n以上是Scrapy的基本介绍和使用方法，希望对你有所帮助！"
        }
      ],
      "id": "iv_tlAy6",
      "createdAt": 1737543748336,
      "updatedAt": 1737543762569
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "7IuFDFml",
      "tagsIds": [],
      "description": null,
      "name": "速查表",
      "content": [
        {
          "label": "Fragment 1",
          "language": "markdown",
          "value": "| 匹配字符 |                                                                                    |          |                                 |\n| -------- | ---------------------------------------------------------------------------------- | -------- | ------------------------------- |\n| [abc]    | 匹配a,b,c中的任意一个字符                                                          | [^abc]   | 匹配除a,b,c之外的任意字符       |\n| [a-g]    | 匹配a-g范围内的任意一个字符                                                        | [^a-g]   | 不匹配a-g中的所有字符           |\n| [H-N]    | 匹配H-N范围内的任意一个字符                                                        | [a-gH-N] | 匹配a-g,H-N范围内的任意一个字符 |\n| [0-9]    | 匹配0-9范围内的任意一个字符                                                        | [0\\|9]   | 匹配0或9                        |\n| .        | 匹配除换行符以外的任意字符                                                         | x\\|y     | 匹配x或y                        |\n| \\s       | 匹配任意的空白符  \\n - 换行符 \\r - 回车符 \\t - 制表符  \\f - 换页符 \\v - 垂直制表符 | \\S       | 匹配非空白字符 [^\\s]            |\n| \\d       | 匹配数字                                                                           | \\D       | 匹配非数字 [^\\d]                |\n| \\w       | 匹配字母和数字                                                                     | \\W       | 匹配非字母和数字 [^\\w]          |\n|          |                                                                                    |          |                                 |\n\n| 频次范围(量词) |                               |       |            |\n| -------------- | ----------------------------- | ----- | ---------- |\n| *              | 重复零次或更多次{0,},贪婪模式 | *?    | 非贪婪模式 |\n| +              | 重复一次或更多次{1,}          | +?    | 非贪婪模式 |\n| ?              | 重复零次或一次{0,1}           | {n}   | 重复n次    |\n| {n,}           | 重复n次或更多次               | {n,m} | 重复n到m次 |\n|                |                               |       |            |\n\n| 定位匹配     |                                      |          |                          |\n| ------------ | ------------------------------------ | -------- | ------------------------ |\n| ^            | 字符串开始符                         | $        | 字符串结尾符             |\n| \\b           | 匹配单词的开始或结束                 | \\B       | 非单词边界               |\n| (exp)        | 匹配exp,并捕获文本到自动命名的组里   | (?:exp)  | 匹配exp,不捕获匹配的文本 |\n| (?=exp)      | 匹配exp前面的位置                    | (?<=exp) | 匹配exp后面的位置        |\n| (?!exp)      | 匹配后面跟的不是exp的位置            | (?<!exp) | 匹配前面不是exp的位置    |\n| (?<name>exp) | 匹配exp,并捕获文本到名称为name的组里 |          |                          |"
        }
      ],
      "id": "dcxnfzbc",
      "createdAt": 1737547326530,
      "updatedAt": 1737547439135
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "mdpwqphi",
      "tagsIds": [],
      "description": null,
      "name": "password",
      "content": [
        {
          "label": "Fragment 1",
          "language": "mysql",
          "value": "-- method 1:\nSET PASSWORD FOR 'root'@'localhost' = PASSWORD('123456');\t--设置登录密码为123456\nflush privileges;\n\n-- 在 MySQL 8.0 及更高版本中，PASSWORD() 函数已被移除，因此无法使用 SET PASSWORD FOR 'root'@'localhost' = PASSWORD('root'); 这样的语法来设置密码。\nALTER USER 'root'@'localhost' IDENTIFIED BY 'root';\nflush privileges;"
        }
      ],
      "id": "GPOvbUlL",
      "createdAt": 1737975326758,
      "updatedAt": 1737975377827
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "Mongodb",
      "content": [
        {
          "label": "MongoEngine",
          "language": "python",
          "value": "from mongoengine import (\n    Document,\n    StringField,\n    IntField,\n    FloatField,\n    DateTimeField,\n    connect,\n)\n\nfrom datetime import datetime\nimport traceback\nimport sys  # 添加导入sys模块\n\n# from MongoTables import KLine\nfrom tqdm import tqdm\n\n\nclass DBEngine:\n    __DBTABLES__ = {}\n\n    def __init__(\n        self,\n        ip=\"127.0.0.1\",\n        port=27017,\n        user=\"root\",\n        password=\"root\",\n        db=\"binance\",\n    ):\n\n        # 连接到 MongoDB 数据库\n        self.connect = connect(\n            db,\n            host=ip,\n            port=port,\n            username=user,\n            password=password,\n            maxPoolSize=32,\n        )\n        # 连接已经通过 connect 函数完成\n\n        # 创建索引\n        for table in self.__DBTABLES__.values():\n            table.ensure_indexes()\n\n    def insertKLine(self, kline):\n        # 检查是否存在相同的 (stock_name, open_time, interval)\n        existing_kline = (\n            DBEngine.__DBTABLES__[\"KLine\"]\n            .objects(\n                stock_name=kline.stock_name,\n                open_time=kline.open_time,\n                interval=kline.interval,\n            )\n            .first()\n        )\n\n        if existing_kline:\n            print(\n                f\"KLine for {kline.stock_name} at {kline.open_time} with interval {kline.interval} already exists.\"\n            )\n            return False\n\n        # 插入新数据\n        try:\n            kline.save()\n            print(\n                f\"KLine for {kline.stock_name} at {kline.open_time} with interval {kline.interval} inserted successfully.\"\n            )\n            return True\n        except Exception as e:\n            traceback.print_exc()\n            return False\n\n    def insertKLineList(self, kline_list: list):\n        try:\n            DBEngine.__DBTABLES__[\"KLine\"].objects.insert(kline_list)\n        except Exception as e:\n            traceback.print_exc()\n\n    def queryExistsByNameAndTime(self, stock_name, open_time, interval):\n        existing_kline = (\n            DBEngine.__DBTABLES__[\"KLine\"]\n            .objects(stock_name=stock_name, open_time=open_time, interval=interval)\n            .first()\n        )\n        return existing_kline is not None\n\n    def getMaxOpenTime(self, stock_name, interval):\n        max_open_time = (\n            DBEngine.__DBTABLES__[\"KLine\"]\n            .objects(stock_name=stock_name, interval=interval)\n            .order_by(\"-open_time\")  # \"-\" means descending\n            .first()\n        )\n\n        return max_open_time.open_time if max_open_time else None\n\n    def check_continuous(self, stock_name, interval, o_time=None):\n        # 查询出指定 stock_name 和 interval 的所有 open_time\n        klines = (\n            DBEngine.__DBTABLES__[\"KLine\"]\n            .objects(stock_name=stock_name, interval=interval)\n            .only(\"open_time\")\n            .order_by(\"open_time\")\n        )\n        interval_ms = interval * 1000\n\n        if not klines:\n            return []\n\n        # missing_intervals = []\n        current_time = o_time\n        expected_time = current_time\n\n        for kline in tqdm(klines, desc=\"Checking missing intervals\"):\n            open_time = kline.open_time\n            if current_time is None:\n                current_time = open_time\n            elif open_time > expected_time:\n                # 找到缺失的时间点\n                missing_start = expected_time\n                missing_count = (open_time - expected_time) // interval_ms\n                # missing_intervals.append((missing_start, int(missing_count)))            \n                # 使用 yield 逐批返回缺失的时间间隔\n                yield (missing_start, int(missing_count))\n            expected_time = open_time + interval_ms\n\n        # return missing_intervals\n\n    def getLength(self, stock_name, interval, batch_size=1024 * 16):\n        # 使用聚合框架优化 count 操作\n        # pipeline = [\n        #     {\"$match\": {\"stock_name\": stock_name, \"interval\": interval}},\n        #     {\"$count\": \"length\"},\n        # ]\n        # result = list(DBEngine.__DBTABLES__[\"KLine\"].objects.aggregate(pipeline))\n        # return result[0][\"length\"] if result else 0\n\n        batch_size = 10000\n        cursor = (\n            DBEngine.__DBTABLES__[\"KLine\"]\n            .objects(stock_name=stock_name, interval=interval)\n            .limit(batch_size)\n        )\n\n        length = 0\n        while cursor:\n            batch = list(cursor)\n            if len(batch) < batch_size:\n                length += len(batch)\n                break\n            else:\n                length += batch_size\n                sys.stdout.write(\n                    f\"\\rLength: {length}\"\n                )  # 使用sys.stdout.write和sys.stdout.flush来更新长度\n                sys.stdout.flush()\n        return length\n\n    @classmethod\n    def register_table(cls, table_class):\n        if table_class.__name__ not in cls.__DBTABLES__:\n            # cls.__DBTABLES__.append(table_class)\n            cls.__DBTABLES__[table_class.__name__] = table_class\n        else:\n            raise Exception(\n                f\"Table {table_class.__name__} has already been registered as: \"\n                + cls.__DBTABLES__[table_class.__name__]\n            )\n        return table_class\n\n\n# 定义文档类\n@DBEngine.register_table\nclass KLine(Document):\n    stock_name = StringField(required=True)\n    open_time = IntField(required=True)\n    interval = IntField(required=True)\n    open_price = FloatField(required=True)\n    high_price = FloatField(required=True)\n    low_price = FloatField(required=True)\n    close_price = FloatField(required=True)\n    volume = FloatField(required=True)\n    close_time = IntField(required=True)\n    quote_asset_volume = FloatField(required=True)\n    number_of_trades = IntField(required=True)\n    taker_buy_base_asset_volume = FloatField(required=True)\n    taker_buy_quote_asset_volume = FloatField(required=True)\n\n    meta = {\n        \"indexes\": [\n            (\"stock_name\", \"open_time\", \"interval\"),\n            (\"interval\", \"stock_name\", \"open_time\"),\n        ]\n    }\n\n\nif __name__ == \"__main__\":\n    from utils import convert_to_seconds\n\n    # db = DBEngine(ip=\"10.68.34.200\")\n    interval = convert_to_seconds(\"1h\")\n    db = DBEngine(ip=\"192.168.101.14\")\n    print(db.getMaxOpenTime(\"BTCUSDT\", 1))\n    print(db.getLength(\"BTCUSDT\", interval))\n    missing_intervals = db.check_continuous(\"BTCUSDT\", 1)\n    pass\n"
        },
        {
          "label": "Fragment 2",
          "language": "python",
          "value": ""
        }
      ],
      "id": "qijWW0-B",
      "createdAt": 1738504214297,
      "updatedAt": 1738504232041
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "numpy",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": ""
        }
      ],
      "id": "JreokbdZ",
      "createdAt": 1738552792353,
      "updatedAt": 1738552807237
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "numpy",
      "content": [
        {
          "label": "取整",
          "language": "python",
          "value": "向上取整：使用 numpy.ceil() 函数。\n向下取整：使用 numpy.floor() 函数。\n四舍五入：使用 numpy.round() 函数。"
        },
        {
          "label": "Fragment 2",
          "language": "python",
          "value": ""
        }
      ],
      "id": "Yc12Pbu8",
      "createdAt": 1738552904866,
      "updatedAt": 1738552923147
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "VCkpA7ri",
      "tagsIds": [],
      "description": null,
      "name": "datetime",
      "content": [
        {
          "label": "month",
          "language": "markdown",
          "value": "|kanji|hina|\n|---|---|\n|一月|いちがつ|\n|二月|にがつ|\n|三月|さんがつ|\n|四月|しがつ|\n|五月|ごがつ|\n|六月|ろくがつ|\n|七月|しちがつ|\n|八月|はちがつ|\n|九月|くがつ|\n|十月|じゅうがつ|\n|十一月|じゅういちがつ|\n|十二月|じゅうにがつ|"
        },
        {
          "label": "day",
          "language": "markdown",
          "value": "|kanji|hina|\n|--|--|\n|1日|ついたち|\n|2日|ふつか|\n|3日|みっか|\n|4日|よっか|\n|5日|いつか|\n|6日|むいか|\n|7日|なのか|\n|8日|ようか|\n|9日|ここのか|\n|10日|とおか|\n|11日|じゅういちにち|\n|12日|じゅうににち|\n|13日|じゅうさんにち|\n|14日|じゅうよっか|\n|15日|じゅうごにち|\n|16日|じゅうろくにち|\n|17日|じゅうしちにち|\n|18日|じゅうはちにち|\n|19日|じゅうくにち|\n|20日|はつか|\n|21日|にじゅういちにち|\n|22日|にじゅうににち|\n|23日|にじゅうさんにち|\n|24日|にじゅうよっか|\n|25日|にじゅうごにち|\n|26日|にじゅうろくにち|\n|27日|にじゅうしちにち|\n|28日|にじゅうはちにち|\n|29日|にじゅうくにち|\n|30日|さんじゅう|\n|31日|さんじゅういちにち|"
        },
        {
          "label": "hour",
          "language": "markdown",
          "value": "|kanji|hina|\n|--|--|\n|1時|いちじ|\n|2時|にじ|\n|3時|さんじ|\n|4時|よじ|\n|5時|ごじ|\n|6時|ろくじ|\n|7時|しちじ|\n|8時|はちじ|\n|9時|くじ|\n|10時|じゅうじ\n|11時|じゅういちじ|\n|12時|じゅうにじ|"
        },
        {
          "label": "minute",
          "language": "markdown",
          "value": "|kanji|hina|\n|--|--|\n|1分|いっぷん|\n|2分|にふん|\n|3分|さんぷん|\n|4分|よんぷん|\n|5分|ごふん|\n|6分|ろっぷん|\n|7分|ななふん|\n|8分|はちふん（はっぷん）|\n|9分|きゅうふん|\n|10分|じっぷん（じゅっぷん）|"
        },
        {
          "label": "second",
          "language": "markdown",
          "value": "- 全部都是音读数字，数字后面加秒（びょう）。\n\n- 4秒（よんびょう）\n- 7秒（ななびょう）\n- 9秒（きゅうびょう）\n\n"
        },
        {
          "label": "数",
          "language": "markdown",
          "value": "# 【天数的读法】\n\n\n除一天外，经过的天数和日期可以一样，也可以在日期后面加“間（かん）”\n\n例：一日　いちにち　　（不可以读成ついたち）　　\n\n　　二日　ふつか或ふつかかん\n\n\n\n# 【几小时的读法】\n\n\n小时的说法是“時間（じかん）”。\n\n注意：其中“4小时”为“よじかん”，“7小时”为“しちじかん”，“9小时”为“くじかん”。\n\n\n\n分钟数、秒数和年数的读法\n\n可以与分、秒、年相同，也可以在后面 加“間（かん）”。\n\n\n\n# 【月数的读法】\n\n\n月数“个月”的日语读法是“かげつ”一般写“ヶ月”或“ヵ月”\n\n1个月 一ヶ月　いっかげつ\n\n2个月 二ヶ月　にかげつ\n\n3个月 三ヶ月　さんかげつ　\n\n4个月 四ヶ月　よんかげつ\n\n5个月 五ヶ月　こかげつ\n\n6个月 六ヶ月　ろっかげつ\n\n7个月 七ヶ月　ななかげつ\n\n8个月 八ヶ月　はっかげつ（はちかげつ）\n\n9个月 九ヶ月　きゅうかげつ\n\n10个月 十ヶ月　じっかげつ（じゅうかげつ）\n\n1个月和2个月还可以用训读，分别说成：“一月（ひとつき）”和“二月（ふたつき）”。因此，在日语文章中看到“一月”时，根据前后文判断，是指“一月（元月）”时就读“いちがつ”；说的是“一个月”时读“ひとつき”。\n\n\n\n# 【几周的读法】\n\n\n“周”在日语中说“週間（しゅうかん）”。由于4周就是一个月，所以除有特殊含义的数目以外，很少说很大数目的周数。\n\n1周 一週間　いっしゅうかん\n\n2周　二週間　にしゅうかん\n\n3周　三週間　さんしゅうかん\n\n4周　四週間　よんしゅうかん\n\n5周　五週間　ごしゅうかん\n\n6周　六週間　ろくしゅうかん\n\n7周　七週間　ななしゅうかん\n\n8周　八週間　はちしゅうかん\n\n9周　九週間　きゅうしゅうかん\n\n10周 十週間　じっしゅうかん"
        }
      ],
      "id": "EiSxI6Kk",
      "createdAt": 1740032510225,
      "updatedAt": 1740034251139
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "csv",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": "import csv\nfrom MongoEngine import DBEngine  # 导入DBEngine类\n\n\ndef query_and_save_to_csv(\n    DB_INFO, stock_name, interval, output_file, order_by=\"open_time\", descending=False\n):\n    db_engine = DBEngine(**DB_INFO)\n\n    # 调用queryByNameAndInterval方法获取数据\n    query_result = db_engine.queryByNameAndInterval(\n        stock_name, interval, order_by, descending\n    )\n\n    # 将查询结果写入CSV文件\n    with open(output_file, mode=\"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        # 写入表头\n        writer.writerow(\n            [\n                \"stock_name\",\n                \"open_time\",\n                \"interval\",\n                \"open_price\",\n                \"high_price\",\n                \"low_price\",\n                \"close_price\",\n                \"volume\",\n                \"close_time\",\n                \"quote_asset_volume\",\n                \"number_of_trades\",\n                \"taker_buy_base_asset_volume\",\n                \"taker_buy_quote_asset_volume\",\n            ]\n        )\n        # 写入数据行\n        for kline in query_result:\n            writer.writerow(\n                [\n                    kline.stock_name,\n                    kline.open_time,\n                    kline.interval,\n                    kline.open_price,\n                    kline.high_price,\n                    kline.low_price,\n                    kline.close_price,\n                    kline.volume,\n                    kline.close_time,\n                    kline.quote_asset_volume,\n                    kline.number_of_trades,\n                    kline.taker_buy_base_asset_volume,\n                    kline.taker_buy_quote_asset_volume,\n                ]\n            )\n"
        }
      ],
      "id": "B-8b6f89",
      "createdAt": 1740710380792,
      "updatedAt": 1740710399559
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "YouDaoDict",
      "content": [
        {
          "label": "Word",
          "language": "python",
          "value": "from pathlib import Path\nfrom tqdm import tqdm\nimport re\nimport xml.etree.ElementTree as ET\n\nclass YouDaoWord:\n    \"\"\"\n    <wordbook>\n        <item>\n            <word>This is a Test这是单词 或者 句子</word>\n            <trans><![CDATA[这是解释]]></trans>\n            <phonetic><![CDATA[这是音标]]></phonetic>\n            <tags>这是分类</tags>\n            <progress>0</progress>\n        </item>\n    </wordbook>\n    \"\"\"\n    def __init__(self, word, trans=\"\", phonetic=\"\", tags=\"\", progress=0):\n        self.word = word\n        self.trans = trans\n        self.phonetic = phonetic\n        self.tags = tags\n        self.progress = progress\n    \n    def __str__(self):\n        return f\"<item>\\n\\t<word>{self.word}</word>\\n\\t<trans><![CDATA[{self.trans}]]></trans>\\n\\t<phonetic><![CDATA[{self.phonetic}]]></phonetic>\\n\\t<tags>{self.tags}</tags>\\n\\t<progress>{self.progress}</progress>\\n</item>\"\n\n    def as_node(self):\n        # 创建 <item> 元素\n        item = ET.Element(\"item\")\n        \n        # 创建并添加 <word> 元素\n        word = ET.SubElement(item, \"word\")\n        word.text = self.word\n        \n        # 创建并添加 <trans> 元素\n        trans = ET.SubElement(item, \"trans\")\n        trans.text = f\"<![CDATA[{self.trans}]]>\"\n        \n        # 创建并添加 <phonetic> 元素\n        phonetic = ET.SubElement(item, \"phonetic\")\n        phonetic.text = f\"<![CDATA[{self.phonetic}]]>\"\n        \n        # 创建并添加 <tags> 元素\n        tags = ET.SubElement(item, \"tags\")\n        tags.text = self.tags\n        \n        # 创建并添加 <progress> 元素\n        progress = ET.SubElement(item, \"progress\")\n        progress.text = self.progress\n        \n        return item\n    \n    def __repr__(self):\n        return self.__str__()"
        },
        {
          "label": "XML",
          "language": "python",
          "value": "from pathlib import Path\nfrom tqdm import tqdm\nimport re\nimport xml.etree.ElementTree as ET\n\nclass YouDaoXML:\n    def __init__(self, words=[]):\n        self.words = words\n    \n    def add_word(self, word):\n        \"\"\"\n        添加一个单词到单词列表中。\n        \"\"\"\n        self.words.append(word)\n\n    def as_xml(self):\n        \"\"\"\n        返回包含所有单词的完整 XML 文档。\n        \"\"\"\n        \"\"\"\n        <wordbook>\n            <item>\n                <word>This is a Test这是单词 或者 句子</word>\n                <trans><![CDATA[这是解释]]></trans>\n                <phonetic><![CDATA[这是音标]]></phonetic>\n                <tags>这是分类</tags>\n                <progress>0</progress>\n            </item>\n        </wordbook>\n        \"\"\"\n        # 创建 <wordbook> 根元素\n        wordbook = ET.Element(\"wordbook\")\n        \n        # 遍历所有单词，将每个单词转换为 XML 节点并添加到 <wordbook> 中\n        for word in self.words:\n            wordbook.append(word.as_node())\n        \n        # 将 ElementTree 对象转换为字符串\n        xml_str = ET.tostring(wordbook, encoding=\"unicode\", method=\"xml\")\n        return xml_str\n    \n    def save_xml(self, file_path):\n        \"\"\"\n        将 XML 文档保存到指定路径的文件中。\n        \"\"\"\n        # 将 XML 文档转换为字符串\n        xml_str = self.as_xml().replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n        \n        # 将字符串写入文件\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(xml_str)\n        \n        return file_path\n"
        }
      ],
      "id": "fg-bsAcY",
      "createdAt": 1742546720683,
      "updatedAt": 1744270604001
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "whisper",
      "content": [
        {
          "label": "dw",
          "language": "python",
          "value": "import argparse\nimport os\nimport subprocess\nfrom pathlib import Path\n\n\ndef getparser():\n    parser = argparse.ArgumentParser(\n        description=\"Download files from the internet\",\n    )\n    parser.add_argument(\n        \"-d\",\n        \"--dir\",\n        type=str,\n        required=True,\n        help=\"Directory to read the file\",\n    )\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        type=str,\n        default=None,\n        help=\"Output directory to save the file\",\n    )\n    # mpsac: 2\n    parser.add_argument(\n        \"-m\",\n        \"--mpsac\",\n        type=int,\n        default=2,\n        help=\"Number of processes to run in parallel\",\n    )\n    # model: large-v3\n    parser.add_argument(\n        \"-model\",\n        \"--model\",\n        type=str,\n        default=\"large-v3\",\n        help=\"Model to use\",\n    )\n    # model_dir: ~/.cache/whisper\n    parser.add_argument(\n        \"-model_dir\",\n        \"--model_dir\",\n        type=str,\n        default=\"~/.cache/whisper\",\n        help=\"Model directory\",\n    )\n    # world_size: 2\n    parser.add_argument(\n        \"-w\",\n        \"--world_size\",\n        type=int,\n        default=1,\n        help=\"World size\",\n    )\n    return parser\n\n\ndef main(args):\n\n    dir = Path(args.dir).absolute()\n    output_dir = dir.parent / f\"{dir.name}_sub\"\n\n    if args.output is not None:\n        output_dir = Path(args.output).absolute()\n\n    CMD = [\n        \"torchrun\",\n        \"--nproc_per_node\",\n        str(args.world_size),\n        \"process_script.py\",\n        \"--model\",\n        args.model,\n        \"--model_dir\",\n        args.model_dir,\n        \"--mpsac\",\n        str(args.mpsac),\n    ]\n    for d in dir.iterdir():\n        subprocess.run(\n            CMD\n            + [\n                \"--input_dir\",\n                d.__str__(),\n                \"--output_dir\",\n                output_dir.__str__(),\n            ],\n            check=True,\n        )\n\n\nif __name__ == \"__main__\":\n    ROOT = Path(__file__).resolve().parent\n\n    parser = getparser()\n    args = parser.parse_args()\n    main(args)\n"
        },
        {
          "label": "process_script",
          "language": "python",
          "value": "import whisper\nfrom whisper.transcribe import *\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.distributed import init_process_group, barrier\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport argparse\n\nMPS_AC = 0\nMPS_NUM = 2\nMPS_DEVICE = [1, 1, 2, 2, 3, 3, 4, 4]\n# MPS_DEVICE = [0,0,1,1,2,2,3,3,4,4]\n# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"#\"0,1,2,3,4\"\nos.environ[\"MKL_NUM_THREADS\"] = \"4096\"\nos.environ[\"OMP_NUM_THREADS\"] = \"4096\"\ntorch.set_num_threads(4096)\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\nLOCAL_RANK = int(\n    os.getenv(\"LOCAL_RANK\", 0)\n)  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv(\"RANK\", 0))\nWORLD_SIZE = int(os.getenv(\"WORLD_SIZE\", 1))\n\nFULL_S = [\"json\", \"srt\", \"tsv\", \"txt\", \"vtt\"]\nFULL_S_FILTER = lambda path, complete_ss: all(\n    [f\"{path.stem}.{suf}\" in complete_ss for suf in FULL_S]\n)\n\n\nclass input_files(Dataset):\n    def __init__(\n        self,\n        path,\n        valid_suffix=[\".acc\", \".mp3\", \".wav\", \".mp4\", \".m4a\"],\n        output_dir=None,\n        data_filter=None,\n        full_ss=True,\n    ):\n        self.path = path\n        self.files = (self.path / file for file in os.listdir(path))\n        self.files = [\n            f.__str__() for f in filter(lambda f: f.suffix in valid_suffix, self.files)\n        ]\n        if output_dir:\n            complete_ss = os.listdir(output_dir)\n            complete_set = set()\n            for i in complete_ss:\n                complete_set.add(Path(i).stem)\n            self.files = (\n                list(filter(lambda f: not FULL_S_FILTER(Path(f), complete_ss), self.files))\n                if full_ss\n                else list(\n                    filter(\n                        lambda f: Path(f).stem not in complete_set,\n                        self.files,\n                    )\n                )\n            )\n        if data_filter:\n            self.files = list(filter(lambda f: data_filter(f), self.files))\n\n    def __getitem__(self, index):\n        return self.files[index]\n\n    def __len__(self):\n        return len(self.files)\n\n\ndef ddp_setup(rank: int, world_size: int):\n    \"\"\"\n    Args:\n        rank: Unique identifier of each process\n    world_size: Total number of processes\n    \"\"\"\n    if MPS_AC == 0:\n        print(\"no mps\")\n        torch.cuda.set_device(rank)\n    elif MPS_AC == 1:\n        print(\"use MPS_DEVICE\")\n        torch.cuda.set_device(MPS_DEVICE[rank])\n    elif MPS_AC > 1:\n        print(f\"use MPS_AC={MPS_AC} devide\")\n        torch.cuda.set_device(rank // MPS_AC)\n    else:\n        raise (Exception(f\"mpsac={MPS_AC} is invalid\"))\n    if WORLD_SIZE > 1:\n        init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n\n\ndef get_args():\n    # fmt: off\n    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    # parser.add_argument(\"audio\", nargs=\"+\", type=str, help=\"audio file(s) to transcribe\")\n    parser.add_argument(\"--model\", default=\"small\", type=str, help=\"name of the Whisper model to use\")\n    parser.add_argument(\"--model_dir\", type=str, default=\"~/.cache/whisper\", help=\"the path to save model files; uses ~/.cache/whisper by default\")\n    parser.add_argument(\"--device\", default=\"cuda\" if torch.cuda.is_available() else \"cpu\", help=\"device to use for PyTorch inference\")\n    parser.add_argument(\"--mpsac\", type=int, default=0, help=\"device to use for PyTorch inference\")\n    parser.add_argument(\"--input_dir\", \"-i\", type=str, default=\"./input\", help=\"directory to read the music\")\n    parser.add_argument(\"--output_dir\", \"-o\", type=str, default=\"./output\", help=\"directory to save the outputs\")\n    parser.add_argument(\"--output_format\", \"-f\", type=str, default=\"all\", choices=[\"txt\", \"vtt\", \"srt\", \"tsv\", \"json\", \"all\"], help=\"format of the output file; if not specified, all available formats will be produced\")\n    parser.add_argument(\"--verbose\", type=str2bool, default=False, help=\"whether to print out the progress and debug messages\")\n\n    parser.add_argument(\"--task\", type=str, default=\"transcribe\", choices=[\"transcribe\", \"translate\"], help=\"whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')\")\n    parser.add_argument(\"--language\", type=str, default=None, choices=sorted(LANGUAGES.keys()) + sorted([k.title() for k in TO_LANGUAGE_CODE.keys()]), help=\"language spoken in the audio, specify None to perform language detection\")\n\n    parser.add_argument(\"--temperature\", type=float, default=0, help=\"temperature to use for sampling\")\n    parser.add_argument(\"--best_of\", type=optional_int, default=5, help=\"number of candidates when sampling with non-zero temperature\")\n    parser.add_argument(\"--beam_size\", type=optional_int, default=5, help=\"number of beams in beam search, only applicable when temperature is zero\")\n    parser.add_argument(\"--patience\", type=float, default=None, help=\"optional patience value to use in beam decoding, as in https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to conventional beam search\")\n    parser.add_argument(\"--length_penalty\", type=float, default=None, help=\"optional token length penalty coefficient (alpha) as in https://arxiv.org/abs/1609.08144, uses simple length normalization by default\")\n\n    parser.add_argument(\"--suppress_tokens\", type=str, default=\"-1\", help=\"comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations\")\n    parser.add_argument(\"--initial_prompt\", type=str, default=None, help=\"optional text to provide as a prompt for the first window.\")\n    parser.add_argument(\"--condition_on_previous_text\", type=str2bool, default=True, help=\"if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop\")\n    parser.add_argument(\"--fp16\", type=str2bool, default=True, help=\"whether to perform inference in fp16; True by default\")\n\n    parser.add_argument(\"--temperature_increment_on_fallback\", type=optional_float, default=0.2, help=\"temperature to increase when falling back when the decoding fails to meet either of the thresholds below\")\n    parser.add_argument(\"--compression_ratio_threshold\", type=optional_float, default=2.4, help=\"if the gzip compression ratio is higher than this value, treat the decoding as failed\")\n    parser.add_argument(\"--logprob_threshold\", type=optional_float, default=-1.0, help=\"if the average log probability is lower than this value, treat the decoding as failed\")\n    parser.add_argument(\"--no_speech_threshold\", type=optional_float, default=0.6, help=\"if the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence\")\n    parser.add_argument(\"--word_timestamps\", type=str2bool, default=False, help=\"(experimental) extract word-level timestamps and refine the results based on them\")\n    parser.add_argument(\"--prepend_punctuations\", type=str, default=\"\\\"\\'“¿([{-\", help=\"if word_timestamps is True, merge these punctuation symbols with the next word\")\n    parser.add_argument(\"--append_punctuations\", type=str, default=\"\\\"\\'.。,，!！?？:：”)]}、\", help=\"if word_timestamps is True, merge these punctuation symbols with the previous word\")\n    parser.add_argument(\"--highlight_words\", type=str2bool, default=False, help=\"(requires --word_timestamps True) underline each word as it is spoken in srt and vtt\")\n    parser.add_argument(\"--max_line_width\", type=optional_int, default=None, help=\"(requires --word_timestamps True) the maximum number of characters in a line before breaking the line\")\n    parser.add_argument(\"--max_line_count\", type=optional_int, default=None, help=\"(requires --word_timestamps True) the maximum number of lines in a segment\")\n    parser.add_argument(\"--max_words_per_line\", type=optional_int, default=None, help=\"(requires --word_timestamps True, no effect with --max_line_width) the maximum number of words in a segment\")\n    parser.add_argument(\"--threads\", type=optional_int, default=0, help=\"number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS\")\n    parser.add_argument(\"--clip_timestamps\", type=str, default=\"0\", help=\"comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process, where the last end timestamp defaults to the end of the file\")\n    parser.add_argument(\"--hallucination_silence_threshold\", type=optional_float, help=\"(requires --word_timestamps True) skip silent periods longer than this threshold (in seconds) when a possible hallucination is detected\")\n\n    parser.add_argument(\"--eval_only\", action=\"store_true\", default=False)\n    parser.add_argument(\"--pretrained\", type=str, default=\"\")\n    return parser.parse_args().__dict__\n\n\nif __name__ == \"__main__\":\n    args = get_args()\n    \n    # input_dir = Path(\"kyr_mp3\")\n    # output_dir = Path(\"kyr_s\")\n    input_dir = Path(args[\"input_dir\"])\n    output_dir = Path(args[\"output_dir\"])\n    output_dir.mkdir(exist_ok=True)\n\n    model_name = \"large-v3\"\n    model_dir = args[\"model_dir\"]\n    output_format = \"all\"\n    device = \"cuda\"\n    args[\"language\"] = \"Japanese\"\n    MPS_AC = args[\"mpsac\"]\n\n    args.pop(\"mpsac\")\n    args.pop(\"model\")\n    args.pop(\"model_dir\")\n    args.pop(\"output_dir\")\n    args.pop(\"input_dir\")\n    args.pop(\"output_format\")\n    args.pop(\"device\")\n    args.pop(\"threads\")\n    args.pop(\"eval_only\")\n    args.pop(\"pretrained\")\n\n    ddp_setup(RANK, WORLD_SIZE)\n\n    model = whisper.load_model(\"large-v3\", device=\"cuda\", download_root=model_dir)\n    temperature = args.pop(\"temperature\")\n    if (increment := args.pop(\"temperature_increment_on_fallback\")) is not None:\n        temperature = tuple(np.arange(temperature, 1.0 + 1e-6, increment))\n    else:\n        temperature = [temperature]\n\n    writer = get_writer(output_format, output_dir)\n    exists_ssrs = {Path(i).stem for i in os.listdir(output_dir)}\n    word_options = [\n        \"highlight_words\",\n        \"max_line_count\",\n        \"max_line_width\",\n        \"max_words_per_line\",\n    ]\n    args[\"word_timestamps\"] = True\n    if not args[\"word_timestamps\"]:\n        for option in word_options:\n            assert args[option], Exception(\n                f\"--{option} requires --word_timestamps True\"\n            )\n    if args[\"max_line_count\"] and not args[\"max_line_width\"]:\n        warnings.warn(\"--max_line_count has no effect without --max_line_width\")\n    if args[\"max_words_per_line\"] and args[\"max_line_width\"]:\n        warnings.warn(\"--max_words_per_line has no effect with --max_line_width\")\n    writer_args = {arg: args.pop(arg) for arg in word_options}\n\n    def data_filter(s):\n        # stem = Path(s).stem\n        # if int(stem[:4]) > 800:\n        # return True\n        # return False\n        return True\n\n    dataset = input_files(input_dir, output_dir=output_dir, data_filter=data_filter)\n    loop = DataLoader(\n        dataset,\n        batch_size=1,\n        sampler=(\n            DistributedSampler(dataset, shuffle=False) if (WORLD_SIZE > 1) else None\n        ),\n    )\n    if not RANK:\n        loop = tqdm(loop)\n    for audio_path in loop:\n        assert len(audio_path) == 1\n        audio_path = audio_path[0]\n        # if Path(audio_path).stem in exists_ssrs:\n        #     print(f\"skip audio_path\")\n        #     continue\n        # result = transcribe(\n        #     model, audio_path.__str__(), temperature=temperature, **args\n        # )\n        # writer(result, audio_path, **writer_args)\n        try:\n            result = transcribe(\n                model, audio_path.__str__(), temperature=temperature, **args\n            )\n            audio_path = Path(audio_path)\n            audio_path = (audio_path.parent / f\"{audio_path.stem[:120]}{audio_path.suffix}\").__str__()\n            writer(result, audio_path, **writer_args)\n        except Exception as e:\n            traceback.print_exc()\n            print(f\"Skipping {audio_path} due to {type(e).__name__}: {str(e)}\")\n"
        }
      ],
      "id": "VVwP7Nqo",
      "createdAt": 1742957822421,
      "updatedAt": 1742957886042
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "MeloTTS",
      "content": [
        {
          "label": "MeloEngine",
          "language": "python",
          "value": "from melo.api import TTS\n\nclass MeloEngine:\n    def __init__(self, language='JP', device='cuda'):\n        self.language = language\n        self.device = device\n        self.model = TTS(language=language, device=device)\n        self.speaker_ids = self.model.hps.data.spk2id[language]\n    \n    def __call__(self, text, output_path=None, speed=1.0):\n        self.model.tts_to_file(text, self.speaker_ids, output_path, speed=speed)\n\nif __name__ == '__main__':\n    import os\n\n    os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\"\n    \n    melo = MeloEngine()\n\n    # text = \"彼は毎朝ジョギングをして体を健康に保っています。\"\n    text = \"628年10月17日 金曜日 午前9時57分30秒\"\n\n    melo(text, output_path='test.wav', speed=1.0)\n    \n    pass"
        }
      ],
      "id": "NTDC84Ld",
      "createdAt": 1742957936993,
      "updatedAt": 1742957974615
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "PgWKBdHD",
      "tagsIds": [],
      "description": null,
      "name": "oray",
      "content": [
        {
          "label": "Fragment 1",
          "language": "markdown",
          "value": " +--------------------------------------------------+\n |             Oray PeanutHull Linux 5.3.0          |\n +--------------------------------------------------+\n |  SN: oray109ad98a4ebf   Default password: admin  |\n +--------------------------------------------------+\n |    Remote Management Address http://b.oray.com   |\n +--------------------------------------------------+\n"
        }
      ],
      "id": "YpWbKr6A",
      "createdAt": 1742960558143,
      "updatedAt": 1742960563742
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "NCg2YrWJ",
      "tagsIds": [],
      "description": null,
      "name": "zip",
      "content": [
        {
          "label": "Fragment 1",
          "language": "sh",
          "value": "Linux zip 命令\nLinux 命令大全 Linux 命令大全\n\nLinux zip 命令用于压缩文件。\n\nzip 是个使用广泛的压缩程序，压缩后的文件后缀名为 .zip。\n\n与 gzip 或 bzip2 不同，zip 可以压缩多个文件或整个目录，并保留文件的目录结构。\n\nzip 在跨平台（如 Windows、macOS）上也广泛支持。\n\n语法\nzip [options] output.zip file1 file2 ...\noutput.zip：生成的压缩文件名。\nfile1 file2 ...：要压缩的文件或目录。\noptions 参数选项：\n\n-r：递归压缩目录及其子目录中的所有文件。\n-e：为压缩文件设置密码保护。\n-q：静默模式，不显示压缩过程。\n-v：显示详细的压缩过程。\n-x：排除某些文件或目录，不进行压缩。\n-m：压缩后删除原始文件。\n-0 到 -9：指定压缩级别，-0 表示存储不压缩，-9 表示最高压缩率，默认是 -6。\n实例\n压缩单个文件\n\nzip archive.zip example.txt\n此命令会将 example.txt 压缩为 archive.zip。\n\n压缩多个文件\n\nzip archive.zip file1.txt file2.txt file3.txt\n此命令会将 file1.txt、file2.txt 和 file3.txt 压缩到 archive.zip 中。\n\n递归压缩目录\n\nzip -r archive.zip directory/\n此命令会递归压缩 directory 目录及其子目录中的所有文件，并保留目录结构。\n\n压缩并设置密码保护\n\nzip -e archive.zip file.txt\n此命令会压缩 file.txt 并设置密码保护，解压时需要输入密码。\n\n排除特定文件\n\nzip -r archive.zip directory/ -x \"*.log\"\n此命令会压缩 directory/ 目录下的所有文件，但排除所有 .log 文件。\n\n压缩后删除原始文件\n\nzip -m archive.zip file.txt\n此命令会将 file.txt 压缩为 archive.zip，并删除原始文件 file.txt。\n\n解压缩文件\n\n使用 unzip 命令来解压缩 .zip 文件：\n\nunzip archive.zip"
        }
      ],
      "id": "ph1XnnQC",
      "createdAt": 1742967973924,
      "updatedAt": 1742967976671
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "",
      "tagsIds": [],
      "description": null,
      "name": "Untitled snippet",
      "content": [
        {
          "label": "Fragment 1",
          "language": "plain_text",
          "value": ""
        }
      ],
      "id": "y4N6bDzt",
      "createdAt": 1745238323633,
      "updatedAt": 1745238329204
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "voicevox",
      "content": [
        {
          "label": "rename",
          "language": "python",
          "value": "import shutil\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport json\n\nVOICE_MAP = {\n    \"WhiteCUL（ノーマル）\": \"a\",\n    \"青山龍星（ノーマル）\": \"b\",\n}\n\n\nclass Setence:\n    def __init__(self, ja, voice_a, voice_b):\n        self.ja = ja\n        self.voice_a = voice_a\n        self.voice_b = voice_b\n\n\nif __name__ == \"__main__\":\n    ROOT = Path(__file__).parent.resolve()\n    wav_dir = ROOT / \"bk_wav_new\"\n    wav_tran = ROOT / \"bk_wav_new_tran\"\n    wav_tran.mkdir(exist_ok=True)\n\n    for wav in tqdm(list(wav_dir.glob(\"*.wav\"))):\n        file_name = wav.stem.split(\"_\")\n        new_file = wav_tran / f\"{file_name[0]}_{VOICE_MAP[file_name[1]]}.wav\"\n        if new_file.is_file():\n            continue\n        shutil.copy(\n            wav,\n            new_file,\n        )\n        print(new_file)\n    pass\n\n"
        },
        {
          "label": "anki",
          "language": "python",
          "value": "# anki 批量制卡\nimport genanki\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom sqlalchemy import create_engine, Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom pprint import pprint\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport json\n\nBase = declarative_base()\n\n\nclass Line(Base):\n    __tablename__ = \"Line\"\n\n    id = Column(Integer, primary_key=True, autoincrement=True)\n    ja = Column(String, nullable=False)\n    zh = Column(String, nullable=False)\n\n    def __repr__(self):\n        return f\"Line(id={self.id}, ja={self.ja}, zh={self.zh})\"\n\n\nif __name__ == \"__main__\":\n    ROOT = Path(__file__).parent.resolve()\n\n    DB_PATH = ROOT / \"bk.db\"\n\n    # 创建数据库引擎\n    engine = create_engine(f\"sqlite:///{DB_PATH}\", echo=True)\n\n    # 创建表\n    Base.metadata.create_all(engine)\n\n    # 创建会话\n    Session = sessionmaker(bind=engine)\n    session = Session()\n\n    WAV_DIR_O = ROOT / \"bk_wav_new\"\n    WAV_DIR = ROOT / \"bk_wav_new_tran\"\n\n    proj_file_0 = WAV_DIR_O / \"bk_whitecul.vvproj\"\n    with open(proj_file_0, \"r\", encoding=\"utf-8\") as f:\n        proj_0 = json.load(f)\n    seq_id_list_0 = proj_0[\"talk\"][\"audioKeys\"]\n    seq_0 = proj_0[\"talk\"][\"audioItems\"]\n\n    proj_file_1 = WAV_DIR_O / \"bk_aoyama.vvproj\"\n    with open(proj_file_1, \"r\", encoding=\"utf-8\") as f:\n        proj_1 = json.load(f)\n    seq_id_list_1 = proj_1[\"talk\"][\"audioKeys\"]\n    seq_1 = proj_1[\"talk\"][\"audioItems\"]\n\n    seq = []\n\n    file_pattern_a = \"%s_a.wav\"\n    file_pattern_b = \"%s_b.wav\"\n\n    # 创建一个模型\n    model_id = 1607396719\n    model = genanki.Model(\n        model_id,\n        \"Picture Card\",\n        fields=[\n            {\"name\": \"FrontText\"},\n            {\"name\": \"BackText\"},\n        ],\n        templates=[\n            {\n                \"name\": \"Card 1\",\n                \"qfmt\": \"{{FrontText}}\",\n                \"afmt\": \"{{BackText}}\",\n            },\n        ],\n    )\n\n    # 创建一个牌组\n    deck_id = 2059457111\n    deck = genanki.Deck(deck_id, \"JA商务会话\")\n\n    media_files = []\n\n    def zh_query(ja):\n        results = session.query(Line).filter(Line.ja.like(f\"%{ja}%\")).all()\n        assert len(results) >= 1\n        if len(results) == 0:\n            return \"\"\n        else:\n            return results[0]\n\n    for idx, (id_a, id_b) in enumerate(zip(seq_id_list_0, seq_id_list_1), 1):\n        assert seq_1[id_b][\"text\"] == seq_0[id_a][\"text\"]\n        wav_a = WAV_DIR / (file_pattern_a % str(idx).rjust(3, \"0\"))\n        wav_b = WAV_DIR / (file_pattern_b % str(idx).rjust(3, \"0\"))\n        assert wav_a.is_file()\n        assert wav_b.is_file()\n        ja = seq_1[id_b][\"text\"]\n        zh = zh_query(ja).zh\n\n        media_files.append(str(wav_a))\n        media_files.append(str(wav_b))\n        note = genanki.Note(\n            model=model,\n            fields=[\n                \"\"\"<h1>%s<h1/>[sound:%s][sound:%s]\"\"\"\n                % (\n                    ja,\n                    wav_a.name,\n                    wav_b.name,\n                ),\n                \"\"\"<h1>%s<h1/><h1>%s<h1/>[sound:%s][sound:%s]\"\"\"\n                % (\n                    ja,\n                    zh,\n                    wav_a.name,\n                    wav_b.name,\n                ),\n            ],\n        )\n        deck.add_note(note)\n\n    # 生成APKG文件\n    my_package = genanki.Package(deck)\n    my_package.media_files = media_files\n    my_package.write_to_file(ROOT / \"bk_cards.apkg\")\n"
        }
      ],
      "id": "4NbKuVgA",
      "createdAt": 1745238331747,
      "updatedAt": 1745240130151
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "singleton",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": "class Solution:\n    # 1、记录第一个被创建对象的引用，代表着类的私有属性\n    _instance = None # 静态变量 存储在类的命名空间里的\n\n    def __init__(self,name,data):\n        self.name = name\n        self.data = data\n        self.xml_load(self.data)\n\n    def __new__(cls, *args, **kwargs):\n        # 2.判断该类的属性是否为空；对第一个对象没有被创建，我们应该调用父类的方法，为第一个对象分配空间\n        if cls._instance == None:  \n            # 3.把类属性中保存的对象引用返回给python的解释器\n            cls._instance = object.__new__(cls)  # 3\n            return cls._instance\n        # 如果cls._instance不为None,直接返回已经实例化了的实例对象\n        else:\n            return cls._instance  # 必须把地址返回给new方法，让它有存储空间\n\n    def xml_load(self,data):\n        print(\"初始化init\",self.name,data)\n\n    def Parser(self):\n        print(\"解析完成finish\",self.name)\n\na = Solution(\"A11\",10)  #第一次开辟一个对象空间地址，后面创建都是在该地址上进行的\na.Parser()\nb = Solution(\"A12\",20)  #b把a覆盖掉\nb.Parser()\nprint(id(a))\nprint(id(b))\n# 内存地址，而且它们的内存地址都是一样的\nprint(a.name)\nprint(b.name)"
        }
      ],
      "id": "n4eLuxEl",
      "createdAt": 1746247756330,
      "updatedAt": 1746247761800
    },
    {
      "isDeleted": true,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": ""
        }
      ],
      "id": "a5sePRNb",
      "createdAt": 1746416405665,
      "updatedAt": 1746416410661
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "docker gpu",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": "docker run -itd --restart=always --shm-size=32g --gpus all -e NVIDIA_VISIBLE_DEVICES=all -e NVIDIA_DRIVER_R_CAPABILITIES=compute,utility -v /home/C:/data/C -v /root:/rootm -v /home/B:/data/B --name project_docker project:v0.2"
        }
      ],
      "id": "TmHM7l7v",
      "createdAt": 1746416412705,
      "updatedAt": 1746436393249
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "DvcfGvIx",
      "tagsIds": [],
      "description": null,
      "name": "logger",
      "content": [
        {
          "label": "logger ddp",
          "language": "python",
          "value": "def get_logger(\n    local_rank=0,\n    name=\"logger\",\n    cli_level=logging.INFO,\n    log_level=logging.DEBUG,\n    cli=True,\n    log_dir=None,\n):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    logger.propagate = False\n\n    if cli:\n        cli_formatter = logging.Formatter(\"%(message)s\")\n        cli_handler = logging.StreamHandler(sys.stdout)\n        cli_handler.setLevel(cli_level if local_rank == 0 else logging.CRITICAL)\n        cli_handler.setFormatter(cli_formatter)\n        logger.addHandler(cli_handler)\n\n    if log_dir:\n        log_dir = Path(log_dir)\n        if log_dir.is_file():\n            raise ValueError(f\"Log directory path exists as file: {log_dir}\")\n        log_dir.mkdir(exist_ok=True, parents=True)\n\n        file_formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n        file_handler = logging.FileHandler(\n            log_dir / f\"log_rank{local_rank}.txt\",\n        )\n        file_handler.setLevel(log_level)\n        file_handler.setFormatter(file_formatter)\n        logger.addHandler(file_handler)\n\n    return logger\n"
        },
        {
          "label": "Fragment 2",
          "language": "python",
          "value": ""
        }
      ],
      "id": "ng1EATAD",
      "createdAt": 1746436163485,
      "updatedAt": 1746436195715
    },
    {
      "isDeleted": false,
      "isFavorites": false,
      "folderId": "weWtbZI4",
      "tagsIds": [],
      "description": null,
      "name": "download tqdm",
      "content": [
        {
          "label": "Fragment 1",
          "language": "python",
          "value": "    chuck_size = chuck_size\n\n    # download url use requests with tqdm\n    with requests.get(\n        url,\n        headers={\n            \"User-Agent\": USER_AGENT,\n        },\n        stream=True,\n    ) as r:\n        with tqdm(\n            total=int(r.headers.get(\"content-length\")),\n            unit=\"B\",\n            unit_scale=True,\n            unit_divisor=chuck_size,\n        ) as pbar:\n            with open(path, \"wb\") as f:\n                for data in r.iter_content(\n                    chunk_size=chuck_size,\n                ):\n                    f.write(data)\n                    pbar.update(len(data))"
        }
      ],
      "id": "j9-3d9t7",
      "createdAt": 1746503342598,
      "updatedAt": 1746503351754
    }
  ],
  "tags": [
    {
      "name": "normal usage",
      "id": "7xSxQ3Xg",
      "createdAt": 1705650814819,
      "updatedAt": 1705650814819
    },
    {
      "name": "object array",
      "id": "7pTrIPxa",
      "createdAt": 1729698459359,
      "updatedAt": 1729698459359
    },
    {
      "name": "unique index",
      "id": "DRCnm5ma",
      "createdAt": 1730010904478,
      "updatedAt": 1730010904478
    }
  ]
}